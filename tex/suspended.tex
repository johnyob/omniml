%; whizzy section

%% Leave the above line for didier
%% No macros before \documentclass


\documentclass[acmsmall,screen,nonacm,review,anonymous]{acmart}
\input{suspended.cfg}

\newcommand{\acmart}{\True}
\usepackage{suspended}

%% \Xfirstname defined in {mycomments}
%% Use either
%%   \Xfistname[text to comment]{your comment on the text}
%% or
%%   \Xfirstname{free comment}
%% Uncomment this line to hide all comments.
% \UNXXX{}

\author{Alistair O'Brien}
\orcid{0009-0009-0055-7793}
\affiliation{
  \instuition{University of Cambridge}
  \city{Cambridge}
  \country{United Kingdom}
}
\email{ajo41@cam.ac.uk}

\usepackage{marginnote}

\title{Omnidirectional type inference for \ML: principality any way}

\begin{document}

\begin{abstract}

We propose a new concept of \emph{omnidirectional} type inference: the
ability to resolve \ML-style typing constraints in disorder. In contrast,
all known existing implementations typically infer the types of
let-bound expressions before typechecking their use sites.
%
This relies on two technical devices: \emph{suspended match constraints},
which suspend the resolution of some constraints until the context has more
information about a type variable; and \emph{partial type schemes}, which
allow taking instances of a partially solved type scheme containing
suspended constraints, with a mechanism to incrementally update instances as
the scheme is refined.
%
\Xalistair[Changed, preferred the submitted version. Was]{While the benefits of omnidirectional type inference are minor for core \ML,
  which truly enjoy principal types, they}\XDR{The meaning is not the
  same. I find the formulation you like overselling, and lying by omission}

  \TODO{Change to mention that omnidirectional doesn't Core \ML, issue with striking, frame it that the framework
  makes a striking improvement.}

The benefits of omnidirectional type inference are striking for several advanced
\ML extensions, typically those that rely on optional type annotations where
principality is fragile.  We illustrate them with \OCaml's static
overloading of record labels and datatype constructors, semi-explicit
first-class polymorphism, and tuple projections \ala \SML.
\end{abstract}
\maketitle

\section{Introduction}
\label{sec/introduction}

\parcomment {Introduction (ML, principality)}

The Damas-Hindley-Milner (\HM) \citep*{Damas-Milner/W@popl82} type system has
long occupied a sweet spot in the design space of strongly typed programming
languages, as it enjoys the \emph{principal types property}: every well-typed
expression $\e$ has a most general type $\ts$ from which all other valid types
for $\e$ are instances of $\ts$. For example, the identity function $\efun \x
\x$ has the principal type $\tfor \tv \tv \to \tv$, generalizing types like
$\tint \to \tint$ and $\tbool \to \tbool$.

\parcomment {Benefits of principality}

This property ensures predictable and efficient inference. Local typing
decisions are always optimal, yielding most general types without guessing
or backtracking. As a result, inference of subexpressions can proceed in any
order, with one exception: let-bound expressions are typically inferred
before their use. Still, well-typedness is preserved under common program
transformations such as let-contraction and argument reordering.

\parcomment {Extensions often break pincipality}

Over the years, many extensions of \ML have been proposed. Some of
them, such as extensible records with row-polymorphism, higher-kinded
types, or dimensional types, fit perfectly into the \ML
framework. Others such as GADTs, higher-rank polymorphism, or static
overloading, are \emph{fragile}, as they sometimes require explicit
type annotations. The return type of overloaded datatype constructors may
be annotated; polymorphic expressions can be annotated with a type
scheme; and for GADTs, both the type of the \texttt{match} scrutinee and return
type can be annotated with a rigid type, which is refined by type
equalities introduced in each branch.
These type annotations may sometimes---but
not always---be omitted.

For instance, consider impredicative higher-rank polymorphism:
\begin{program}[input]
let self f = f f
\end{program}
One could \emph{guess} the (higher-rank) type of \code{f} to be
either $\tfor \tv \tv \to \tv$ or $\tfor \tv \tv \to \tv \to \tv$ in order
to typecheck \code{self}---neither of which is strictly more general than the other,
violating principality.

\parcomment {Current approaches are kinda bad}

To fix this, inference algorithms require a minimal amount of
\emph{known} type information to restore principality; in this example
the binding of \code{f} should be annotated with a polymorphic type
scheme. Yet specifying annotatability declaratively is
difficult. As a result, the specifications are often twisted with some
direct or indirect algorithmic flavor in order to preserve
principality and completeness.
%
Moreover, these (more or less) ad-hoc restrictions commonly reject examples
whose type could easily be guessed. For instance, \MLF~\citep*{LeBotlan-Remy/recasting-mlf} accepts
or rejects the following expression, depending on the position of the
annotation (using a traffic-light scheme: \smashcolorbox{welltyped}{\strut green} and \smashcolorbox{illtyped}{\strut red} indicate typechecking success
and failure):
\begin{program}[input]
let self' (f : $\forall$'a. 'a -> 'a) = if true then f f else f $
$   °\Ocamlcomment{\ocamlFlag {\MLF}0}°
let self' f = if true then f f else (f : $\forall$'a. 'a -> 'a) $
$   °\Ocamlcomment{\ocamlFlag {\MLF}1}°
\end{program}

\parcomment {Annotations fixes all the issues (but they're problematic)}

\subsection{Directional type inference}

Each fragile construct admits
a robust counterpart where the type annotation is mandatory. While
robust constructs fit perfectly into the \ML framework, they are
significantly more cumbersome to use, as they always require explicit type
annotations. Fragile constructs can be defined by elaboration into their
robust counterpart.
%
% The elaboration determines which annotations can be
% omitted and rebuilt from context, a point of view already taken by~\citet*
% {Pottier-Regis-Gianas/stratified@popl06} in their work on stratified type
% inference.
%
The difficulty lies in finding a specification
that is sufficiently expressive, principled, and intuitive to the user,
and that also admits a complete and principal inference algorithm.

The solutions proposed so far all enforce some ordering in which type
inference is performed, which can be used to propagate both inferred
types and user-provided type annotations as \emph{known} types that can be
used for disambiguation and enable the omission of some annotations.

\TODO{Give overview of the current state of directionality (and the problems we face) }
\TODO{Consider moving both these paragraphs to related work. Make the introduction more
vague (but still true)}
\Xalistair{This feels a bit out of place, should we say this earlier?}
\Geninst-directional inference offers a way to specify and implement principal
type inference for fragile features, aligning with the implicit inference order
present in most \ML-like typecheckers.
%
This mechanism was originally proposed by~\citet*{Garrigue-Remy/poly-ml} for
semi-explicit first-class polymorphism, and later used
by~\citet*{LeBotlan-Remy/recasting-mlf} for empowering \MLF.
%
It has since been adopted in \OCaml for features such as polymorphic object
methods and the overloading of record fields and variant constructors. More
generally, \OCaml uses \geninst-directionality whenever the typechecker
disambiguates on type information.


\paragraph{\Geninst-directional type inference}

\parcomment{Introduce the order}

Most \ML inference algorithms enforce a fixed order when typechecking
let-bindings $\elet \x \ea \eb$: first typecheck the definition $\ea$, then
the body $\eb$. \OCaml leverages this ordering to resolve overloaded or
ambiguous constructs in a \emph{principal} way: polymorphic (parts of) types
are treated as \emph{known} and may guide disambiguation, whereas
monomorphic (parts of) types are considered not-yet-known and cannot be
relied on for disambiguation.

\parcomment{What is it, and what does it solve (by example)}

We call this \textbf{\geninst}-directional (read as
``\textbf{pi}-directional'') type inference, to mean that
\textbf{p}olymorphic expressions must be typed before their
\textbf{i}nstances.
%
\parcomment{Summary / uses}

To illustrate \geninst-directionality, consider the following two record types with overlapping field
names:
\begin{program}[input]
type 'a one = {x : 'a; y : int}
type two = {x : int; z : int}
\end{program}
In \OCaml, both definitions are in scope, and the compiler must
statically disambiguate each field usage.
\begin{program}[input,check]
let one = { x = 1; y = 1 }                               °\ocamlflags 00°
\end{program}
The expression \ocaml!one! can only be \code{int one}.
Similarly, \code{r.y} necessarily infers \code{one} for the type of \code{r}.
But field accesses such as \code{r.x} are ambiguous unless the type of
\code{r} is
\emph{known}. Consider:
\begin{program}[input,check]
let ex_1 r = r.x                                           °\ocamlflags 21°
let ex_2 = let r = one in r.x                              °\ocamlflags 00°
let ex_3 = (fun r -> r.x) one                              °\ocamlflags 10°
\end{program}
In \ocaml{ex_1}, the type of \code{r} is unconstrained, so disambiguation
fails.\footnote
%
{
  In fact, \OCaml does not fail on ambiguous types, but instead applies a
    default resolution strategy: it emits a warning and selects the last
    matching type definition in scope. Here, this will amount to choosing the
    type \code{two} for \code{r}. To check all our examples, use the options
    \texttt{-principal -w +41+18 -warn-error +41+18}, which enables principal
    type inference and escalates the associated warnings to errors.
    \label{fn/principal}
}
%
\relax
At first glance, \code{ex_2} and \code{ex_3} appear equivalent: in both,
the expression \code{r.x} can only refer to the field from type \code{int one}.
Yet, \OCaml accepts \code{ex_2} and rejects \code{ex_3}.
This is because the \code{let}-binding in \code{ex_2} allows \code{r} to be
treated polymorphically, and thus its type is considered \emph{known}--enabling
disambiguation. In \code{ex_3}, by contrast, \code{r} is monomorphic at the
point of projection, and disambiguation is therefore forbidden.

To emphasize that this behavior is specification-driven and not an
artifact of \OCaml's inference algorithm, consider two equivalent versions of
\ocaml{ex_3}:\footnote {\ocaml{app} and \ocaml{rev_app} are the application
function $\efun f \efun \x \eapp f \x$ and the reverse application function
$\efun \x \efun f \eapp f \x$, respectively.}
\begin{program}[input,check]
let ex_3_2 = app (fun r -> r.x) one                        °\ocamlflags 10°
let ex_3_3 = rev_app one (fun r -> r.x)                    °\ocamlflags 20°
\end{program}
While these terms are semantically equivalent, they highlight a potential
hazard: their typability may vary under a directionally biased inference
algorithm, depending on whether the function or argument is typed first.  To
limit such implementation-dependent behavior, \OCaml infers all
subexpressions \emph{simultaneously}, until they are \code{let}-bound.
Consequently, \OCaml does not make any difference between
\ocaml[indices]{ex_3}, \ocaml[indices]{ex_3_2}, and \ocaml[indices]{ex_3_3}.
The same criterion also fails on \ocaml[indices]{ex_4_1} and
\ocaml[indices]{ex_4_2} below, since although \code{r} is annotated, it is
$\lambda$-bound and therefore assigned a monomorphic type.
\begin{program}[input,check]
let ex_4_1 p r = if p then (r : 'a one).x else r.x         °\ocamlflags 20°
let ex_4_2 p r = if p then r.x else (r : 'a one).x         °\ocamlflags 10°
\end{program}
Treating both examples uniformly is in one sense a strength of
\geninst-directionality, but it also reveals a limitation:
annotatability is fragile, in that well-typedness depends on the
\emph{precise} placement of annotations, often forcing the programmer
to introduce annotations that would otherwise be unnecessary.

\paragraph{Bidirectional type inference}

Bidirectional type inference is a standard alternative to unification for
propagating type information. It is typically formulated by splitting typing
rules into two modes: \emph{checking mode}, which typechecks a term $\e$
against a \emph{known} type $\t$ in a given context, and \emph{inference
mode} which infers $\e$ from the context alone.

For example, the type system designer can decide to typecheck function
applications $\eapp \ea \eb$ by first \emph{inferring} that $\ea$ has some
function type $\t \tarrow \tp$, and then \emph{checking} $\eb$ against $\t$.
This is not the only possible choice: bidirectional type inference is a
framework that must be instantiated by assigning modes---checking or
inference---to each language construct. There is usually no optimal assignment
of modes: for any choice of modes, some programs will typecheck successfully,
while others will fail unnecessarily. Yet, the typing rules must irrevocably
commit to a fixed set of modes, after which, principal types often exist, but
only with respect to a specification that made non-principal choices to
begin with.
%
Bidirectional type inference has been largely used for languages with
higher-rank polymorphism, dependent types, or subtyping.  Still, both \OCaml
and \Haskell only use a limited form of bidirectional typing with an
underlying first-order unification-based type inference engine, that limits
the downsides of bidirectional type inference.


\paragraph{Limitations of directional type inference}

\Xalistair{Redundant? We give uses above?}\XDR{Do you mean next sentence,
next two paragraphs, or the whole section?}While both strategies for
directional type inference have some virtues, and have proved quite useful
in the past, they also have some limitations.

Bidirectional type inference is lightweight, practical, and well-suited for
complex language features. It supports the propagation of type information with
minimal annotations. Its main downside lies in the need to fix an often
arbitrary flow of type information---as in the case of function applications
discussed above.

On the other hand, \emph{\Geninst-directional} type inference appears better
suited for \ML, relying on polymorphism, the essence of \ML. But it remains
surprisingly weak in some cases: it does not even allow the propagation of
user-provided type annotations from a function to its argument!
This weakness is sometimes counter-intuitive to the user.
For example,
the following would be rejected as ambiguous with \geninst-directional
type alone:
\begin{program}[input,check]
let ex_5 = let g (f : 'a one -> int) = f one in g (fun r -> r.x)$
$ °\ocamlflags 00°
\end{program}
Here, \code{r} is $\lambda$-bound and therefore monomorphic. Without further
propagation, the term \code{r.x} would be ambiguous, as no polymorphic (and
thus \emph{known}) type can be ascribed to \code{r}. \OCaml resolves this by
supplementing  \geninst-directional inference with a weak form of bidirectional
propagation: the expected type of \code{g}'s argument (\code{'a one -> int}) is
bidirectionally propagated to the $\lambda$-function, assigning \code{r} to have the
\emph{known} type \code{'a one} and thereby disambiguating \code{r.x}.

\Xalistair{A couple proof readers have found this point odd (since it is a
rather technical point), perhaps it is sufficient to say that
\geninst-directionality incurs a cost and that \OCaml by default disables
principal inference?}\XDR{This is important, and be stated,
rephrased or moved somewhere else in the discussion, but not removed}
Besides, the implementation of \geninst-directional type
inference has an algorithmic cost. For technical reasons, type annotations must
unshare types (from acyclic graphs as naturally produced by unification to
trees), which may increase the size of types and the cost of type inference.
For that reason, the implementation of \OCaml cheats and is incomplete by
default. The user must explicitly pass the \texttt{\small -principal}
flag\cref{fn/principal} to require the more expensive computation when desired.

\subsection{Omnidirectional type inference}

In the absence of \emph{implicit} polymorphism, type inference is solely
based on unification constraints which can be solved in any order;
omnidirectional inference is then natural and easy to implement.  The
difficulty originates from \ML \emph{implicit} let-polymorphism for which
all known implementations follow the \geninst-order: first typing the
binding, generalizing it into a type scheme, and finally typing the body
under the extended typing environment that binds the generalized scheme.
The Hindley-Milner algorithm $\mathcal{J}$, one of its variants
$\mathcal{W}$ or $\mathcal{M}$~\citep* {Lee_Yi/algoM@toplas1998}, or more
flexible constraint-based type inference implementations~\citep*
{Remy/mleth,Remy/thesis, Odersky-Sulzmann-Wehr@tpos, Pottier-Remy/emlti} all
follow this strategy, to the best of our knowledge.\relax
\footnote {See \cref{sec:related-work} for a closer comparison with
\cite* {Pottier-Remy/emlti}.}
However, this state of affairs is not a necessity.



To efficiently achieve omnidirectional type inference for fragile \ML
extensions:
\begin{enumerate}

\item
  We introduce \emph{suspended match constraints} as a way to suspend
  ambiguity resolution until sufficient information has been found from the
  context so that they can be discharged.

\item
  We work with \emph{partial types schemes}, \ie with the ability to
  instantiate type
  schemes that are not yet fully determined and consequently revisit their
  instances when they are being refined, incrementally. This allows
  inferring parts of a \texttt{let}-body to disambiguate its definition,
  without duplicating constraint-solving work.

\end{enumerate}

These technical devices are introduced once and for all---in a general
framework of constraint-based type inference. Each fragile \ML construct can
then be implemented by suspended constraints that expand to its robust
counterpart once the annotation has been inferred. This generality comes at
a cost, which is that everything is hard:
\begin{enumerate}

\item
  Giving an adequate semantics for suspended constraints is hard, as we
  must capture declaratively the intuition that some type information must be
  \emph{known} rather than \emph{guessed}.

\item

  Implementing partial types schemes efficiently is equally hard, as it
    requires triggering re-instantiations upon refinements to the scheme, while
    avoiding redundant constraint solving across instantiations.

\end{enumerate}
In return, the techniques we developed for the semantics
also help provide declarative typing rules for each fragile
construct, for which the generated constraints are correct and
complete.

\paragraph{Illustrative examples}

Examples \code{ex_2} to \code{ex_4} are all typable with omnidirectional
inference, as indicated by the green traffic light labeled \OML---the
calculus formalized in this paper.

%
In contrast, both bidirectional and \Geninst-directional inference
rely on specifications that include choices that are subjective
and somewhat arbitrary. As a result, they reject programs
that have a unique well-typed solution. We now turn to
further examples that illustrate such failures:
%
\locallabelreset
%
\begin{program}[input,check]
let ex_6 r = (r.x, r.y)                          	   °\ocamlflags 10°
let ex_7 r = let x = r.x in x + r.y              	   °\ocamlflags 10°
let ex_8 = let getx r = r.x in getx one                    °\ocamlflags 10°
let ex_9 r = (r.x : bool)                        	   °\ocamlflags 11°
let ex_1_0 r = r.x.x                              	   °\ocamlflags 11°
\end{program}
All are arguably unambiguous; \OCaml accepts none of them, \OML accepts the
first three.

In \ocaml{ex_6}, \ocaml{r} can only be of type \ocaml{'a one}. Indeed,
considering the second projection first, we should learn that
\ocaml{r} is of type \ocaml{'a one} and since it is $\lambda$-bound, this
should then make the first projection unambiguous. Disambiguating this
example is a matter of solving the typing constraints in the right order.
%
A similar failure occurs in \ocaml{ex_7}, where the type of the
$\lambda$-bound variable \code{r} is initially ambiguous and
unknown. It is only upon typing the projection \code{r.y} that
\code{r} is forced to have the type \ocaml{'a one}; this requires
inferring the $\Let$-body to disambiguate the $\Let$-definition.
%
In \code{ex_8}, disambiguation information flows from an instance back
to the definition, opposite to the \Geninst-order; we call this
\emph{backpropagation}.

The example \ocaml{ex_9} can be disambiguated from the return type of
the projection, rather than from the type of \code{r}. The typing rules for
records that we present in this work restrict disambiguation to the
record type alone, and thus rejects this example. Alternative typing rules
using omnidirectional type inference could support this example as
well.
\TODO{Point to discussion in future work.}

Finally, \ocaml{ex_1_0} is an example where none of the field
projections has enough type information to be disambiguated on its own, but the
constraints they impose can be combined to deduce that the type of
\ocaml{r} must be \ocaml{one}, as the \code{x} field of \code{two}
does not have a record type. This lies outside the framework of
omnidirectional type inference, in which suspended constraints must be
discharged one by one in some order, independently of other
still-suspended constraints.
%
We believe that this restriction is necessary for effective type inference,
since the complexity of general overloading without this restriction is
NP-hard, even in the absence of let-polymorphism, as shown by an encoding of
3-SAT problem by~\citet*
{Chargueraud-Bodin-Dunfield-Riboulet/jfla2025}.

\subsubsection* {Plan}

The paper is organized as follows:
\begin{enumerate*}[label={}]

\item
  In \cref{sec:constraints}, we give an overview of suspended constraints
  and their application to three extensions for \ML of various kinds.

\item
  In \cref{sec:semantics}, we describe suspended match constraints and their semantics.

\item
  In \cref{sec:language}, we define \OML, an extension of \ML featuring
  static overloading of record labels, overloaded tuple projections, and
  semi-explicit first-class polymorphism. We sketch its typing rules and
  state the theorems of soundness and completeness for constraint
  generation, as well as principality.
  \Long {By lack of space, detailed typing
  rules and constraint generation are postponed to \cref {app/oml}.}{}

\item
  In \cref{sec:solving}, we provide a formal definition of our constraint
  solver as a series of non-deterministic rewriting rules and state the main
  theorems for correctness.

\item
  In \cref{sec:implementation}, we describe an efficient implementation
    of suspended constraints and partial type schemes.

\item
  In \cref{sec:related-work}, we compare with related work,
  and in \cref{sec:future-work}, we conclude with a discussion of future work,
  including prototyped extensions whose theory is less clear.

\end{enumerate*}
\Long
  {Appendix \cref{appendix:figures} contains a complete technical reference,
  collecting key definitions and figures for convenient lookup. All proofs
  are postponed to appendices.}  {By lack of space, detailed typing rules,
  constraint generation, and all proofs are postponed to \cref {app/oml}.}

\subsubsection* {Our contributions}

Our contributions are:
\begin{enumerate*}
\item
  A novel \emph{omnidirectional} type inference framework for
  extensions of \ML with advanced features, based on two new devices,
  suspended constraints and partial type schemes;

\item A declarative semantics of suspended constraints that captures the
  idea that they wait on information that must be propagated from the
  context, not \emph{guessed}.

  This includes, in particular, a new declarative characterization of
  \emph{known} type information.

\item
  A complete yet efficient constraint-solving type inference algorithm.

\item
  Three instantiation of our framework that give new declarative type
  systems and their implementation using suspended constraints for tuple
  projection in the style of \SML, static overloading of record fields and
  datatype constructors, and for semi-explicit first-class polymorphism.

\end{enumerate*}

\TODO{Move 1.1 to 2. Rename section title to include discussion on \ML extensions}
\section{Suspended constraints: an overview}
\label{sec:constraints}

\XDR{I changed the syntax of explicit record projection to $\exfield \e
\elab \T$ to make it looked like qualified labels, labels prefixed with
their type. I think this is more intuitive and make it look like qualified
records. This is macroified and can then be easily undone. (Tuple
and record projections should not share their macros)}

\begin{bnffig}[t]%
  {fig:constraint-syntax}%
  {Syntax of types and constraints.}
\entryset[Type variables]{\tva, \tvb, \tvc}{\TyVars}{}
\\
%% \entryset[Types]{\t}{\Types}\\
\entry[Types]{\t}{
    \tv \and
    \tunit \and
    \ta \to \tb \color{gray} \and
    \Pi\iton \ti \and
    \T \tys \and
    \tpoly \ts\
}\\
\entry[Type schemes]{\ts}{
    \t \and
    \all \tv \ts
}\\[1ex]
\entry[Constraints]{\c}{
        \ctrue
  \and  \cfalse
  \and  \ca \cand \cb
  \and  \cexists \tv \c
  \and 	\cfor \tv \c
  \and  \cunif \ta \tb
  \nextline
  \and  \clet \x \tv \ca \cb
  \and  \capp \x \t
  %% \nextline
  \and  \cmatch \t \cbrs
}\\[1ex]
\entry[Branches]{\cbr}{\cbranch \cpat \c} \\
\entry[Patterns]{\cpat}{}{} \\[1ex]
\entry[Constraint contexts]{\C}{
  \square
  \and \C \cand \c
  \and \c \cand \C
  \and \cexists \tv \C
  \and \cfor \tv \C
  \nextline
  \and \clet \x \tv \C \c
  \and \clet \x \tv \c \C
} \\
\entry[Shapes] {\Sh} {} {}
\\
\entry[Canonical principal shapes] {\sh} {} {}
\end{bnffig}

\parcomment{Syntax!}

The syntax of types and constraints is given
in~\Cref{fig:constraint-syntax}. Monotypes (or just types) include, as
usual, type variables $\tv$, the unit type $\tunit$, arrow types, but
also\footnote{These are grayed, as they which will be introduced in the
following subsections.}  structural tuples $\Pi\iton \ti$, nominal
types\footnote {Type constructors are prefixed, except in \OCaml code, where
they are postfixed.}  $\T \tys$, and polytypes $\tpoly \ts$.  Type schemes
$\ts$ are of the form $\all \tvs \t$, they are equal up to the reordering of
binders and removal of useless variables. We write $\TyVars$ the set of type variables.

Building atop the constraint-based type inference framework of
\citet*{Pottier-Remy/emlti}, we adopt a constraint language that includes both
term and type variables.
%
The language (in \cref{fig:constraint-syntax}) contains tautological ($\ctrue$) and
unsatisfiable ($\cfalse$) constraints, conjunctions
($\ca \cand \cb$). The constraint form $(\cexists \tv \c)$ binds an
existentially quantified type variable $\tv$ in $\c$, while the
constraint $(\cfor \tv \c)$ binds $\tv$ universally. The constraint form
$(\cunif \ta \tb)$ asserts that the types $\ta$ and $\tb$ are
equal.
%
When $\ts$ is a polymorphic type scheme $\tfor \tvs \tp$, we use the
notation $(\cleq \ts \t)$ as syntactic sugar for the instantiation
constraint $\cexists \tvs \cunif \tp \t$.

\parcomment{Constraint abstractions}

Two constructs deal with the introduction and elimination of
constraint abstractions. A constraint abstraction $\cabs \tv \c$ can
simply be seen as a function which when applied to some type $\t$
returns $\c \where {\tv \is \t}$. Constraint abstractions are
introduced by a let construct $(\clet \x \tv \ca \cb)$ which binds
the constraint abstraction to the term variable $\x$ in
$\cb$---additionally ensuring the abstraction is satisfiable. They
are eliminated using the application constraint $(\capp \x \t)$ which
applies the type $\t$ to the abstraction constraint bound to $x$.

\parcomment {Suspended match constraints}

Finally, we introduce \textit{suspended match constraints} $(\cmatch \t \cbrs)$.
%% \footnote
%% {Previously dubbed `frozen constraints'.
%% %in \citep{TODO} % this would be a de-anonymizing citation, silence it for now
%% }
These constraints are \emph{suspended} until
the \textit{shape} of $\t$, such as its top-level constructor,
is known. Then they are \emph{discharged}: a unique branch is selected
and its associated constraint has to be solved. A match constraint
that is never discharged is considered unsatisfiable.

More precisely:
\begin{enumerate*}

\item
  The matchee $\t$ is a type. The constraint remains suspended
  while $\t$ is a type variable, that is,
  until the shape of $\t$ is determined.

\item
  $\cbrs$ is a list of branches of the form $\cbranch \cpat \c$,
  where $\cpat$ is a shape pattern. For example, the pattern
  $\tva \to \tvb$ matches function types, binding its domain and
  codomain to $\tva$ and $\tvb$, respectively. The constraint $\c$
  is then solved in the extended context.
  %
  To ensure determinism, the set of patterns $\bar \cpat$ must be
  \emph{disjoint}---that is, no shape may be matched by more
  than one pattern in the list.

\end{enumerate*}

We keep the grammar of shapes and patterns abstract in this section,
to explain the general framework of suspended constraints. For now, it suffices to
think of shapes as top-level constructors like function arrows $\cdot \to \cdot$.
This will be made more precise in \cref{sec:semantics}.

\parcomment {Constraint contexts}

Throughout this paper, we will find it convenient to work with
\emph{constraint contexts}. A constraint context is simply a constraint with
a \emph{hole}, analogous to evaluation contexts $\E$ used extensively in
operational semantics. We write $\C\where{\c}$ to denote filling the hole of
the context $\C$ with the constraint $\c$. Hole filling may capture
variables, so we frequently require explicit side conditions when
variable capture must be avoided. We write $\bvs \C$ for the set of
variables bound at the hole in $\C$.

\paragraph{Suspended constraints in action}

The remainder of this section illustrates the role of suspended constraints
in supporting \emph{fragile} language features as defined above.
In particular:
\begin{enumerate}

\item[(\cref{sec/constraints/polytypes})]
   Semi-explicit first-class polymorphism;

\item[(\cref{sec:constraints:overloading})]
   Constructor and record label overloading for nominal algebraic datatypes;

\item[(\cref{sec:constraints:tuples})]
  Overloaded tuple projection in the style of \SML.

\end{enumerate}
We demonstrate how the typability of each of these features can be elaborated
into constraints, formalized using a constraint generation function of the
form $\cinfer \e \tv$, which, given a term $e$ and expected type $\tv$,
produces a constraint $\c$ which is satisfiable if and only if $\e$ is
well-typed.
%

\parcomment{Why our solution makes things easier?}

As we will see, once we adopt the suspended constraint machinery developed in
this paper, much of the complexity of these typing fragile constructs
vanishes---suspended constraints do most of the heavy lifting.

\subsection{Semi-explicit first-class polymorphism}
\label {sec/constraints/polytypes}

\parcomment {Why semi-explicit first-class poly is used?}

Semi-explicit first-class polymorphism \citep*{Garrigue-Remy/poly-ml} brings
some System $\F$-like expressiveness to $\ML$ by allowing impredicative,
first-class polymorphism while preserving principal type inference. It has
since been adopted by \OCaml, notably for polymorphic object methods.

\parcomment {Intro (and annotations)}

The type constructor $\tapoly \ts \av$ boxes a polymorphic type scheme
$\ts$, turning it into a \textit{polytype} annotated with the \emph{annotation
variable} $\av$.  Once boxed, the polytype $\tapoly \ts \av$ is considered
a monotype, thereby enabling impredicative polymorphism.
Annotation variables record the origins of polytypes and may themselves
be generalized, yielding type schemes such as $\tfor
\av {\tapoly \ts \av}$. When $\av$ is generalized, the polytype is considered \emph{known},
rather than still being inferred---this distinction is precisely the purpose of annotation
variables, and it captures \geninst-directionality explicitly.

\parcomment {Boxing}

The introduction form for polytypes is a boxing operator $\expoly
\e \tvs \ts$ with an explicit polytype annotation $\exi \tvs \ts$
where the $\tvs$ are all the type variables that are free in
$\ts$.
%
The resulting expression has type $\tapoly {\ts \where {\tvs \is \tys}} \av$
where $\av$ is an arbitrary (typically fresh) annotation variable and $\tys$
are arbitrary types that replace the free variables $\tvs$.
The annotation variable $\av$ can thus be generalized.  That is $\expoly \e
\tvs \ts$ can also be assigned the type scheme $\all \av {\tapoly {\ts
\where {\tvs \is \tys}} \av}$.

\parcomment {Unboxing (principality restriction and \geninst-directionality)}

Conversely, to instantiate a polytype expression, one must use an explicit
unboxing operator $\einst \e$, which requires no accompanying type
annotation. However, the operator requires $\e$ to have a polytype scheme of
the form $\tfor \av {\tapoly \ts \av}$ and then assigns $\einst \e$ a type
$\t$ that is an instance of $\ts$. If, by contrast, $\e$ has the type
$\tapoly \ts \av$ for some non-generalizable annotation variable $\av$, then
$\e$ is considered of a not-yet-known polytype, and therefore $\einst \e$ is
ill-typed.

\parcomment {Example ill-typed term}

For example, the expression $\efun \x {\einst \x}$ is not
typable. Indeed, the $\lambda$-bound variable $\x$ is assigned
a monotype. The only admissible type for $\x$ is $x : \tapoly \ts \av$
for some $\ts$ and $\av$.  Since $\av$ is bound in the surrounding
context at the point of typing $\einst \x$, it cannot be generalized
prior to unboxing, rendering the term ill-typed.

\parcomment {Annotations}

However, type annotations can be used to freshen annotation variables.
We usually omit annotation variables in annotations, since we can
implicitly introduce fresh ones in their place. For example,
$\efun {\x : \tapoly \ts {}} {\einst \x}$---which is syntactic sugar
for $\efun \x {\elet \x {(\x : \tapoly \ts {})} {\einst \x}}$---is
well-typed because the explicit annotation introduces a fresh
variable annotation $\ava$, which can then be generalized, yielding
$\tfor \ava {\tapoly \ts \ava}$.

\parcomment {Shortcomings of annotation variables}

This behavior can be counter-intuitive: type information that has
just been inferred must still be considered as yet-unknown until its
generalization. It also makes the system sensitive to the placement of type annotations, an
artifact of the fixed directionality of generalization in \geninst-directional
inference. For instance, the following two terms differ only in the position of
the annotation, yet only the one on the left-hand side is well-typed.
\begin{mathpar}
 \efun f {\eapp {\einst {(f : \tpoly {\tfor \tv {\tv \to \tv}})}} f}

\efun f {\eapp {\einst f} {(f : \tpoly {\tfor \tv {\tv \to \tv}})}}
\end{mathpar}
The difference lies in how generalization and annotation variables interact.
In the first term, the annotation occurs in an unboxing operator introducing
fresh annotation variables and may therefore be generalized to the type
scheme $\tfor \av {\tapoly {\tfor \tv {\tv \to \tv}} \av}$, enabling
unboxing to proceed. Whereas the second term applies the annotation to the
argument $f$, which fixes $f$'s type to the monotype $\tapoly {\tfor \tv
{\tv \to \tv}} \ava$ for some fresh annotation variable $\ava$. Because this
type is assigned to $f$ at its binding site, $\ava$ is bound in the context
when typing $\einst f$ and cannot be generalized, so the second term is
ill-typed despite the annotation.

\parcomment {Suspended match constraints fixes this}

Suspended match constraints eliminate this sensitivity to directionality
when typechecking $\einst e$. If $\e$ is already known to have the type
$[\ts]$, then we can simply
instantiate it.  However, if the type of $\e$ is not yet known---\ie  it is a
(possibly constrained) type variable $\tv$---then we must defer until more
information is available. We capture this behavior with a suspended match
constraint:
\begin{mathpar}
\cinfer {\einst \e} \tva \Wide\eqdef
    \cexists \tvb \cinfer \e \tvb
\cand
    \cmatch  \tvb {\parens {\cbranch {\tpoly s} s \leq \tva}}
\end{mathpar}
The match constraint is suspended until $\tvb$ is resolved to a polytype
$\tpoly \ts$ matching the pattern $\tpoly s$, which binds the type scheme
$\ts$ to the scheme variable $s$. The selected branch then performs the
instantiation $\cleq s \tva$, that is $\cleq \ts \tva$.
%
% If $\tvb$ is already known to be a polytype, the constraint discharges
% immediately and behaves like a standard instantiation constraint $\cleq \ts
% \tva$.
%
By waiting for the type of $e$ to be \emph{known}, we ensure principal types
without annotation variables.

\subsection{Static overloading of constructors and record labels}
\label{sec:constraints:overloading}

% What do we mean by static overloading?

\emph{Static overloading} denotes a form of overloading in which resolution is
performed entirely at compile time, enabling the compiler to select a unique
implementation without relying on runtime information---in contrast to
\emph{dynamic overloading}, which defers resolution to runtime via
mechanisms such as dictionary-passing or dynamic dispatch.

\parcomment {Other languages}

Many languages offer statically resolved overloading to avoid the overhead
of dynamic dispatch. C++ and Java resolve overloaded functions through
compile-time specialization based on argument types. Conversely, languages
like Rust and Haskell primarily employ dynamic overloading via traits and
type classes, respectively, which can incur runtime overhead unless
optimized away by monomorphization and aggressive inlining.

\parcomment {\OCaml and \OCaml's approach (PI-directionality)}

As noted in the introduction, \OCaml supports a limited yet useful form of
static overloading for record labels and datatype constructors. When
encountering overloaded labels or constructors, \OCaml resolves ambiguity
using local type information, guided by \geninst-directional
inference. Nominal types $\Tapp \tys$ carry annotation variables $\av$,
written $\Tapp^\av \tys$. As discussed in \cref{sec/constraints/polytypes},
this mechanism allows one to deduce that types polymorphic over their
annotation variable $\tfor \av {\Tapp^\av \tys}$ are \emph{known}.

\parcomment {A note on bidirectional expected type propagation}

Because static overloading involves more intricate flows of information than
polytype inference, \OCaml supplements \geninst-directionality with a limited,
ad-hoc form of bidirectional type inference. This mechanism is folklore; no
formal account has been given.

\parcomment {Closed-world reasoning and default rules}


Beyond propagation, \OCaml also exploits \emph{closed-world reasoning} to
resolve ambiguities in record types. For instance:
\begin{program}[input,check]
let ex_1_1 = {x = 42; z = 1337} °\ocamlflags 00°
\end{program}
Here, \code{x} and \code{y} appear together only in the type \code{two},
allowing the type checker to unambiguously infer the type of \ocaml{e$_{11}$} as
\code{two}.
%
If local type information and closed-world reasoning are insufficient,
\OCaml falls back to a syntactic default: it selects the most recently
defined compatible type. For example, \OCaml accepts the following
expression, when \smashcolorbox{warning}{warnings} are not turned
into \smashcolorbox{illtyped}{errors}:\cref{fn/principal}
\begin{program}[input,check=true]
let getx r = r.x                                      °\ocamlflags 21°
\end{program}
The expression is compatible with both \code{one} and \code{two},
since each defines a field \code{x}. But \code{two} is chosen simply
because it appears later in the source.
We do not treat this behavior as principal; accordingly, we provide
no formalization of such ``default'' rules, though their implementation is
discussed further in \cref{sec:discussion}.
%
This fallback mechanism highlights the directionality of \OCaml inference.
Once the compiler selects a type, it commits to it---even if that choice
causes errors downstream. Consider \code{ex_7} from \cref{sec/introduction}:
\begin{program}[input,check=true]
let ex_7 r = let x = r.x in x + r.y                    °\ocamlflags 10°
\end{program}
Here, \OCaml defaults to \code{two}\footnote {While warning the user that
this default choice is ambiguous.} for \code{r} when typing \code{r.x} , but
then fails to type \code{r.y}, as this default choice is fixed---even
though
\code{one} would have satisfied both projections.

\parcomment {Record field disambiguation in suspended constraints}

We assume a global typing environment $\labenv$ mapping labels to type schemes,
written $\elab : \tlab [\tvs]{{\Tapp \tvs}}{\t} \in \labenv$ where $\tlab
[\tvs]{{\Tapp \tvs}}{\t}$ is the type of the projection on label $\elab$ from a
record of type $\t$. A given label $\elab$ may be defined several times in
$\labenv$, but at most once at a given record type~$\T$. We write
$\labenv(\labfrom \elab \T)$ for the type scheme of $\elab$ in $\T$ when it
exists.

We propose an alternative account of static overloading using suspended
match constraints.  For example, in the case of an ambiguous record
projection $\efield \e \elab$, we generate the typing constraint:
\begin{mathpar}
\cinfer {\efield \e \elab} \tva \wide\eqdef
  \cexists \tvb \cinfer \e \tvb
  \cand
  \cmatch \tvb
      {\cbranch {\cpatrcd \ct}
	{\parens {\labenv(\labfrom \elab \ct) \leq \tva \to \tvb}}
      }
\end{mathpar}
This constraint suspends resolution of the return type $\alpha$ until the
record type $\tvb$ of $\e$ is known. Its branch matches against the nominal
type pattern $\cpatrcd t$, binding the type constructor name to~$t$. Using
this, the appropriate type scheme for $\elab$ is retrieved from
$\labenv(\elab/t)$, instantiated, and the resulting constraints are imposed
on the domain and codomain of the field-access type.

\parcomment{Suspended constraints are better}

\OCaml programs that do not use the default rule are accepted by this
approach. Certain expressions, such as \code{e}$_{12}$ are well-typed under
our account but rejected by \OCaml's current type checker.

\parcomment {Constructor disambiguation in suspended constraints}

Our approach also applies to overloaded datatype constructors. Since
the formal treatment is analogous to that of record fields, we focus only
on fields in this work. However, our prototype implementation of \OML
supports both.

\subsection{Tuple projections \`a la \SML}
\label{sec:constraints:tuples}

\SML supports positional projections from tuples using expressions of the form
\ocaml{#$j$ e} to extract the $j$-th component of the tuple \code{e}.
%
Internally, tuples in \SML are treated as structural records with numeric
labels, so \ocaml{(#$j$ e)} desugars into a structural record field access
\ocaml{e.$j$}: if $\e$ has the type $\tsrecord {j = \tj; \varrho}$, where
$\varrho$ is a row describing the remaining tuple fields, then $\eproj \e j$
has type $\tj$.

\SML enforces an additional restriction: the tail $\varrho$ must be
fully determined (\ie it cannot be a polymorphic row variable).  This
ensures that the arity of the tuple is \emph{known} statically from
the surrounding context, thereby avoiding the need for row
polymorphism. However, this restriction is not expressed in the typing
rules themselves, but is specified operationally as part of the
type inference process.

\parcomment {Tuple projection is statically overloaded}

From a typing perspective, tuple projection in \SML behaves like a form
of static overloading: the expression $\eproj \e j$ is valid only when $\e$ is
known to be an $n$-ary tuple for some fixed $n \geq j$.

\parcomment {We can precisely specify this with suspended constraints}

We can capture the typing of tuple projections precisely using suspended
constraints. For the projection $\eproj \e j$, we generate the following
constraint:
\begin{mathpar}
  \cinfer {\eproj \e j } \tv \wide\eqdef
  \cexists \tvb
    \cinfer \e \tvb
    \cand \cmatch \tvb {\cbranch {\cpatprod \tvc j} {\cunif \tva \tvc}}
\end{mathpar}
\parcomment{Tuple patterns}
The suspended constraint $(\cmatch \tvb {\cbranch {\cpatprod \tvc j} {\cunif
\tva \tvc}})$ blocks until the shape of $\e$ ($\tvb$) is known to be a tuple
of sufficient arity. The pattern $\cpatprod
\tvc j$ matches only tuple types $\tProd \ti$, where $n \geq j$, binding the
$j$-th component to $\tvc$, which is then unified with the expected result type
$\tva$.

\paragraph{Comparison to \SML}

Our understanding is that \SML typecheckers implement row-polymorphic records
under the hood, but they never generalize row variables, rejecting any
declaration that leaves a row variable undetermined. This is a neat approach,
and we conjecture that it accepts the same programs as our implementation of
overloaded tuples using suspended constraints. On the other hand, it only works
for structural types. It cannot be applied to disambiguate between
nominal records or variants that share field or constructor names, particularly
when some field projections or constructors need non-uniform typing rules,
such polymorphic fields or GADT constructors.

%% BEWARE: Can only be located as the top of a page---otherwise  it would be
%% misplaced
\begin{mathparfig}[t]%
  {fig:constraint-semantics}%
  {Semantics of constraints (without suspended constraints).}
  \begin{bnfgrammar}
     \entry[Semantic environments]{\semenv}
     {\emptyset \and \semenv\where{\tv \is \gt} \and
      \semenv\where{\x \is \gabs}}
   \end{bnfgrammar}
   \par
  \infer[True]
    { }
    {\semenv \th \ctrue}

  \infer[Conj]
    {\semenv \th \ca \\
     \semenv \th \cb}
    {\semenv \th \ca \cand \cb}

  \infer[Exists]
    {\semenv\where{\tv \is \gt} \th \c}
    {\semenv \th \cexists \tv \c}

  \infer[Forall]
    {\forall \gt, ~ \semenv\where{\tv \is \gt} \th \c}
    {\semenv \th \tfor \tv \c}

  \infer[Unif]
    {\semenv(\ta) = \semenv(\tb)}
    {\semenv \th \cunif \ta \tb}

  \infer[Let]
    {\semenv \th \exists \tv. \ca \\
     \semenv\where{\x \is \semenv(\cabs \tv \ca)} \th \cb}
    {\semenv \th \clet \x \tv \ca \cb}

  \infer[App]
    {\semenv(\t) \in \semenv(\x)}
    {\semenv \th \capp x \t}

  \let \Eqdef\eqdef \def \eqdef {&\Eqdef&}
  \begin{tabular}[c]{.R.C;.L.}
  %%\semenv &::=&
  %%  \emptyset \mid
  %%  \semenv\where{\tv \is \gt} \mid
  %%  \semenv\where{\x \is \gabs}
  %%\\
  \semenv(\cabs \tv \c) \eqdef
    \set {\gt \in \Ground : \semenv\where{\tv \is \gt} \th \c}
  \\
  \ca \centails \cb \eqdef
    \forall \semenv,\ \semenv \th \ca \implies \semenv \th \cb
  \\
  \ca \cequiv \cb   \eqdef
    (\ca \centails \cb) \wide\wedge   (\ca \centails \cb)
  %% \forall \semenv,\ \semenv \th \ca \iff \semenv \th \cb
  \end{tabular}
\end{mathparfig}

\section{Semantics of constraints}
\label{sec:semantics}

To implement a typechecker using constraint-based type inference, it
suffices to generate constraints from terms and to solve them. To study the
meta-theory of this approach, we follow the standard
approach of assigning a \emph{semantics} for our constraints---as declaratively as
possible. The existence of well-defined declarative semantics provides
a foundation for reasoning about correctness and validates the design of the
constraint language.


In our work on suspended constraints, defining a satisfying semantics was the
most challenging aspect. The key difficulty lies in capturing what it means for
type information to be \emph{known}. Our semantics is declarative, but not
syntax-directed unlike the standard constraint semantics of
\citet*{Pottier-Remy/emlti}. This lack of syntax-directness complicates
reasoning and proofs. On the upside, the semantics directly
  suggest declarative typing rules for the surface language.

\parcomment {Judgment shape}

The semantics of constraints follows the standard form of
a satisfiability judgment $\semenv \th \c$. The semantic environment
$\semenv$ contains a ground assignment for each free variable of $\c$
(type and term variable), and $\semenv \th \c$ states that these
assignments indeed satisfy $\c$. Let us write $\Ground$ for the set of
\emph{ground} types, types without free variables\footnote{Ground
  types are thus finite trees, assuming the existence
%
of some base types such as $\tint$. In \cref{sec/rec-types}, we
discuss the alternative choice of regular trees for the set of ground
types that models equirecursive types.}. $\semenv$ maps each type
variable $\tv$ to a ground types $\gt \in \Ground$, and each term
variable $x$ to sets of ground types $\gabs \subseteq \Ground$
(the set of ground instances of a type scheme for $\x$).
%
We write $\semenv\where{\tv \is \gt}$ and $\semenv\where{\x \is \gabs}$ for
the extension of $\semenv$ with a new binding. For a type $\t$, we write
$\semenv(\t)$ for the ground type obtained by substitution.

\parcomment {Definition exampled}

The judgment is defined in \cref{fig:constraint-semantics} for all
constraint formers except suspended constraints; its definition on
this fragment is standard and somewhat tautological. The constraint
$\ctrue$ is satisfied by any environment, and $\cfalse$ by none. An
environment $\semenv$ satisfies $\ca \cand \cb$ if it satisfies both
$\ca$ and $\cb$. Satisfying $\cexists \tv \c$ requires finding
a witness $\gt$ for $\tv$.  The universal constraint $\cfor \tv \c$ is
satisfiable if $\c$ is satisfiable for any binding of $\tv$. The
unification constraint $\cunif \ta \tb$ is satisfied when
$\semenv(\ta)$ and $\semenv(\tb)$ are equal.

The rule for $\clet \x \tv \ca \cb$ states that $\ca$ must satisfied under
\emph{some} instantiation of its bound variable, and that $\cb$ must be
satisfiable when $\x$ is bound to $\cabs \tv \ca$, or rather to its semantic
interpretation as a set of ground types.

An application constraint $\capp \x \t$ is interpreted by checking that $\t$
belongs to the set of types mapped to $\x$ in $\semenv$, that is, $\semenv(\t)
\in \semenv(\x)$. Note that when $\semenv(\x)$ is of the form
$\semenvp(\cabs \tv \c)$, where $\semenvp$ is the environment at the binding
site of $\x$, then $\semenv(\t) \in \semenv(x)$ holds iff
$\semenvp\where{\tv \is \semenv(\t)} \th \c$, which corresponds to the
intuition that the application $\capp {(\cabs \tv \c)} \t$ should be
equivalent to $\c \where {\tv \is \t}$.


\begin{wraphbox}{0.2}{0.6}
\begin{mathpar}[inline]
\infer*[right=Exists]
    {\infer*[Right=Unif]
      {\infer*{}{\tint = \tint}}
      {\semenv\where{\tv \is \tint} \th \cunif \tv \tint}}
  {\semenv \th \cexists \tv \cunif \tv \tint}
\end{mathpar}
\end{wraphbox}
Closed constraints are either satisfiable in any semantic environment (\ie
they are tautologies) or unsatisfiable. For example, the satisfiability of
the constraint $\cexists \tv {\cunif \tv \tint}$ is established by the
derivation on the right-hand side.


% Equivalence and entailment

We write $\ca \centails \cb$ to express that $\ca$ \emph{entails} $\cb$,
meaning every solution $\semenv$ to $\ca$ is also a solution to $\cb$.
We write $\ca \cequiv \cb$ to indicate that $\ca$ and $\cb$ are equivalent,
that is, they have exactly the same set of solutions.

\subsection{Shapes
\label{sec/shapes}}

\parcomment {Why shapes?}

We introduce \emph{shapes} as a generalization of type constructors for
suspended match constraints. They provide a uniform treatment of both
constructors and polytypes, and are useful in defining polytype
unification (\Cref{sec:implementation}).

\parcomment {Definition of shape}

A shape $\Sh$ is a type with holes, written $\any \tvcs \t$, where $\tvcs$
denotes the set of type variables representing the holes.  By construction,
we require $\tvcs$ to be \emph{exactly} the free variables of $\t$.  Hence,
shapes are closed and do not contain useless binders.  We consider shapes up
to $\alpha$-conversion.  When $\t$ is a ground type, we omit the binder and
write simply $\t$.
%
We write $\bot$ for the shape $\any \tvc \tvc$, which we call the
\emph{trivial} shape. We write $\Shapesz$ the
set of non-trivial shapes.
%% and use letter $\Sh$ to range
%% over non trivial shapes.

\begin{wraphbox}{}{}
\begin{mathpar}[inline]
  \infer[Inst-Shape]
    {\tvcs_2 \disjoint \any {\tvcs_1} \t}
    {\any {\tvcs_1} \t \preceq
     \any {\tvcs_2} \t \where {\tvcs_1 \is \tys_1}}
\end{mathpar}
\end{wraphbox}
Shapes are equipped with the standard instantiation ordering,
defined by \Rule{Inst-Shape}.
%
When writing $\Sh \preceq \Shp$, we say that $\Sh$ is more general than
$\Shp$. When $\Sh$ and $\Shp$ are more general than one another, they are
actually equal. The trivial shape $\bot$ is the most general shape.
%
If $\Sh$ is $\any \tvcs \t$, the shape application $\shapp[\Sh] \tys$ is
defined as $\t \where {\tvcs \is \tys}$. We say that $\Sh$ is a shape of
$\t$ when there exists $\tys$ such that $\t = \shapp[\Sh] \tys$; in this
case we write that the pair $(\Sh, \tys)$ is a decomposition of $\t$.

\begin{definition}
A non-trivial shape $\Sh \in \Shapesz$ is the principal shape of the type
$\t$ iff:
\begin{enumerate}
  \item
    $\exists \typs,\ \t = \shapp[\Sh] \typs$
  \item
    $\forall \Shp \in \Shapesz, \forall \typs,\ \t = \shapp[\Shp] \typs
    \implies \Sh \preceq \Shp$
\end{enumerate}
\end{definition}

\begin{restatable}[Principal shapes]{theorem}{principalShapes}
  \label{thm:principal-shapes}
Any non-variable type $\t$ has a non-trivial principal shape $\Sh$.
\end{restatable}

There is an equivalent direct description of principal shapes
$\sh$. They are precisely the shapes $\any \tvcs \t$ satisfying two conditions:
\begin{enumerate*}
  \item
    $\tvcs$ must be linear in $\t$ \ie each variable $\tvc$ in $\tvcs$
    occurs exactly once in $\t$.

  \item
    The type $\t$ must be shallow, meaning that its structure is limited in
    the following way.  When $\t$ is not a polytype, all of its subterms must
    be variables. Shapes of this form are $\tunit$, $\tvca \to \tvcb$, and
    $\tProd \tvci$, or $\T \tvcs$.
    When $\t$ is a polytype $\tpoly {\all \tvs \tsp}$, the only subterms
    of $\tsp$ that do not contain one of the polymorphic variables $\tvs$ must be variables in $\tvcs$.
\end{enumerate*}

\parcomment {Define canonical shape}

A principal shape $\any \tvcs \t$ is \emph{canonical} if its free variables
appear in the sequence $\tvcs$ in the order in which they occur in $\t$.  We
write $\sh$ for canonical principal shapes.
%
Each non-variable type $\t$ has a unique canonical principal shape, which we
write $\shape \t$. For example, $\shape {\Tapp \tys}$
is $(\any \tvcs \Tapp \tvcs)$.

\parcomment {Polytypes are constructors}

Polytypes are particularly interesting in this setting because they can be
decomposed into shapes and treated analogously to type constructors.
\begingroup
\newcommand {\tsh}[1]%
  {\def \tsi {\all \tvb {{\parens{\tvb \to #1}}} \tprod \tvb}
  \tpoly {\all \tva {\parens {\tpoly \tsi} \to \tva} \to \tva}}%
For instance, the polytype $\tsh {\tint \tlist}$ has the principal
shape $\sh \is \any \tvc {\tsh \tvc}$. The original polytype can thus
be represented as the shape application $\shapp (\tint \tlist)$.
\endgroup

\subsection{Suspended constraints}

We have left the syntax of shape patterns deliberately abstract.
\XDR{Shape patterns are never defined! in the body of the paper.
What aren't shape patterns just a subset of principal shapes?}
\Xalistair{Because principal shapes cannot express $\cpatpoly \cscm$ or $\cpatrcd \ct$. They lack
binders.}
\XDR{We should say so---and also define them.}
\TODO{Add figure and reference here. Doesn't need prose explanation.}
We also assume a matching relation:
% mathpar instead of mathline since spacing was odd. If spacing is fixed,
% use mathline
\begin{mathpar}
  \cmatches \cpat \sh \tvcs \theta
\end{mathpar}
This partial function matches a pattern $\cpat$ against a principal
shape $\sh$ opened with shape names $\tvcs$ (which must have the same
arity as $\sh$), yielding a substitution $\theta$. The substitution
binds the pattern variables to shape components, that may contain
occurrences of the shape variables $\tvcs$.
%
For our examples we define the trivial pattern $\cpatwild$ which matches
any shape and binds nothing:
\begin{mathpar}
  \cmatches[\eqdef] \cpatwild \sh \tvcs \eset
\end{mathpar}

\begin{definition}[Discharged match constraint]
  Given a suspended constraint $(\cmatch \t \cbrs)$ and a canonical shape
  $\sh$, we introduce the syntactic sugar $(\cmatched \t \sh \cbrs)$ for the
  \emph{discharged match constraint} that selects the branch in $\cbrs$ that
  matches $\sh$:\XDR{$\cmatches \cpati \sh \tvs \theta$ is never defined in
  the body of the paper} \Xalistair{It is left abstract, the matching
  semantics is informally defined in \cref{sec:constraints}. We should link this
  and the appendix. I don't think the definition is interesting enough to
  spend much time on it. Unless you think otherwise?}\XDR{I think we should
  not leave anything undefined: it annoys me when I am reading someone else
  paper. If left abstract, we should defined it by its properties, which is
  often longer and more complicated. And if left abstract, this should be
  make clear at  the location when one would expect a definition.}
\begin{mathpar}
  \cmatched \t \sh {\cbranch \cpats \cs} \uad\eqdef\uad
  \begin{cases}
    \cexists \tvs \cunif \t \shapp \tvs \cand \theta(\ci) & \text{if } \cmatches \cpati \sh \tvs \theta\\
    \cfalse & \text{otherwise}
  \end{cases}
\end{mathpar}
The first conjunct ($\tau = \shapp \tvs$) ensures that $\sh$ is indeed the
canonical shape of $\t$, and the second conjunct is the selected branch
constraint $\ci$ under the appropriate substitution. Since the syntax of
suspended match constraints requires that branch patterns are
non-overlapping, the matching branch $\cbranch \cpati \ci$ is uniquely
determined; but it may not exist as branches need not be exhaustive, in
which case the discharged constraint is $\cfalse$.
\end{definition}

\paragraph {A natural attempt}

To provide semantics for our suspended constraints, a first idea
is to propose the following rule---henceforth referred to as the
\emph{natural semantics} of suspended constraints.
\begin{mathpar}
  \infer[Match-Nat]
  {\sh = \shape {\semenv(\t)} \\ \semenv \th \cmatched \t \sh \cbrs}
  {\semenv \th \cmatch \t \cbrs}
\end{mathpar}
%
This rule states that a suspended constraint is satisfied by $\semenv$ whenever
the corresponding discharged constraint holds for the canonical shape $\sh$ of
$\t$ in the semantic environment $\semenv$. If $\sh$ matches no branch in
$\cbrs$, then the discharged constraint is not defined, so this rule cannot be
applied, and the suspended constraint is unsatisfiable.

\parcomment {The problem}

This semantics rule is nicely declarative, but unfortunately accepts too
many constraints. For example, $\cexists \tv \cmatch \tv {\cbranch
\cpatwild {\cunif \tv \tint}}$ is satisfiable under this natural
semantics:

\begin{mathpar}
\def \cmatchex {\cmatch \tv {\cbranch \cpatwild {\cunif \tv \tint}}}
\def \semenvex {\semenv\where{\tv \is \tint}}
    \infer*[Right=Match-Nat]
    {
      \cmatches \cpatwild \tint \eset \eset
      \\
      \infer*[Right=Unif]
        {\tint = \tint}
	% -------------------------------
    {\semenvex \th \cunif \tv \tint}
}{% ---------------------------------
    \infer*[Right=Exists]
    {\semenvex \th \cmatchex}
  % -----------------------------------
  {\semenv \th \cexists \tv \cmatchex}
}
\end{mathpar}
The semantics can \emph{guess} the type of $\tv$ and use it to unlock the match
constraint, rather than requiring it to be \emph{known} from the surrounding
context. One could call the guess of $\cunif \tva \tint$ an ``out of thin air''
behavior. This does not match the intended meaning of suspended match
constraints, and raises several problems:
\begin{enumerate*}
  \item a reasonable solver---one that avoids guessing or backtracking---cannot
    be complete with respect to this semantics;

  \item this breaks the existence of principal solutions.
    Consider the function $\efun \x (\efield \x 2)$, which projects the second
    component of a tuple. The natural semantics lets us guess for $\x$ any
    tuple type of arity at least $2$; so there is no principal type
    for~$\x$.
\end{enumerate*}

\paragraph {Contextual semantics}

\begin{version}{}
\begin{wraphbox}{}{}
\begin{mathpar}[inline]
  \infer[Match-Ctx]
    {\Cshape \C \t \sh \\\\
      \semenv \th \C \where {\cmatched \t \sh \cbrs}
    }
    {\semenv \th \C \where {\cmatch \t \cbrs}}
\end{mathpar}
\end{wraphbox}
\end{version}
To rule out guessing, we instead adopt a \emph{contextual} semantics: a
match constraint is satisfiable only if the shape of the type is determined
by the surrounding context. The corresponding rule for suspended
constraints, \Rule {Match-Ctx} in \cref {fig:contextual-semantics}, is the
only non-syntax-directed rule in our semantics.
%
In this rule, the shape $\sh$ is not guessed from $\semenv$, but it must be
recovered from the constraint context $\C$. The \emph{unicity} condition
$\Cshape \C \t \sh$ (defined below) ensures that $\sh$ is uniquely determined by $\C$.

\begin{definition}[Erasure]
  \label{def:erasure}
  The erasure $\cerase \c$ of a constraint $\c$ is defined as the constraint
  obtained by replacing suspended match constraints in $\c$ with $\ctrue$.
\end{definition}

\begin{definition}[Simple constraints]
  We say that $\c$ is \emph{simple} if it contains no suspended match
  constraints. We write $\semenv \thsimple \c$ for a derivation of $\semenv \th
  \c$ that only uses the rules listed in \cref{fig:constraint-semantics},
  without using \Rule{Match-Ctx}. This judgment coincides with $\semenv \th \c$
  on simple constraints.
\end{definition}

\begin{definition}[Unicity]
  \label{def:unicity}
  We define the unicity condition $\Cshape \C \t \sh$, which states that $\t$
  has a unique canonical shape $\sh$ within the context $\C$ as:
  \begin{mathpar}[inline]
    %% \Cshape \C \t \sh \Wide\eqdef
    \forall \semenv, \gt. \uad
      \semenv \thsimple \cerase {\C\where{\cunif \t \gt}} \implies
          \shape \gt = \sh
  \end{mathpar}.
\end{definition}

\begin{mathparfig}[htpb!]
  {fig:contextual-semantics}
  {Semantics of suspended constraints.}
\infer[Match-Ctx]
    {\Cshape \C \t \sh \and
      \semenv \th \C\where{\cmatched \t \sh \cbrs}
    }
    {\semenv \th \C\where{\cmatch \t \cbrs}}
\hfill
\begin{array}{.l.}
\Cshape \C \t \sh \eqdef
\\[.6ex]\quad
\forall \semenv, \gt. \uad
      \semenv \thsimple \cerase {\C\where{\cunif \t \gt}} \implies
         \shape \gt = \sh
\end{array}
\end{mathparfig}

The use of erasure $\cerase {\C\where{\cunif \t \gt}}$ in the definition of
$\Cshape \C \t \sh$ ensures that the unicity of $\sh$ is determined only by the
constraints that have already been discharged in $\C$; it excludes suspended
match constraints, which may be discharged in the future. Implicitly, this
induces a linear partial order between the suspended match constraints within a
constraint. In fact this corresponds to an order in which the solver is able to
discharge match constraints: a match constraint may only be discharged once all
of its dependencies have been discharged.

The erasure $\cerase{\C\where{\cunif \t \gt}}$ is simple, so the use of
$\thsimple$ avoids well-foundedness issues that would arise from
a negative occurrence of $(\th)$ in a premise of \Rule{Match-Ctx}.
%
Note that, when $\t$ is not a variable, then $\Cshape \square \t \sh$
holds trivially for $\sh = \shape \t$. Likewise, when $\C$ is unsatisfiable,
then $\Cshape \C \tv \sh$ holds vacuously for any $\sh$. The interesting cases
arise when $\t$ is a type variable and $\C$ is satisfiable.

We summarize the definition of the unicity condition and \Rule{Match-Ctx} in
\cref{fig:contextual-semantics}. Together with the rules of
\cref{fig:constraint-semantics}, this forms the complete semantics of our
constraint language.


\parcomment {Examples}

\begin{example}
Consider the two examples from above:
\begin{mathpar}
\cexists \tv \cunif \tv \tint
  \cand
  \cmatch \tv {\cbranch \cpatwild \ctrue}

  \cexists \tv \cmatch \tv {\cbranch \cpatwild {\cunif \tv \tint}}
\end{mathpar}
In the first example, we apply the contextual rule with the context
\relax $\C \is \cexists \tv \cunif \tv \tint \cand \square$.
Any solution $\semenv$ of this context necessarily satisfies
\relax $\cunif \tv \tint$, so we have
\relax $\Cshape \C \tv \tint$ and the suspended constraint can be discharged.
%
By contrast, the second example has no contextual information around the
suspended constraint: $\C \is \square$. So any solution $\semenv$ satisfies
it, allowing $\semenv(\tv)$ to have an arbitrary shape (\eg $\tint$,
$\tbool$,
  \etc). As a result, the uniqueness condition $\Cshape \C \tv \sh$ never holds
  and the constraint is unsatisfiable as intended.

\end{example}
\begin{example}
Consider the more intricate example:
\begin{mathpar}
  \cexists {\tva \tvb}
  {\def \EX
     {\cmatch \tva {\cbranch \cpatwild {\cunif \tvb \tbool}} \and
      \cmatch \tvb {\cbranch \cpatwild \ctrue} \and
      \cunif \tva \tint}
    \False%\True
      {\def \and{\\{}\cand}\Parens
         {\begin{array}{;l}
            \quad \EX
          \end{array}}}
      {\def \and{)\wide\wedge(}\parens{\EX}}
  }
\end{mathpar}
Suppose we attempt to apply \Rule{Match-Ctx} to the match on $\tvb$ first.
We want to show $\Cshape \C \tvb \tbool$ for the context
$\C$ equal to
\begin{mathpar}[inline]
  \cmatch \tv {(\cbranch \cpatwild {\cunif \tvb \tbool})} \cand
  \square \cand
  \cunif \tva \tint
\end{mathpar}.
Its erasure is
\relax $\cerase \C = \ctrue \cand \square \cand \cunif \tva \tint$.
In this constraint $\tvb$ is unconstrained, so for example
\relax $\cerase {{\C\where{\cunif \tvb \tint}}}$ and
\relax $\cerase {\C\where{\cunif \tvb \tbool}}$
are both satisfiable: unicity does not hold and \Rule{Match-Ctx} cannot be
applied.

Now consider instead applying \Rule{Match-Ctx} to the match on $\tva$
first. To do so, we must show that $\tva$ has a uniquely determined shape in
the context $\C$ equal to
\begin{mathpar}[inline]
  \square \cand
  \cmatch \tvb {\cbranch \cpatwild \ctrue} \cand
  \cunif \tva \tint
\end{mathpar}.
Its erasure $\cerase \C$ is
\relax $\square \cand \ctrue \cand \cunif \tva \tint$.
Since $\tva$ is unified with $\tint$ in the erasure, we have $\Cshape \C
\tva \tint$.
%
We may now discharge the match on $\tva$, rewriting it as
\begin{mathpar}[inline]
(\cmatched \tva \tint {\cbranch \cpatwild {\cunif \tvb \tbool}})
\end{mathpar},
that is, $(\tva = \tint \cand \cunif \tvb \tbool)$. Substituting back, we
are left to satisfy the constraint $\C \where {\tva = \tint \cand \cunif
\tvb \tbool}$, that is,
\begin{mathpar}[inline]
\parens {
  \cunif \tva \tint \cand \cunif \tvb \tbool \cand
  \cmatch \tvb {\cbranch \cpatwild \ctrue} \cand
  \cunif \tva \tint
}
\end{mathpar}.

At this point, we can safely
apply \Rule{Match-Ctx} to the remaining match constraint on $\tvb$.  The
unicity condition now holds, as the erasure of the context includes the
discharged constraint $\cunif \tvb \tbool$, allowing us to eliminate the
final match constraint.

This demonstrates that suspended match constraints must be resolved in a
dependency-respecting order: attempting to resolve a match
constraint too early may result in unsatisfiability.
\end{example}

\begin{example}
Let us consider a constraint with a cyclic dependency between match
constraints:
\begin{mathpar}
  \cexists {\tva \tvb}
  {\def \EX
     {\cmatch \tva {\cbranch \cpatwild {\cunif \tvb \tbool}} \and
      \cmatch \tvb {\cbranch \cpatwild {\cunif \tva \tint}}}
    \False%\True
      {\def \and{\\{}\cand}\Parens
         {\begin{array}{;l}
            \quad \EX
          \end{array}}}
      {\def \and{)\wide\wedge(}\parens{\EX}}
  }
\end{mathpar}
This constraint can be proved satisfiable under the ``natural semantics'' introduced
earlier: by guessing the assignment $\tva \is \tint, \tvb \is
\tbool$, the two match constraints succeed. However, our solver
and the contextual semantics reject it.

Without loss of generality, suppose we attempt to apply \Rule{Match-Ctx} on
$\tva$ first. We must show $\Cshape \C \tva \tint$ where $\C$ is
\begin{mathpar}[inline]
    \square \cand \cmatch \tvb {\cbranch \cpatwild {\cunif \tva \tint}}
\end{mathpar}
But the erasure $\cerase \C$ is $\square \cand \ctrue$ imposes no constraint
on $\tva$, so unicity fails, and \Rule{Match-Ctx} cannot be applied.
\end{example}

\begin{example}
Considering the example \code{ex_7} from \cref{sec/introduction}:
\begin{program}[input]
let ex_7 r = let x = r.x in x + r.y °\ocamlflags 10°
\end{program}
The typing constraint generated for \code{ex_7} contains the following, where $\tv$ stands for the type of \code{r}:
\begin{mathpar}
  \cexists {\tv, \tvc}
    \clet x \tvb
      {(\cmatch \tva \dots)}
      {\cinst x \tint \cand \cunif \tv {\Tapp[\mathsf{one}] \tvc}}
\end{mathpar}
The suspended constraint can be discharged under our semantics, as
intended. We apply the \Rule{Match-Ctx} rule with context
$\C$ equal to
\begin{mathpar}[inline]
  \clet \x \tvb \square \capp \x \tint \cand
  \cunif \tv {\Tapp[\mathsf{one}] \tvc}
\end{mathpar}.
Although the context includes a \code{let}-binding---which in practice
involves \code{let}-generalization---we can still deduce $\Cshape \C \tv
{\any \tvcp \Tapp[\mathsf{one}] \tvcp}$, since the erased context $\cerase \C$ contains the
unification $\cunif \tv {\Tapp[\mathsf{one}] \tvc}$.

This example illustrates that our formulation of suspended constraints
interacts nicely with \code{let}-polymorphism. Although the two features are
specified in a modular fashion, they are carefully crafted to work together,
as we will further show in our next example.
\end{example}

\begin{example}\label{ex:backprop}
A subtle yet crucial feature of our semantics is its support for
\emph{backpropagation}:
\begin{program}[input]
let ex_8 = let getx r = r.x in getx {x = 1; y = 1}  °\ocamlflags 10°
\end{program}
As in the previous example, the type of \code{r} cannot be disambiguated in the
\code{let}-definition alone. In the previous example, this type was unified
to a known shape in the \code{let}-body. Here, this is more subtle: an
\emph{instance} of the type scheme is taken, which is only well-typed if
\code{r} has a variable type or a type of the form
\ocaml{'a one}. The projection \code{r.x} would be
forbidden if \code{r} had a variable type, so
\code{'a one} is the unique solution. We call this flow of
information from instances back to definitions \emph{backpropagation}.

The constraint generated when typing
\code{ex_8} is:
\begin{mathpar}
\begin{tabular}{L.L}
  \cexists \tv {}
  &\clet {getx} \tvd
     {\cexists {\tvb, \tvc} \Parens {\strut
        \cunif \tvd {\tvb \to \tvc} \cand
	\cmatch \tvb \dots
        }}{}
    \cinst {getx} {(\tint \ \mathsf{one} \to \tv)}
\end{tabular}
\end{mathpar}
With the context $\C$ equal to $\clet {getx}
\tvd {\cexists {\tvb, \tvc} \cunif \tvd {\tvb \to \tvc} \cand \square}
{\capp {getx} {(\tint \ \mathsf{one} \to \tv)}}$, we can show the unicity predicate $\Cshape \C \tvb \sh$ for the shape $\sh = (\any \tvc {\tvc~\mathsf{one}})$.
%% That is:
%% \begin{mathpar}
%%   \all {\semenv, \gt} \uad
%%     \semenv \th \cerase {\C\where{\cunif \tvb \gt}} \implies \shape \gt = \sh
%% \end{mathpar}
For any $\semenv, \gt$, the erasure $\cerase {\C \where {\cunif \tvb \gt}}$
is
\begin{mathpar}[inline]
\clet {getx}
\tvd {\cexists {\tvb, \tvc} \cunif \tvd {\tvb \to \tvc} \cand \cunif \tvb \gt}
{\capp {getx} {(\tint \ \mathsf{one} \to \tv)}}
\end{mathpar}.
Since $getx$ is bound to the constraint abstraction
\relax $\cabs \tvd \exists \tvc.\uad \cunif \delta {(\gt \to \gamma)}$,
the instantiation
\relax $\capp {getx} (\tint \ \mathsf{one} \to \tv)$
can only be satisfied when
\relax $\gt = \tint\ \mathsf{one}$. This proves unicity,
hence \code{ex_7} is accepted by our semantics.
\end{example}


\section{The \OML calculus}
\label{sec:language}

\parcomment {Running example: tuple projection disambiguation}

\parcomment {We need a spec, but this itself is hard}

To prove correctness of constraint generation, we must first define a surface
language and its type system. Surprisingly, identifying an appropriate
declarative type system to use as a specification is itself an interesting
problem! In particular, na\"ive specifications often fail to ensure principal types.

\parcomment {Why do naive approaches not guarantee principal types.}

%\begin{wraphbox}[11em]{}{}
%\mprset{sep=1em}
%\begin{mathpar}[inline]
%   \inferrule*
%      {\G \th \e : \Pi\iton \ti \\ 1 \leq j \leq n }
%      {\G \th \exproj \e j n : \tj}
%\end{mathpar}
%\end{wraphbox}
Take overloaded tuple projections \ala \SML. We can ask the user to provide the
length of the tuple explicitly, via an annotated syntax $\exproj \e j n$,
which has a simple typing rule (\Rule{Proj-X}).
\begin{mathpar}
  \infer[Proj-X]
    {\G \th \e : \Pi\iton \ti \\ 1 \leq j \leq n}
    {\G \th \exproj \e j n : \tj }

  \infer[Proj-I-Nat]
    {\G \th \e : \Pi\iton \ti \\ 1 \leq j \leq n}
    {\G \th \eproj \e j : \tj}
\end{mathpar}
%
%\begin{wraphbox}[11em]{}{}
%\mprset{sep=1em}
%\begin{mathpar}[inline]
%  \infer
%    {\G \th \e : \Pi\iton \ti \\ 1 \leq j \leq n}
%    {\G \th \eproj \e j : \tj}
%\end{mathpar}
%\end{wraphbox}
%
On the other hand, the natural typing rule for the fragile construct $\eproj e
j$ breaks principality (\Rule{Proj-I-Nat}). The term $\eproj \e j$ admits
infinitely many typings for $\e$, provided the tuple is of sufficient length.
%
%\begin{wraphbox}[11em]{}{}
%\mprset{sep=1em}
%\begin{mathpar}[inline]
%\infer
%  {\eshape \E \e {\any \tvcs \Pi\iton \tvcs} \\\\
%   \G \th E[\exproj \e j n] : \t}
%  {\G \th \E[\eproj \e j] : \t}
%\end{mathpar}
%\hfil
%\end{wraphbox}
This is the exact same issue we had with the na\"ive semantics of suspended
constraints, and in fact we solve it in the same way, with a unicity
condition and a contextual rule (\Rule{Proj-I}) that transforms the fragile,
implicit
construct into the robust, explicit counterpart:
\begin{mathpar}
  \infer[Proj-I]
  {\eshape \E \e {\any \tvcs \Pi\iton \tvcs} \\
   \G \th \E[\exproj \e j n] : \t}
  {\G \th \E[\eproj \e j] : \t}
\end{mathpar}

\subsection{Syntax}

\begin{bnffig}[t]{fig/syntax}{Syntax of \OML.}
\entry[Terms]{\e}{
  x \and
  () \and
  \efun x e \and
  \eapp \ea \eb \and
  \elet x \ea \eb \and
  \eannot \e \tvs \t \andcr
  (\ea, \ldots, \en) \and
   \eproj e j \and
   \exproj e j n \and%\andcr
   \epoly e \and
   \expoly e \tvs \ts \and
   \einst e \and
   \exinst e \tvs \ts \andcr
  \erecord {\overline{\elab = \e} } \and
  \efield e \elab \and
  \exrecord \T {\overline{\elab = \e}} \and
  \exfield e \T \elab
   }
\\
\\[1ex]
\entry[Types]{\t}{
   \tv \and
   1 \and
   \tya \to \tyb \and
   \T \tys \and
   \Pi \iton \ti \and
   \tpoly \ts
}\\
\entry[Type schemes]{\ts}{
     \t \and
     \tfor \tv \ts
}\\
\entry[Contexts]{\G}{
   \eset \and
   \G, x : \ts
}\\
\end{bnffig}

In \cref {fig/syntax}, we give the grammar for our calculus. Terms include
all of the \ML calculus: variables~$\x$, the unit literal $\eunit$,
lambda-abstractions $\efun \x \e$, applications $\eapp \ea \eb$,
annotations $\eannot \e \tvs \t$ and let-bindings $\elet x \ea \eb$.
Our extensions include:
\begin{enumerate}
\item
  Tuples $(\ea, \ldots, \en)$ with implicit projections
  $\eproj \e j$ and explicit projections $\exproj \e j n$.

\item
  For semi-explicit first-class polymorphism, we have implicit and explicit
    introduction and elimination forms: boxing $\epoly \e$ and $\expoly
    \e \tvs \ts$, and unboxing $\einst \e$ and $\exinst \e \tvs \ts$.
\item
  Overloaded record labels introduce record literals $\erecord { \elaba = \ea;
    \ldots; \elab_n = \en }$ and field projections $\efield \e \elab$. Both
    constructs have explicit counterparts: $\exrecord \T {\elaba = \ea; \ldots;
    \elab_n = \en }$ and $\exfield \e \T \elab$, where the nominal type
    annotation $\T$ indicates that the labels correspond to the label
    definitions in $\T$ (thereby disambiguating overloading). Variant
    constructors are not treated formally in \OML, but behave analogously in
    practice.

\end{enumerate}
We use the metavariable $\e^i$ to range over the
fragile/implicit constructions, and $\e^x$ to range over their
explicit counterpart.

\subsection{Typing rules and unicity}

We have detailed typing rules for the full \OML calculus, but unfortunately
they do not fit in the margins of the 25 pages of this document. We moved them
all\relax
%% , along with detailed examples,
in Appendix \cref{app/oml}.

Our typing rules $\G \th \e : \ts$ are mostly standard, except for
the rules governing implicit (or fragile) constructs $\e^i$. These
rules are inspired by our contextual constraint semantics (\Cref{sec:semantics}):
each is a contextual typing rule paired with a unicity condition and
an elaboration into an explicit form.

The unicity condition requires that the shape $\sh$ is fully determined by the
surrounding term context $\E$, including any subexpressions (\eg $\e$ in
$\eproj \e j$). They are analogous to the unicity condition $\Cshape \C \t \sh$
for constraints, though the analogy is not exact. Different fragile features
require slightly different formulations, depending on whether they infer a
unique shape for a subexpression $\eshape \E \e \sh$ or for the expected type
of the context $\Eshape \E \e \sh$.

\begin{wraphbox}{}{}
\begin{mathpar}[inline]
  \inferrule[Magic]
    {\G \th \e : \t}
    {\G \th \emagic \e : \tp}
\end{mathpar}
\end{wraphbox}
In order to define the unicity conditions, we introduce \emph{typed holes}
$\emagic \e$, which allow any well-typed term $\e$ to be treated as
if it had any type (via \Rule{Magic}). Types holes are forbidden in
the source language---they are a device solely used to define unicity conditions.
%
We also introduce an erasure function $\eerase \e$, the term counterpart of constraint erasure
$\cerase \c$, which erases all not-yet-elaborated implicit constructs
$\e^i$ in $\e$ with typed holes around their subterms. This ensures the
subterms---such as type annotations---remain present, so that any constraints
they introduce can still contribute to unicity.
For example, $\eerase {\eproj \e j}$ is $\emagic {\cerase \e}$.
The full definition is given in Appendix \cref{app:full-reference}.

We can now formalize the two unicity conditions:
\begin{mathpar}
\def \Eqdef {&\eqdef&}
{\begin{tabular}{RCL}
\eshape \E \e \sh \Eqdef
  \forall \G, \t, \gt, \uad
  \G \th \eerase {\E \where {\emagic {\eannot \e {} \gt }}} : \t
      \wide\implies \shape \gt = \sh
\\[1ex]
\Eshape \E \e \sh \Eqdef
  \forall \G, \t, \gt, \uad
      \G \th \eerase {\E\where{\eannot {\emagic \e} {} \gt}} : \t
      \wide\implies \shape \gt = \sh
\end{tabular}}
\end{mathpar}
We use the unicity condition
$\eshape \E \e \sh$ when we disambiguate using the type of a subterm,
as in overloaded tuple projections, record projections, and polytype
unboxing. Conversely, we use $\Eshape \E \e \sh$ for polytype boxing and
overloaded records, where we disambiguate them using the expected type of
the context.

\begin{example}
Let $\e$ be $\elet f {\efun \x {\eproj \x 1}} {\eapp f (1, 2)}$.
$\e$ is well-typed using \emph{backpropagation}.
$\e$ is of the form $\E \where {\x}$ where  $\E$ is the context $\elet f
{\efun \x \ehole} {\eapp f (1, 2)}$.
We have $\eset \th \E \where {\eproj[2] \x 1} : \tint$.
Let us show that $\eshape \E \x {\any {\tvca, \tvcb} \tvca \tprod \tvcb}$.
%
Assume $\eset \th \E \where {\emagic {\eannot \x {} \gt} } : \t$. As $\gt$ is a ground
type, the type $\gt$ of $\x$ is not a variable.  Then, $\gt$ cannot be that
of an arbitrary sized tuple, since there is no such type for a tuple of
arbitrary size. Hence, $\gt$ must be a tuple $\Pi\iton \tys$ for some size
$n$. Since the codomain of $f$ must be a tuple of size~$2$ (for $\eapp f (1,
2)$ to be well-typed), then $n$ must also be $2$. This shows that $\eshape \E
\x {\any {\tvca, \tvcb} \tvca \tprod \tvcb}$.
%% \begin{mathpar}
%%   \infer
%%     {
%%     \infer
%%       {
%% 	\infer
%% 	  {
%% 	    \infer
%% 	      {
%% 		\infer
%% 		  { }
%% 		  {\tva, \tvb, x : \tva \th x : \tva}}
%% 	      {\tva, \tvb, x : \tva \th \ecast x \tva \tvb : \tvb}}
%% 	  {\tva, \tvb \th \efun x {\ecast x \tva \tvb : \tva \to \tvb}}}
%%       {\emptyset \th \efun \x \ecast \x \tva \tvb : \tfor {\tva, \tvb} \tva \to \tvb} \\
%%     \infer
%%       {\ldots}
%%       {f : \tfor {\tva, \tvb} \tva \to \tvb \th \eapp f (1, 2) : \tunit}}
%%     {\emptyset \th \elet f {\efun \x {\ecast \x \tva \tvb}} {\eapp f (1, 2)} : \tunit}
%% \end{mathpar}
\end{example}



\subsection{Metatheory}
\label{sec/oml/metatheory}

Constraint generation is sound and complete with respect to the typing judgment.
That is to say, the term $\e$ is typable with $\t$ if and only if
$\cinfer \e \tv$ is satisfiable when $\tv$ is $\t$.
%
\begin{theorem}[Constraint generation is sound and complete]
  \label{thm:constraint-gen-is-sound-and-complete}
Given a closed term $\e$ and type $\t$. Then for any $\tv \disjoint \t$,
$\th \e : \t$ iff\/
$\cunif \tv \t \centails \csem {\e : \tv}$.
\end{theorem}

\begin{restatable}[Principal types]{theorem}{principalTypes}
\label{thm:principal-types}
For any well-typed closed term $\e$, there exists a type $\t$\relax
%% , which we call principal,
such that:
\begin{enumerate*}[(\roman*)]
\item
  $\th \e : \t$.
\item
  For any other typing $\th \e : \tp$, then $\tp = \theta(\t)$ for some
  substitution $\theta$.
\end{enumerate*}
\end{restatable}
It is also interesting to discuss the stability of typing by common program
transformations.

\paragraph{Application equi-typability does hold}

\newcommand {\eswap}{{\mathprefix {swap}}}
The expressions $\eappp f \ea \eb$ and $\eappp {\eswap f} \eb \ea$ are
equitypable where $\eswap$ is
$\efun f {\efun \xa {\efun \xb {\eappp f \xb \ea}}}$. We also have
that $\eapp f \e$ and $\eappp {\mathsf{app}} f \e$ and
$\eappp {\mathsf{rev\_app}} \e f$ are equitypable.
\begin{version}{}
\XDR{Definition already made in the intro as a footnote.}
, where $\mathsf{app}$ and $\mathsf{rev\_app}$ are the application function
$\efun f \efun \x \eapp f \x$ and the reverse application function $\efun \x
\efun f \eapp f \x$, respectively.
\end{version}
It is well-known that
bidirectional types inference breaks application
equitypability. Both \Geninst-directional and omnidirectional
type inference preserve it.

\paragraph{Factorization does not hold} If $\G \th \e \where {\x \is {\e_0}}
: \t$ with $\x$ appearing in $\e$, we do not necessarily have $\G \th \elet \x
\ez \e : \t$. This is not a defect of our system, but a general property of
all systems that support static overloading: the expanded term $\e \where {x
\is \e_0}$ can pick a different overloading choice for each occurrence of
$\e_0$, and if they are incompatible the factored form may not typecheck.

\paragraph{Inlining does not hold} If $\G \th \elet \x \ez \e : \t$, we do
not necessarily have $\G \th \e \where {\x \is {\e_0}} : \t$. This is
specific to our support for \emph{backpropagation}: the $\Let$-form will use
information from all occurrences of $\x$ in $\e$ to resolve fragile
constructs in $e_0$, but in the inlined form each copy of $\e$ must resolve
its implicit constructs independently, and it has access to less information
to establish unicity. As a result, the implicit \OML calculus does not
preserve typability in its operational semantics.

\section{Solving constraints}
\label{sec:solving}

\parcomment{Intro}
We now present a machine for solving constraints in our language. The solver
operates as a rewriting system on constraints $\c \csolve \cp$. Once no further
transitions are applicable, \ie $\c \cnsolve$, the constraint $\c$ is either in
solved form---from which we can read off a most general solution---or the
solver becomes stuck, indicating that $\c$ is unsatisfiable.

\begin{definition}[Solved form $\hat\up$]
  \label{def:solved-form}
  A solved form is a constraint $\hat\up$ of the form $\cexists \tvs \cAnd
\iton \ueqi$, where:
\begin{enumerate*}
  \item each $\ueqi$ contains at most one non-variable type;
  \item head variables do not occur in multiple equations;
  \item the constraint is acyclic.
\end{enumerate*}
\end{definition}

\subsection{Unification}

Our constraints ultimately reduce to equations between types, which we solve
using first-order unification. Like our solver, we specify unification as a
non-deterministic rewriting relation between \emph{unification problems} $\upa
\unif \upb$, that eventually reduces to a solved form $\hat\up$ or to $\cfalse$.

\begin{mathparfig}[t!]%htpb!
  {fig:unification-syntax-and-semantics}
  {Syntax and semantics of unification problems.
   %Constraints are also extended with the administrative multi-equation construct.
  }
\begin{minipage}[c]{0.7\textwidth}
\begin{bnfgrammar}
  \entry[Unification problems]{\up}{
    \ctrue \and \cfalse \and \upa \cand \upb \and \cexists \tv \up \and \ueq
    \uad\strut
  } \\
  \entry[Multi-equations]{\ueq}{
    \eset \mid \cunif \t \ueq
  } \\
  \entry[Constraints]{\c}{
    \dots \and \ueq
  }
\end{bnfgrammar}
\end{minipage}
\hfill
\vcenter{\hbox{
  \infer[Multi-Unif]
    {\all {\t \in \ueq}\, \semenv(\t) = \gt}
    {\semenv \th \ueq}
}}
\end{mathparfig}

\parcomment{Unification problems and multi-equations}

Unification problems $\up$
(\cref{fig:unification-syntax-and-semantics}) are a restricted subset
of constraints, extended with \emph{multi-equations}
\citep*{Pottier-Remy/emlti}---a multi-set of types considered
equal. These generalize binary equalities: $\semenv$ satisfies
a multi-equation $\ueq$ if all of its members are mapped to a single
ground type $\gt$ (\Rule{Multi-Unif}). Multi-equations are
considered equal modulo permutation of their members.

Our algorithm is largely standard, with it main novelty being the use
of \emph{canonical principal shapes} in place of type constructors. This
uniform treatment of monotypes and polytypes simplifies unification and improves
on the previous treatment of polytype unification \citep{Garrigue-Remy/poly-ml}.
For a detailed discussion of the unification rules, see
\cref{app:unification} (appendix).

\subsection{Solving rules}

% What we do (introduce / explain the solver)

We now gradually introduce the rules of the constraint solver itself
(\cref {fig:solver-basic,fig:solver-susp,fig:solver-schemes}).
These rules define a non-deterministic rewriting
system, operating modulo $\alpha$-equivalence, and the associativity and
commutativity of conjunction. Rewriting takes place under an arbitrary
one-hole constraint context $\C$.
%
% Solved forms
A constraint $\c$ is satisfiable if it rewrites to a solved form
$\hat\up$ (\cref{def:solved-form}); otherwise it gets
stuck.

\begin{mathparfig}[t!]%htpb
  {fig:solver-basic}
  {Basic rewriting rules $\ca \csolve \cb$}
  \rewrite[S-Unif]
    {\upa}
    {\upa \unif \upb}
    {\upb}

  \rewrite[S-False]
    {\C\where\cfalse}
    {\C \neq \square}
    {\cfalse}

  \rewrite[S-Let]
    {\clet \x \tv \ca \cb}
    {}
    {\cletr \x \tv \eset \ca \cb}

  \rewrite[S-Exists-Conj]
    {(\cexists \alpha \ca) \cand \cb}
    {\tv \disjoint \cb}
    {\cexists \tv {\ca \cand \cb}}

  \rewrite[S-Let-ExistsLeft]
    {\cletr \x \tv \tvs {\cexists \tvb \ca} \cb}
    {\tvb \disjoint \tv, \tvs, \cb}
    {\cletr \x \tv {\tvs, \tvb} \ca \cb}

  \rewrite[S-Let-ExistsRight]
    {\cletr \x \tv \tvs \ca {\cexists \tvb \cb}}
    {\tvb \disjoint \tv, \tvs, \ca}
    {\cexists \tvb {\clet \x \tvs \ca \cb}}

  \rewrite[S-Let-ConjLeft]
    {\cletr \x \tv \tvs {\ca \cand \cb} \cc}
    {\ca \disjoint \tv, \tvs}
    {\ca \cand \cletr \x \tv \tvs \cb \cc}

  \rewrite[S-Let-ConjRight]
    {\cletr \x \tv \tvs \ca (\cb \cand \cc)}
    {\x \disjoint \cc}
    {\cc \cand \Clet \x \tv \ca \cb}
\end{mathparfig}

\paragraph{Basic rules}

\parcomment{Unification}

\Rule{S-Unif} invokes the unification algorithm to the
current unification problem. The unification algorithm itself is treated as a
black box by the solver, so the system could be extended with any
equational theory of types implemented by the unification algorithm.
\begin{mathparfig}[t!]%htpb
  {fig:constraint-let-regions}
  {Syntax and semantics of region-based $\Let$ constraints.}
  [mprset=lessskip]
 \begin{bnfgrammar}
  \entry[Constraints]{\c}{
     \dots \and \cletr \x \tv \tvs \ca \cb
   }
 \end{bnfgrammar}
 \vadjust{\vskip -1.2ex}\\
\begin{tabular}{R;;C;;L}
%%\c &::=& \ldots \mid \cletr \x \tv \tvs \ca \cb \\
\semenv(\cabsr \tv \tvs \c) &\eqdef&
  \set{\greg \tv {\semenv\where{\tv \is \gt, \tvs \is \gts}}
       \in \GroundRegion : \semenv\where{\tv \is \gt, \tvs \is \gts} \th \c}
\end{tabular}
\\
  \infer[LetR]
    {\semenv \th \cexists {\tv, \tvs} \ca \\
     \semenv\where{\x \is \semenv(\cabsr \tv \tvs \ca)} \th \cb}
    {\semenv \th \cletr \x \tv \tvs \ca \cb}

  \infer[AppR]
    {\greg \tv \semenvp \in \semenv(\x) \\
     \semenv(\t) = \semenvp(\tv) }
    {\semenv \th \capp \x \t}
\end{mathparfig}

\parcomment{Regional let constraints}

In general, existential quantifiers $\cexists \tv \c$ are lifted to the nearest
enclosing $\Let$, if one exists, or otherwise to the top of the constraint. The
resulting existential prefix $\exists \tvs$ is called a \emph{region}. To make
regions explicit, we introduce the syntax $\cletr \x \tv \tvs \ca \cb$, where
$\tv$ is the \emph{root} of the region and $\tvs$ are auxiliary existential
variables. The order of $\tvs$ is immaterial; regions are considered equal up
to permutation of these variables.

Satisfiability of regional $\Let$-constraints is defined in
\cref{fig:constraint-let-regions}. The semantics of an
abstraction with a region, written $\semenv(\cabsr \tv \tvs \c)$, is a set of
\emph{ground regions} that satisfy $\c$. A ground region is a satisfying
interpretation for the region $\semenvp$ with a designated \emph{root} variable
$\tv$, written $\greg \tv \semenvp$. Regional $\Let$-constraints strictly
generalize ordinary constraint abstractions, as captured by the equivalence:
\begin{mathpar}
  \clet \x \tv \ca \cb \Wide\cequiv \cletr \x \tv \eset \ca \cb
\end{mathpar}
%
\parcomment{Explanation of rules}
%
Rule \Rule{S-Let} rewrites let constraints into regional form.
%
\Rule{S-Exists-Conj} lifts existentials across conjunctions;
\Rule{S-Let-ExistsLeft} and \Rule{S-Let-ExistsRight} lift existentials across
let-binders; \Rule{S-Let-ConjLeft}, \Rule{S-Let-ConjRight} hoist
constraints out of let-binders when they are independent of the local
variables.
%
Collectively, these lifting rules normalize the structure of each
region into a block of existentially bound variables, whose body
consists of a conjunction of solved multi-equations followed by
a residual constraint---typically an application, let-binding, or
suspended constraint.


\parcomment{\OML constraints do not need dedicated rules}

\OML-specific constraints, such as the label and polytype instantiations from
\cref{sec/constraints/polytypes} and \cref{sec:constraints:overloading}, require no
special treatment in our solver. Once their pattern variables are
substituted---after solving a match constraint---they are desugared into
constraints already handled by the solver.

\paragraph{Let constraints}

% Let-constraint solving is generalization

\parcomment{Background on efficient solving of applications (aka generalization)}

Application constraints can be solved by copying constraints:
\begin{mathpar}
\hfil
\rewrite
    {\cletr \x \tv \tvs \ca {\C\where{\capp \x \t}}}
    {\tv, \tvs \disjoint \t \\ x \disjoint \bvs \C}
    {\clet \x \tv \ca {\C\where{\cexists {\tv, \tvs} \cunif \tv \t \cand \ca}}}
\eqno
{\DefTirName{S-Let-App-Beta}}
\end{mathpar}
This resembles $\beta$-reduction, except that the original abstraction is
retained. While correct for \emph{simple} constraints, it may duplicate
solving work across applications of the same abstraction.
%
A more efficient approach first solves the abstraction once---\eg reducing it
to $\cabsr \tv \tvs \ueqs$, where $\tvs$ are generalizable variables---and then
reuses the result at each application site by only copying the solved
constraint $\ueq$. This mirrors \ML generalization and instantiation, a
connection formalized by \citet*{Pottier-Remy/emlti}, where $\cabsr \tv \tvs
\ueqs$ corresponds to the type scheme $\tfor \tvs {\sub(\tv)}$ and $\sub$ is
the \mgu of $\ueqs$. This optimization underlies efficient implementations of
\HM inference, such as \OCaml's.

\parcomment{Generalization with suspended constraints is hard}

However, this approach \emph{does not} extend to suspended constraints. To
illustrate this, let us reexamine \ocaml{ex_7} from \cref{sec/introduction}:
\begin{program}[input]
let ex_7 r = let x = r.x in x + r.y °\ocamlflags10°
\end{program}
The generated typing constraint contains:
\begin{mathpar}
  \cexists {\tv, \tvc}
    \clet x \tvb
      {\cmatch \tvb {\cbranch {(\cpatrcd \ct)} {\C\where {\ct,\tva,\tvb}}}}
      {\cinst x \tint \cand \cunif \tv {\Tapp[\mathsf{one}] \tvc}}
\end{mathpar}
where $\C\where{\ct,\tv,\tvb}$ is ${\Omega(\elab / t) \leq \tva \to \tvb}$.
Here, $\tv$ stands for \code{r}'s type. The constraint remains suspended until
\code{r.y} forces \code{r}'s type to be \code{one}. Crucially, the variable
$\tvb$ (introduced inside the abstraction for the type of \code{y}) is captured
by the suspended match constraint that is not yet resolved at the point of
solving the $\Let$ constraint that binds \code{x}.

\parcomment {Partial type schemes}

Nonetheless, to continue solving the let-body, we must assign a scheme to
\code{x}. We na\"ively pick $\tfor \tvb \tvb$. This appears unsound, since
$\tvb$ will later unify with $\tint$ once the match constraint is discharged.
But it would be incomplete to lower $\tvb$ as a monomorphic variable.
%
This motivates \emph{partial type schemes}, our second novel mechanism for
omnidirectional inference. Partial type schemes are type schemes that delay
commitment to certain quantifications (\eg $\tvb$). Such \emph{partially
generalized} variables are treated as generalized, but can be incrementally
refined in future as suspended constraints are discharged.

\begin{mathparfig}[t]
  {fig:constraint-partial-app}
  {The syntax and semantics of partial instantiations.}
\begin{minipage}[b]{0.5\hsize}
  \indent
  \begin{bnfgrammar}
    \entry[Constraints]{\c}{
      \dots
      \and \cexistsi \inst \x \c
      \and \cpinst \inst \tv \t
    } \\
    \entry[Semantic environments]{\semenv}{
      \dots
      \and \semenv\where{\inst := \semenvp}
    }
  \end{bnfgrammar}
\end{minipage}
\hfill
\infer[Exists-Inst]
  {\greg \tv\semenvp \in \semenv(\x) \\\\
   \semenv\where{\inst \is \semenvp} \th \c}
  {\semenv \th \cexistsi \inst \x \c}

\infer[Partial-Inst]
  {\semenv(\inst)(\tv) = \semenv(\t) }
  {\semenv \th \cpinst \inst \tv \t}
\end{mathparfig}


\parcomment {Intro partial applications}

To support this, we extend the constraint language with \emph{partial
instantiation constraints}. Instead of duplicating an abstraction at each
application site, we introduce:
\begin{enumerate*}
  \item
    $\cexistsi \inst \x \c$, which binds a fresh instantiation $\inst$ of $\x$'s
    region within $\c$, and
  \item
    $\cpinst \inst \tv \t$, which asserts that the copy of $\tv$ in $\inst$
    equals~$\t$.
\end{enumerate*}
%
The instantiation variable $\inst$ is required to ensure all partial
instantiations $\cpinst \inst \tv \t$ are solved uniformly. Within the
solver, we view partial instantiations as markers indicating which parts of
the abstraction still need to be copied.

Partial instantiations enables efficient incremental instantiation of
constraint abstractions: solved parts are reused immediately, while
suspended constraints can be solved later, further refining the
abstraction and propagation additional equations to the application
sites.

\parcomment{Semantics of partial applications}

The semantics of the existential constraint $\cexistsi \inst \x \c$
(\Rule{Exists-Inst}) introduces the fresh instantiation~$\inst$ by ``guessing''
a region $\semenvp$ that satisfies the regional constraint abstraction bound to
$\x$.
%
Partial instantiations (\Rule{Partial-Inst}) equate the copy of $\tv$ in
$\inst$ with $\t$.
%
The domain of partial instantiation constraints must lie within the closure of
the abstraction or among the regional variables of $\x$. Consequently, the
variables $\tv, \tvs$ bound by the $\Let$-constraint $\cletr \x \tv \tvs \ca
\cb$ are bound not only in the body of the abstraction $\ca$, but also in the
constraint $\cb$, where they may appear in partial instantiations of $\x$ via
renamings---and only there. Hence, they cannot appear in $\cb$ when the
corresponding variable $\x$ does not itself appear in $\cb$.

\parcomment{Solving partial instantiations}

Partial instantiation constraints are reduced using the following rules:
\begin{enumerate}

\item
  \Rule{S-Inst-Copy} copies the shape of a type to the instantiation site,
    introducing fresh variables for each subcomponents and marking them with
    corresponding instantiation constraints.
    %
    We write $\cpapp \x \tv \t \inst$ as a shorthand for $\cpinst \inst \tv \t$
    when $\inst$ is bound with $\exists \inst^\x$ in the context. To ensure
    termination, the abstraction must contain acyclic types.

  \item \Rule{S-Inst-Unify} unifies two instantiations if they refer to the
    same source variable.
\end{enumerate}
There are three cases in which an instantiation constraint is eliminated:
\begin{enumerate}
  \item
    A nullary shape is copied and no further instantiations are needed
    (\Rule{S-Inst-Copy}).

  \item
    The copied variable $\tvb$ is polymorphic, and thus the instantiation
    constraint imposes no restriction (\Rule{S-Inst-Poly}), provided no
    other instantiations of $\tvb$ remain (if not, then apply
    \Rule{S-Inst-Unify}).

  \item
    The copy is monomorphic and in scope, so we unify it directly
    (\Rule{S-Inst-Mono}).
\end{enumerate}


%% Uncomment to restore the old style
%% \let \rewrite \hrewrite
\begin{mathparfig}[t]
  {fig:solver-schemes} {Select rewriting rules for let-bindings and
  applications.}
  \rewrite[S-Exists-Lower]
    {\cletr \x \tv {\tvas, \tvbs} \ca \cb\\}
    {\th \cdetermines {\cexists {\tv, \tvas} \ca} \tvbs}
    {\cexists \tvbs \cletr \x \tv \tvas \ca \cb}

  \rewrite[S-Let-AppR]
    {\cletr \x \tv \tvs \c {\C\where{\capp \x \t}}}
    {\tvc \disjoint \t \\
     \x \disjoint \bvs \C}
    {\cletr \x \tv \tvs \c
       {\C\where{\cexistsi {\tvc, \inst} \x
                {\cunif \tvc \t \cand \cpinst \inst \tv \tvc}}}}

  \rewrite[S-Inst-Copy]
    {\cletr \x \tv \tvs {\c}
      \C\where{\cpapp \x \tvp \tvc \inst}}
     {\c = \cp \cand \cunif \tvp {\cunif {\shapp \tvbs} \ueq}\\\\
      \tvp \in \reg \tv \tvs \\
      \neg \cyclic {\c} \\
     \tvbs' \disjoint \tvp, \tvc, \tvbs \\
     \x \disjoint \bvs \C}
    {\cletr \x \tv \tvs {\c}
      \C\where{\cexists {\tvbs'}
          \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}}

  \rewrite[S-Inst-Unify]
    {\cpinst \inst \tv \tvca \cand \cpinst \inst \tv \tvcb}
    {}
    {\cpinst \inst \tv \tvca \cand \cunif \tvca \tvcb}

  \rewrite[S-Inst-Poly]
    {\cletr \x \tv {\tvs} {\ueqs \cand \c}
        {\C\where{\cpapp \x \tvp \tvc \inst}}}
    {\\\cfor \tvp \cexists {\tv, \tvs \setminus \tvp} {\ueqs} \cequiv \ctrue \\
      \tvp \in \reg \tv \tvs \\\\
     \tvp \disjoint \c \\ \inst.\tvp \disjoint \insts \C \\
     \x \disjoint \bvs \C}
    {\cletr \x \tv {\tvs} {\ueqs \cand \c} {\C\where\ctrue}}

  \rewrite[S-Inst-Mono]
    {\cletr \x \tv \tvs \c {\C\where{\cpapp \x \tvb \tvc \inst}}\\}
   {\tvb \notin \reg \tv \tvs \\
     \x, \tvb \disjoint \bvs \C}
    {\cletr \x \tv \tvs \c {\C\where{\cunif \tvb \tvc}}}

  \rewrite[S-Let-Solve]
    {\cletr \x \tv \tvs \ueqs \c\\}
    {\cexists {\tv, \tvs} \ueqs \cequiv \ctrue \\
     \x \disjoint \c}
    {\c}

  \rewrite[S-Compress]
    {\cletr \x \tv {\tvs, \tvb} {\ca \cand \cunif \tvb {\cunif \tvc \ueq}} {\cb}}
    {\tvb \neq \tvc}
    {\cletr \x \tv {\tvs}
       {\ca\where{\tvb \is \tvc} \cand
        \cunif \tvc {\ueq\where{\tvb \is \tvc}}} {\cb\where{\x.\tvb \is \tvc}}}
\end{mathparfig}


\parcomment{Cleaning up partial applications and let constraints}

\Rule{S-Let-Solve} remove a $\Let$ constraint when the bound term
variable is
unused and the abstraction is satisfiable. \Rule{S-Compress} determines that a
regional variable $\tvb$ is an an alias for $\tvc$. We replace every free
occurrence of $\tvb$ with $\tvc$---\emph{including} the domains of any partial
instantiation constraints, written as the substitution $\where{\x.\tvb \is
\tvc}$. We view this as an analogous copy rule for variables.

\parcomment{Lowering}

Rule \Rule{S-Exists-Lower} implements the non-trivial case of lowering
existentials across $\Let$-binders. It identifies a subset of variables in
the region of a $\Let$ constraint that are unified with variables from
outside the region. Such variables are considered monomorphic and thus
cannot be generalized; they can instead be safely lowered to the outer
scope.

\parcomment {Determines}

This is the case when the types of $\tvbs$ are \emph{determined} in a unique
way. In short, $\c$ determines $\tvbs$ if and only if the solutions for
$\tvbs$ are uniquely fixed by the solutions to other variables in $\c$.

\begin{definition}
  $\cdetermines \c \tvbs$ if and only if every ground assignments
  $\semenv$ and $\semenvp$ that satisfy (the erasure of) $\c$ and coincide outside of $\tvbs$
  coincide on $\tvbs$ as well.
  \begin{mathpar}
    \cdetermines \c \tvb \uad\eqdef\uad \all {\semenv, \semenvp} \uad
      \semenv \th \cerase \c
      \wedge \semenvp \th \cerase \c
      \wedge \semenv =_{\setminus \tvbs} \semenvp
      \implies
      \semenv = \semenvp
  \end{mathpar}
\end{definition}

\parcomment {How the determines relation corresponds to ML}

Conceptually, this corresponds to the negation of the generalization condition
in \ML: a type variable cannot be generalized if it appears in the typing
context. In the constraint setting, it cannot be generalized if it depends on
variables from outside the region. For instance, $\cexists \tvba \cunif \tv
{\tvba \to \tvbb}$ determines $\tvbb$, as $\tvbb$ is free.

\parcomment{How to decide the relation}

To decide when $\cdetermines \c \tvs$, we introduce the judgment $\th \cdetermines \c \tvs$,
which syntactically proves that $\tvs$ are determined in $\c$.
%
If $\c$ is of the form $\cexists \tvbs \cp$ where $\tvbs \disjoint \tvs$, then
we search for a multi-equation $\ueq$ in $\cp$ of the form:
\begin{enumerate*}
  \item
    $\cunif \tvc \ueq'$ where $\tvc \disjoint \tvs, \tvbs$ and
    $\tvs \subseteq \fvs {\ueq'}$, or
  \item
    $\cunif \tvs {\cunif \t \ueq'}$ where
    $\fvs \t \disjoint \tvs, \tvbs$.
\end{enumerate*}
%
This syntactic relation coincides with the semantic definition of determinacy whenever
$\c$ is in solved form.

\parcomment{Why we lower?}

Lowering such variables improves solver efficiency. It avoids unnecessary
duplication of work that would otherwise occur via \Rule{S-Inst-Copy}. By
reducing the number of variables that need to be copied, lowering directly
reduces instantiation overhead.

\paragraph{Suspended match constraints}

\begin{mathparfig}[htpb!]
  {fig:solver-susp}
  {Rewriting rules for suspended match constraints.}
  \rewrite[S-Match-Ctx]
    {\C\where{\cmatch \t \cbrs}}
    {\th \Cshape \C \t \sh}
    {\C\where{\cmatched \t {\sh} \cbrs}}

  \infer[Uni-Var]
    {\color{gray}\tv \disjoint \bvs \Cb}
    {\th \Cshape {\Ca\where{\cunif \tv {\cunif \t \ueq} \cand \Cb\where{-}}} \tv {~\shape \t}}

  \infer[Uni-Type]
    {{\color{gray}\t \notin \TyVars}}
    {\th \Cshape \C \t {~\shape \t}}

  \infer[Uni-BackProp]
    {\th \Cshape{\cletr \x \tv \tvs {\Ca\where{\ctrue}} {\Cb\where{\cpapp \x \tvp \tvc \inst \cand -}}} \tvc \sh \\
     \color{gray}\tvp \in \tv, \tvs \\
     \color{gray}\x \disjoint \bvs \Cb \\
     \color{gray}\tvp \disjoint \bvs \Ca}
    {\th \Cshape{\cletr \x \tv \tvs {\Ca\where{-}} {\Cb\where{\cpapp \x \tvp \tvc \inst}}} \tvp \sh}
\end{mathparfig}

\parcomment{S-Match-Ctx}

\Rule{S-Match-Ctx} solves suspended match constraints when the surrounding
context $\C$ \emph{proves} that the scrutinee $\t$ has the unique shape $\sh$,
denoted $\th \Cshape \C \t \sh$.
%
Case \Rule{Uni-Type} handles when $\t$ is a non-variable type $\t$, in which
case the shape is simply $\shape \t$. \Rule{Uni-Var} applies when the scrutinee
is a variable $\tv$ and the context establishes that $\tv$ is equal to some
non-variable type $\t$ by exhibiting an equality $\cunif \tv {\cunif \t \ueq}$
and $\t$ is a non-variable type. In this case, the shape of $\tv$ is $\shape
\t$.
%
Finally, \Rule{Uni-BackProp} expresses \emph{backpropagation}, previously
illustrated in \cref{ex:backprop}. In particular, the shape of a regional
variable can sometimes be determined from its instantiations. If an abstraction
contains a regional variable $\tvp$, and the constraint context includes a
partial instantiation $\cpapp \x \tvp \tvc \inst$ together with a proof that the copy of
$\tvc$ has the unique shape $\sh$. Then $\tvp$ must also have shape $\sh$,
as any other shape would render the instantiation unsatisfiable.
%
This final case (\Rule{Uni-BackProp}) may raise concerns about the well-foundedness of $\th \Cshape \C \t \sh$.
However, well-foundedness follows directly from the fact that in \Rule{Uni-BackProp} the regional depth
of the hole strictly decreases.
%
For a solved context $\hat\C$, this relation is moreover sound and complete with respect
to the semantic definition of unicity (\cref{def:unicity}).

% Properties
% May look like space hacks, but restatable introduces its own space
\Xalistair{@Didier, can you take a look at the new correctness corollary to check if
this is what you wanted in terms of scoping?}

\begin{version}{}
\XDR {Shouldn't we defined a notion of well-scoped constraints and
show that well-scoping is preserved by rewriting rules?}

\XDR {Then, a stuck constraint would either be $\cfalse$ or contain
a suspended constraint.}

\XDR {A stuck constraint may also contain well-scoped
instantiation clauses \emath{\cpapp \x \tv \tvc \inst}
since Rule \Rule {S-Inst-Poly} may not fire because of
$\tvp$ occurring in $\C$}
\Xalistair{Yes, but this is a special case of (d), since
this occurs if $\tv \in \fvs \c$ and $\c$ is stuck. Thus the
`root' cause of the constraint being stuck isn't the instantiation
but the body of the abstraction being stuck.}
\end{version}

\begin{restatable}[Progress]{theorem}{progress}
  \label{thm:progress}
  If constraint $\c$ cannot take a step $\c \csolve \cp$, then either:
  \begin{enumerate}%[(\roman*)]
    \item $\c$ is solved.
    \item $\c$ is stuck, it is either:
      \begin{enumerate*}
      \item
        \label {item/progress/false}
        $\cfalse$;
      \item
        \label {item/progress/scope/x}
        $\hat\C\where{\capp \x \t}$ where $\x \disjoint \hat\C$;
      \item
        \label {item/progress/scope/i}
        $\hat\C\where{\cpapp \x \tv \tvc \inst}$ where
        $\x \disjoint \hat\C$ and $\inst.\tv \disjoint \insts {\hat\C}$;
      \item
        \label {item/progress/suspended}
        for every match constraint $\hat\C\where{\cmatch \tv \cbrs}$ in
        $\c$, $\Cshape {\hat\C} \tv \sh$ does not hold for any $\sh$.

        \Xalistair{Name: stuck suspended constraints?}

      \end{enumerate*}
     Here, $\hat\C$ is a normal context, \ie such that no other
     rewrites can be applied.
  \end{enumerate}
\end{restatable}

%% \vspace{-1ex}
%
%% This is unconditional skiping is fragile, You may insteat will only
%% backskip avalaible extra skip (when there is some)
%
\vskip -\lastskip
\begin{restatable}[Termination]{theorem}{termination}
  \label{thm:termination}
  The constraint solver terminates on all inputs.
\end{restatable}
\vskip -\lastskip
\begin{restatable}[Preservation]{theorem}{preservation}
  \label{thm:preservation}
  If $\ca \csolve \cb$, then $\ca \cequiv \cb$.
\end{restatable}

\begin{corollary}[Correctness]
  For the closed-term-variable constraint $\c$, $\c$ is satisfiable if and only if
  $\c \csolve^* \hat\c$ and $\hat\c$ is a solved form equivalent to $\c$.
\end{corollary}

\section{Implementation}
\label{sec:implementation}

We have two working prototypes implementing the \OML language with suspended
match constraints and partial type schemes, in which we have reproduced the
various type-system features and examples presented in this work.  One
closely follows the constraint-based presentation described
here\footnote{The other prototype is a direct implementation of type
inference based on semi-unification. We mention it here only it indicate
that we have explored multiple implementation strategies leading to the same
results.}. It is public and open-source\footnote {Link omitted for
anonymity.}. Its implementation is inspired by previous work such as
\Inferno~\citep {Pottier/inferno@icfp2014, Pottier/inferno@opam}.  It uses
state-of-the-art implementation techniques for efficiency, such as a
Tarjan's union-find data structure for unification
\citep*{journals/jacm/Tarjan75} and \emph{ranks} (or \emph{levels}) for
efficient generalization \citep*{Remy/mleth}. Let us discuss a few salient
points.

\paragraph{Unification and scheduling}

Each unsolved unification variable maintains a \emph{wait list} of suspended
constraints that are blocked until the variable is unified with a concrete
type. When such a unification occurs, the wait list is flushed: the suspended
constraints are scheduled on the global constraint scheduler, which is
responsible for eventually solving them.

\paragraph{From a stack to a tree}

% To implement generalization (the \Rule{S-Lower-Exists} rule)
% efficiently, we follow the classic rank-based approach to
% generalization. Each $\Let$ constraint and type variable is allocated
% an integer \emph{rank}, which informs us the depth of the region
% within the constraint. Type variables of rank $0$ are bound at the
% top-level region, and type variables of rank $r \geq 1$ are bound in
% the region of $\Let$ constraint at depth $r$.

% As inference progresses, unification may widen the scope of variables,
% thereby lowering their rank. The set of variables eligible for
% generalization at a given region consists precisely of those
% whose rank remains equal to that of the region.

Many standard \ML implementations, for example \Inferno, represent the solver
state as a linear \emph{stack} of inference regions, from the outermost
variable scope to the current region. Unification associates
an integer \emph{rank} (or \emph{level}) for each variable, that indexes the
region in the stack to which it belongs.
%
This approach does not work for partial generalization. If
generalization at some region is suspended by a match constraint, the
region must remain alive while we continue inference in other
regions. However, later parts of the constraint may introduce a new
$\Let$-region at the same rank that is unrelated to the suspended one---neither its
ancestor nor its descendant---breaking the linear assumption of ranks.

Our implementation must instead use a \emph{tree} of nested
$\Let$-regions. Under this scheme, ranks no longer uniquely determine a
variable's region. Instead, we interpret a rank relative to a path in the
region tree from the root. When two variables are unified, they must always
lie on some shared path---by scoping invariants---so computing their minimum
rank (along this path) suffices to determine the lowered region: we keep
the efficient integer comparisons of generalization.

\paragraph{Partial generalization}

Partial generalization arises when a region cannot be fully
generalized due to suspended constraints that may still update
its variables. To manage this, we classify type variables
into four categories:
\begin{itemize}
  %% \let \\ \relax
  \let \Item \item
  \renewcommand \item [1][]{\Item[(\textbf{#1})]}
  \item[I] Variables are yet to be generalized.
    \emph{Introduced by instantiations or source types in constraints}

  \item[G] Variables that are generalized.
    \emph{Not accessible from any instance type; treated polymorphically.}

  \item[PG] Variables that are partially generalizable. %\\
    \emph{Generalizable variables mentioned by suspended match constraint or partial
    instantiations.}

  \item[PI] Variables that were previously partially generalized
    but have since been updated.  %\\
    \emph{Awaiting re-generalization. Introduced by the unification of partial
    generics.}
\end{itemize}
At generalization time, we conservatively approximate whether a variable may be
updated in the future using \emph{guards}. A guard is a mark on a variable that
indicates the variable is captured by some suspended constraint that has not
yet been solved. Guarded variables are generalized as partial generics (\textbf{PG});
unguarded ones are fully generalized (\textbf{G}).

When an instance is taken from a partial generic, we retain a forward reference
from the partial generic (\textbf{PG}) to the instance. This enables the
generic to notify the instance that it has been updated, propagating the
updated type structure to all instances. This mirrors, in reverse, the way our
formalized solver uses partial instantiation constraints to track copies. In
addition, the instance remains guarded by the partial generic until the latter
is either lowered or fully generalized.

Once a suspended match constraint is solved, it removes the guards it
introduced. This may enable previously partial generics to become fully
generalizable. Conversely, if a partially generalized variable is lowered (\eg
by \Rule{S-Lower-Exists}), it must be unified with all its instances.

\paragraph{Lazy generalization} Repeatedly generalizing a region after every
update is expensive.  Instead we generalize on demand. We mark regions as
``stale'' when they may require re-generalization. When an instance is taken,
we re-generalize the stale descendants of the region in the region tree.

\section{Related work}
\label{sec:related-work}

\paragraph{The essence of \ML}

\XDR{Should perhaps be inlined in \cref {sec:solving} or
\cref {sec:semantics}.}

\citet* {Pottier-Remy/emlti} already allow let-constraints to be
copied before being fully solved. However, they copy the whole constraint
including unsolved parts, which duplicates the work of the constraint
resolution.  That is, they still lack a mechanism to incrementally and
efficiently instantiate partial type schemes.  Besides, this is only allowed
in their rewriting rules.  The resolution strategy imposed on top of their
rewriting rules requires that let-constraints be fully solved before being
inlined---and similarly in their accompanying prototype.

%% Unsurprisingly, both implementations based on their framework, described in
%% \url{https://pauillac.inria.fr/~remy/attapl/},
%% follow a \Geninst-directional strategy.



\paragraph{Principality tracking in \OCaml}

\citet*{Garrigue-Remy/poly-ml} introduced an approach to principality tracking
for polytypes (which we called \geninst-directional inference) in which
generalization and instantiation govern the flow of known type information.
Their approach has since been extended to other features of the \OCaml language:
whenever the typechecker need to know if a type is known in a robust way, it
checks whether the type is generalizable.
%% We compared their approach to ours in
It is compared to ours in
%% \cref{sec/introduction} and
\unskip~\cref{sec/constraints/polytypes}.

\paragraph{Bidirectional type inference}

At the level of simply-typed
terms or \ML, we believe that omnidirectional inference works better
than bidirectional type inference: it can type more programs than
a given fixed bidirectional system, and has a more declarative
specification---we would say that it is ``more principal''.  In fact,
a direct inspiration for the present work was a user complaint in
\citet*{rossberg-wasm} on the type-based disambiguation of \OCaml: its
bidirectional logic propagates type information from patterns to
definitions in \code{let}-bindings, when the WebAssembly reference
implementation would sometimes prefer the other direction.
%
% De-anonymizing URL: https://github.com/ocaml/ocaml/issues/7389
%
On the other hand, bidirectional typing is known to scale to powerful
systems such as fully-implicit predicative
polymorphism~\citep*{dunfield-krishnaswami-bidirectional-poly} and we
have not considered scaling our approach to those systems yet.

Contextual typing \cite {Xue-Oliveira/contextual-typing@icfp2024} is a
recent improvement of bidirectional typing that captures more complex flows
of \emph{known} type information, but still suffers from directionality. It
has not been combined with ML-style type inference yet, but this would be
interesting to explore.




\paragraph{Qualified types}

Qualified types~\citep*{jones-qualified-types}, most well-known via their usage
in Haskell type-classes, are related to our suspended match constraints as they
represent constraints on types or type variables. At generalization time, the
constraints on generalizable variables are kept as part of the generalized type
scheme, and they get copied during instantiation. This is much simpler to
implement than our partial type schemes, but it provides a different behavior
where each instance can choose independently how to resolve the constraint.
Qualified types are an excellent choice when this is the desired behavior,
typically for dynamic overloading. To handle cases that require a unique
resolution of the constraint across all instances---such as static
overloading---we require the more complex mechanism of partial generalization.

\paragraph{Suspended constraints in dependent-type systems}

Suspending the constraints that cannot be solved yet is not a novel idea: it
is a standard approach to implement unification dependently-typed
systems. This goes back to Huet's algorithm for higher-order
unification~\citep*{huet-unif} and pattern
unification~\citep*{Miller/pattern-unif@iclp91} where flexible-flexible
pairs are delayed until at least one side becomes rigid. The novelty of our
work lies in combining constraint suspension with \ML-style implicit
polymorphism---absent from most dependently-typed systems---and in the design
of a declarative constraint semantics used to establish principality.

%% \paragraph{Leijen et al. (TODO change paragraph naming)}
%% Should we cite \citet*{Leijen-Ye/prefix@pldi2025}?
%% \Xdidier{I'm volunteering to write this, but we are not sure we have to}.

\paragraph{\OutsideIn}

\OutsideIn~\citep*{conf/icfp/SchrijversJSV09} is a type system for GADTs that
introduces \emph{delayed implications} of the form $\where{\tvs}(\all \tvbs \ca
\Rightarrow \cb)$. Constraint solving for delayed implications proceeds in two
steps; solving simple constraints first and then solving delayed implications.
The deferral ensures that inference for GADT match branches occurs when more is
known about the scrutinee and expected return type from the context.
%
To ensure principality, \OutsideIn enforces an algorithmic restriction: the
variables $\tvs$ must already be instantiated to concrete type constructors
before they may be unified by the implication's conclusion $\cb$. This ensures
information only flows from the outside into the implication's
conclusion. Notably, they do give a declarative specification for this
restriction, using an elegant but mysterious quantification on all possible
ways to type the context outside the GADT clauses. Using our new perspective
on \emph{known} type information, we can say that their semantics enforces
that only \emph{known} information from outside GADT clauses can be used
inside.

Later work on \OutsideIn argues
\citep*{Vytiniotis-Peyton-Jones-Schrijvers-Sulzmann/outsidein@jfp2011}
that delayed implication constraints make local let-generalization all
but unmanageable, both in theory and implementation. Their proposed
fix is to abandon local let-generalization altogether. We believe that
we have solved the troubling interactions between let-generalization
and suspended constraints in this work, and would be interested in
studying applications to GADT typing\XDR[, which was also one of our
original motivations]{Does not bring much to the reader}.

\section{Conclusions and future work}
\label{sec:discussion}
\label{sec:future-work}

%% In this work,
We developed a constraint-based framework for omnidirectional
type inference, capable of supporting fragile features that would otherwise
break principality.
%
Central to our approach is a new declarative account of when a type is
\emph{known} from the context, rather than \emph{guessed}.

Our constraint solver is omnidirectional: constraints may be solved in any
order, made possible by our introduction of \emph{partial type schemes}.
We formalized the solver as a non-deterministic, terminating rewrite system,
and implemented an efficient prototype to demonstrate its practicality.

Through three instantiations of our framework---static overloading of
tuples, nominal records and variant constructors, and semi-explicit
first-class polymorphism---we showed that our framework yields a sound and
complete inference algorithm and a principal type system. In short, it
appears principality holds \emph{anyway} from our approach.
%
Naturally, all this begs the question: what else can be done with
omnidirectional inference beyond the features of \OML?


\paragraph{Static overloading}

Our nominal records use a restricted form of overloading.  We have also
experimented with a more general overloading mechanism in which several
definitions may be bound to the same identifier ${\color{gray}\M.}\x$, but
prefixed with a namespace\footnote {Reusing the notation
of~\citet*{Leijen-Ye/prefix@pldi2025}.}~$\color{gray}\M$ used for
disambiguation: an implicit form $\x$ in the source is elaborated to an
explicit form~$\exover {{\color{gray}\M}} \x$.
%
Although implemented in a prototype, we have not yet
%% identified a satisfactory typing behavior or
formalized this feature.  Nevertheless, we conjecture
that it should be typable with our framework.

Modular implicits \citep*{White-Bour-Yallop/Modular_Implicits/ml2014} are a
proposed extension to \OCaml's module system, intended to support ad-hoc
polymorphism through type-directed implicit parameters. We believe
omnidirectional type inference could serve as a principled, constraint-based
approach foundation for resolving implicits in the presence of
let-generalization.
%
As future work, we aim to extend our constraint language to typecheck an
implicit-parameters calculus, similar to \COCHIS
\citep*{journals/jfp/SchrijversOWM19}, but with \ML polymorphism.


\paragraph{Higher-rank polymorphism}

In \cref{sec/introduction} and \cref{sec:related-work}, we compared
omnidirectional and bidirectional type inference in the context of static
overloading. While overloading is non-trivial, it poses little challenge for the
bidirectional framework, making the comparison somewhat limited. Bidirectional
typing is best known for its scalability to more complex settings, such as
higher-rank polymorphism. We are therefore interested in extending our
framework to support higher-rank polymorphism, in the style of
\citet*{dunfield-krishnaswami-bidirectional-poly}. This would provide a more
meaningful basis for understanding the trade-offs of omnidirectional and
bidirectional inference.

\MLF is an extension of \ML that support first-class polymorphism that
goes beyond the power of System $\F$, while retaining type inference.
It is a generalization of \OCaml's polytypes, relying on \geninst-directionality.
It would therefore be worth exploring whether omnidirectional type inference
could further empower \MLF.

\paragraph{Default rules}

Some type systems disambiguate fragile constructs using known type information,
but fall back on default, non-principal choices when none is available. \OCaml
selects the most recent matching record type in scope for ambiguous field
names; \SML assigns default types to overloaded numeric
literals~\citep*[Section 5.8]{rossberg-hamlet}.

We explored adding such \emph{default rules} to suspended match constraints,
allowing unresolved constraints to discharge with a default shape rather
than fail. Using default shapes rather that default types ensures that the
default behavior could also have been obtained by adding an extra shape
annotation in the code.
%
While pragmatic, such rules are inherently non-principal and difficult to
reconcile with our framework.  In particular, they introduce subtle semantic
complexities: if two suspended constraints could unlock each other, then
defaulting one over the other may force an unsatisfiable branch to be taken.
%
%% Still, we can formulzate some good propeties that a strategy for firing
%% defaulting rules should satisfy.  It appears that under some reasonable
%% blackbox asumptions (the stategy cannot explore the suspended constraints,
%% but only know type variables they may contraint), there is actually an
%% optimal strategy.

Is there an optimal or principled strategy for applying defaults in such
cases? Should we fire all default rules of all suspended
constraints that remain after the solver terminates simultaneously, or in
batches, \eg. restricted to connected components of mutually dependent suspended
constraints?  Our prototype opts for the latter, but this warrants further
study. More details can be found in Appendix \cref {app/default-rules}.

%%\paragraph{Behavior of default rules} Giving priority to most recent
%%definitions is a possible default behavior for field and constructor
%%disambiguation. For structural tuples there is no reasonable default
%%rule.
%
%%For polytypes, one option is to fallback to a monomorphic polytype. The
%%other one is to pick the principal type scheme of the expression with an
%%unresolved polytype. Of course, there are examples that favor one choice
%%and other examples that favor the other.

\paragraph{Equi-recursive types}
\label {sec/rec-types}

\OCaml allows equi-recursive types to express recursive polymorphic variants
and objects types. Supporting such types is a necessary step towards integrating
our approach into \OCaml's typechecker.
%% In this work,
For the sake of simplicity, we treated ground types as finite
trees. Supporting equi-recursive types amounts to using regular trees instead
\citep*{Pottier-Remy/emlti}. Our prototype already supports them,
but the formalization of our solver relies on acyclicity to ensure
termination.  Extending the formalization to accommodate cycles would
require some changes.  Following the implementation, incremental
instantiation might require to instantiate cycles atomically.

Shapes may also be equi-recursive, though only minimal shapes of polytypes
can be recursive. In the acyclic setting, shape equality is syntactic; with
cycles, this no longer holds---but we do not anticipate any fundamental issues.

% \begin{acks}
% \end{acks}

%% \bibliographystyle{ACM-Reference-Format}
\begin{local}
\let \t \latext \let \c \latexc

\bibliography{suspended}
\end{local}

\newpage
\appendix

\section*{\Large Organization of appendices}
\label{app:outline}

\begin{local}
\renewcommand{\paragraph}[1]{\subsubsection*{#1}}

\paragraph{Content appendices.} These appendices are intended to be
readable prose in the style of the rest of the paper.

\begin{itemize}
\item
  \cref{app/oml} presents and explains the typing rules for \OML;
  this is the long version of \cref{sec:language}.
\item
  \cref{app:unification} presents a relatively standard part of our
  constraint solver (\cref{sec:solving}), namely the unification rules.
%%\item \cref{app:more-discussion} contains topics of discussion that we
%% did not have the space to include in \cref{sec:discussion}.
\end{itemize}

\paragraph{Reference appendix}
\begin{itemize}
\item \cref{app:full-reference} gives a full reference for all
  definitions, grammars and figures in the paper, including all cases
  (even those omitted from the main paper for reasons of space).
\end{itemize}

\paragraph{Proof appendices} These appendices contain proofs for the
formal claims in the article. They are typically written tersely.
\begin{itemize}
\item \cref{app:proofs-constraints} proves properties of the
  constraint language and its semantics. The main result is
  canonicalization, which morally establishes that uses of the
  contextual rule \Rule{Match-Ctx} can be ``permuted down'' in the
  proof until they are all at the bottom of the derivation, followed
  by a proof on a simple constraint.
\item \cref{app:proofs-solving} proves the correctness of the
  constraint solver with respect to the semantics.
\item \cref{app/oml/proofs} proves the properties about the \OML
  type system, in particular the correctness of constraint generation.
\end{itemize}

\end{local}


\section{The \OML calculus: typing rules and constraint generation}
\label{app/oml}

The \OML calculus extends \ML with three fragile constructs: structural
tuples, polytypes, and nominal records.  Each fragile construct $e^i$ is
paired with a robust counterpart $e^x$, which carries more explicit type
information and admits straightforward typing rules. Typing rules for the
original \ML calculus, together with those for the robust forms of
structural tuples, polytypes and nominal records, are given in
\cref{app/oml/typing/X}. The robust typing of nominal records, includes the
more intricate (yet largely folklore), treatment of \emph{closed world}
reasoning.

The crux of our work is the novel typing of all three fragile constructs,
presented in~\cref {app/oml/typing/I}, and illustrated with examples in \cref
{app/oml/examples}.  Constraint generation corresponding to these typing rules
is described in \cref{app/oml/constraints}. Finally, the metatheoretical
results for \OML are presented in~\cref {sec/oml/metatheory} and proved
in~\cref {app/oml/proofs}.

\subsection{Typing rules for robust, explicit constructs}
\label{app/oml/typing/X}

\begin{mathparfig}[t]{fig/typing/core}{Traditional \ML typing rules in \OML.}
  \inferrule[Var]
    {x : \sigma \in \G}
    {\G \th x : \sigma}

  \inferrule[Fun]
    {\G, x : \ta \th e : \tb }
    {\G \th \efun x e : \ta \to \tb}

  \inferrule[App]
    {\G \th \ea : \ta \to \tb \\
     \G \th \eb : \ta}
    {\G \th \eapp \ea \eb : \tb}

  \inferrule[Unit]
    { }
    {\G \th () : 1}

  \inferrule[Gen]
    {\G \th e : \sigma \\ \tv \disjoint \G}
    {\G \th e : \tfor \tv \sigma}

  \inferrule[Inst]
    {\G \th e : \tfor \tv \ts}
    {\G \th e : \ts \where{\tv \is \t}}

  \inferrule[Let]
    {\G \th \ea : \sigma \\\\
     \G, x : \sigma \th \eb : \t}
    {\G \th \elet x \ea \eb : \t}

  \inferrule[Annot]
    {\G \th e : \t\where {\tvs \is \tys}}
    {\G \th (e : \exi \tvs \t) : \t\where {\tvs \is \tys}}
\end{mathparfig}

\begin{version}{}
\TODO

  {We should consider handling the three features (tuples, records,
  polytypes) separately, one in each subsection. If we later run out of
  space budget it will be easier to move only some of those subsections to
  an appendix.  Concrete proposal:
\begin{itemize}
\item
  one subsection at the beginning that only hints at the standard ML stuff:
  show the syntax, hint at typing rules, show a short bit of constraint
  generation
\item
  then each advanced feature (from the simplest to the more complex: tuples,
  polytypes, records) show the typing rules, and examples, and its dedicated
  patterns, and its constraint generation
\end{itemize}}
\end{version}

\parcomment {Simple typing rules explained}
As usual, the main typing judgment $\G \th \e : \ts$ states that in
context~$\G$, expression~$\e$ has type scheme~$\ts$.
%
For completeness, we recall the typing rules of the standard \ML calculus
in \cref{fig/typing/core} and briefly review them here.

%
\XDR{Why removing \emph{Rule} in front of single-rule names?}
\Rule{Var} retrieves the type scheme $\x : \ts$ from the context $\G$.
Function types are introduced via lambda abstractions: in \Rule{Fun}, the
system guesses a well-formed type $\ta$ for the type of $\x$, typechecks the
body $e$ is under the extended context $\G, \x : \tya$ producing the return
type $\tyb$, and assigns the abstraction the function type $\tya \to \tyb$.
Conversely, function types are eliminated by applications; in
\Rule{App}, the type of the argument must match the function's parameter
type $\tya$ and application returns the type $\tyb$. \Rule{Unit}
asserts that $\eunit$ has the unit type $\tunit$.
%
\parcomment {Gen/Inst variant explained}
%
Rules \Rule{Gen} and \Rule{Inst} correspond to implicit
\textit{generalization} and \textit{instantiation} respectively.
Generalization universally quantifies a type variable $\tv$, introducing it
as a fresh polymorphic variable in the typing context. In \Rule{Inst}, we
specialize a type scheme $\tfor \tv \ts$ to $\ts \where{\tv \is \t}$,
substituting $\tv$ for an arbitrary monotype $\t$.
%
\parcomment {Let rule}
%
Let-polymorphism is handled by the \Rule{Let} rule, where a
\textit{polymorphic} term can be bound. This allows a single definition to be
instantiated differently at each use site---an essential feature of \ML. In
this rule, the term $\ea$ has a polymorphic type scheme $\ts$, adds $\x :
\ts$ into the context $\G$ to typecheck $\eb$.
%
\parcomment {Annotations}
%
Finally, annotations $\eannot \e \tvs \t$ ensures that the type of $\e$ is
(an instance of) the type $\t$. The type variables $\tvs$ are
\emph{flexibly} (or existentially) bound in $\t$, meaning that $\tvs$ may be
unified with some types $\tys$ to produce a well-typed term. For instance,
the term $(\efun \x \x + 1 : \exi \tv \tv \to \tv)$ is well-typed with
the substitution $\where {\tv \is \tint}$ in \Rule{Annot}.


\begin{mathparfig}[t]{fig/typing/X}
        {Typing rules of \OML---robust, explicitly typed extensions.}
\mprset{sep=1.75em}
  \inferrule[Tuple]
    {\parens{\G \th \ei : \ti}\iton}
    {\G \th (\ea, \ldots, \en) : \Pi\iton \ti}

  \inferrule[Proj-X]
    {\G \th \e : \Pi\iton \ti \\
     1 \leq j \leq n}
    {\G \th \exproj \e j n : \tj}

  \inferrule [Poly-X]
    {\G \th \e : \ts\where {\tvs \is \tys}}
    {\G \th \epoly[\exi \tvs \ts] \e : \tpoly {\ts \where {\tvs \is \tys}}}

  \inferrule [Use-X]
    {\G \th \e : \tpoly \ts \where {\tvs \is \tys}}
    {\G \th \exinst e \tvs \ts : \ts \where {\tvs \is \tys}}

  \inferrule[Rcd-X]
    {\parens{\G \th \ei : \ti}\iton \\\\
     \parens{{\labfrom \elabi \T} \leq \t \to \ti}\iton \\
     \dom {(\Labenv[\T])} = \elabs}
    {\G \th \exrecord \T {\elaba = \ea; \ldots; \elab_n = \en} : \t}

  \inferrule[Rcd-Closed]
    {\G \th \exrecord \T {\overline{\elab = \e}} : \t \\
     \labsuni \elabs \T }
    {\G \th \erecord {\overline{\elab = \e}} : \t}

  \inferrule[Rcd-Proj-X]
    {\G \th \e : \tya \\ {\labfrom \elab \T} \leq \tya \to \tyb}
    {\G \th \exfield \e \T \elab : \tyb}

  \inferrule[Rcd-Proj-Closed]
    {\G \th \exfield \e \T \elab : \t \\
     \labuni \elab \T}
    {\G \th \efield \e \elab : \t}

  \inferrule[Lab-Inst]
    {\labenv(\labfrom \elab\T) = \tfor \tvs {\Tapp \tvs} \to \t}
    {{\labfrom \elab \T} \leq \Tapp \tys \to \t\where{\tvs \is \tys}}
\end{mathparfig}

\paragraph {Typing rules for explicit tuples and polytypes}

The typing rules for tuples and polytypes are given in \cref {fig/typing/X}.
These rules are straightforward and largely considered folklore.
%
\parcomment{Structural tuples}
%
\Rule {Tuple} introduces tuple types in the expected way, assigning an $n$-ary
tuple expression the type $\tProd \ti$. Conversely, \Rule {Proj-X} eliminates
tuple types by projecting the $i$-th component from a tuple of an explicit size $n$.
%
\parcomment{Polytypes}
%
Explicit polytypes likewise have introduction and elimination forms. When
the annotation is a closed type schemes $\ts$ ($\tvs$ is empty), \Rule
{Poly-X} introduces a first-class polytype $\tpoly \ts$, requiring the
expression $\e$ to be at least as polymorphic as $\ts$. \Rule {Use-X}
eliminates a first-class polytype $\tpoly \ts$ into the type scheme $\ts$,
which may then be freely instantiated (via \Rule{Inst}).
Both rules also allow polytype annotations to be partial,
\ie $\ts$ to have free type variables $\tvs$, which
should be existentially quantified so that the annotation is itself
closed\XDR{Should we put this invariant as a premise?};
then, \emph{monotypes} $\tys$ will be inferred for $\tvs$.


\paragraph{Typing rules for explicit nominal records}
\label {app/typing/X/records}

\parcomment{Nominal records}

The rules for overloaded nominal records are a bit more technical.
%% , as we allow disambiguation by qualified labels $\labfrom \elab \T$
We assume that record types have been previously defined, building a global
environment $\labenv$ that maps labels to their projection type, \ie type
schemes of the form $\all \tvs \Tapp \tvs \to \t$. A label $\elab$ may
belong to several record types, but it is unique within a given record type
$\T$ (if defined).

We write $\Labenv$ for the restriction of $\labenv$ to the labels of $\T$:
${\Labenv} \eqdef \set {\elab : \all \tvs \T \tvs \to \t
\in \labenv}$ . Hence, $\dom (\Labenv)$ is
the set of labels belonging to type $\T$,  and $\labtyp \elab$,
abbreviated as $\labenv (\labfrom \elab \T)$, is (when defined) the unique
type scheme $\tfor \tvs {\Tapp \tvs} \to \t$ associated to $\elab$ in type $\T$.

Label instantiations are typed by an auxiliary judgment ${\labfrom \elab
\T} \leq \tya \to \tyb$, defined by \Rule{Lab-Inst}. Explicit field
projections are typed by \Rule{Rcd-Proj-X}, which asserts that an explicitly
annotated label can project from a record $\e$ of type $\tya$, yielding
$\tyb$, provided that $\tya \to \tyb$ is an instance of the projection type
of $\labfrom \elab \T$.
%
Explicit records (\Rule {Rcd-X}) are typed similarly, checking that each field
has the appropriate type. In addition, the premise $\dom {(\Labenv)} = \elabs$
ensures that the set of labels underlying~$\elabs$ is exactly the set of labels
of the record type~$\T$.

\parcomment {Closed world reasoning}

Our explicit system also supports \emph{closed-world} reasoning, which exploits
the absence of ambiguity in the global environment $\labenv$ to infer nominal
record type annotations.
%
In particular, in a record expression $\erecord {\elaba = \ea; \ldots; \elab_n
= \en}$, if the set of labels ${ \elaba, \ldots, \elab_n }$ uniquely identifies
a record type $\T$ in the typing context $\labenv$, then the record has the
type of $\exrecord \T {\elaba = \ea; \ldots; \elab_n = \en}$ (via
\Rule{Rcd-Closed}).
%
Similarly, if the label $\elab$ is associated with exactly one record type $\T$
in $\labenv$, then the projection $\efield \e \elab$ has the type of $\exfield
\e \T \elab$ (by \Rule{Rcd-Proj-Closed}).

These two forms of uniqueness are not equivalent. A \emph{closed set} of labels
may uniquely identify a record type without any of its constituent labels begin
unique. Conversely, if a label is unique, any closed set containing it is also
unique. For instance, consider the program:
\begin{program}[input]
  type point  = { x : int; y : int }
  type cpoint = { x : int; y : int; c : color }
\end{program}
\programjoin[-1ex]
\begin{program}[input]
  let ex_1_2 = { x = 42; y = 1337 }           °\ocamlflags 00°
\end{program}
\XDR{I changed the examples to show that the types of fields are
irrelevant---they do not help disambiguate}
Here the label set $\set {x, y}$ in \code{ex_1_2} uniquely identifies
\code{point}, even though the individual labels $x$ and $y$ are not unique
(both also appear in \code{cpoint}).
%
\XDR{I understand that $\labuni \elab \T$ should be distinct from $\labsuni
\elabs \T$, since when $\elabs$ is a singleton, they do not mean the same
thing, but it should note resemble $\eshape \E \e \sh$ and $\Eshape \E \e \sh$,
which instead involve types. Hence, we should use another symbol for $\elab
\labuni \T$}

We formalize uniqueness using the judgments\XDR{We should rather use math
predicates than judgments and present them in math rather than with one
clause inference rules. I think this would give a simpler reading.}
$\labuni \elab \T$ (a label uniquely identifies $\T$) and $\labsuni \elabs
\T$ (a closed label set uniquely identifies $\T$):
\begin{mathpar}
  \inferrule
    {\elab \in \dom {(\Labenv)} \\\\
     \forall \Tp, \;
        \parens {\elab \in \dom {(\Labenv[\Tp])} \implies {\T} = \Tp}}
    {\labuni \elab \T}

  \inferrule
    {\dom {(\Labenv)} = \elabs \\\\
     \forall \Tp, \;
        \parens {\dom {(\Labenv[\Tp])} = \elabs \implies {\T} = \Tp}}
    {\labsuni \elabs \T}
\end{mathpar}
Notice that these predicates only depend on the global environment
$\labenv$, and require no contextual information and ignore the types of
fields. They are used in the two robust typing rules \Rule {Rcx-X} and
\Rule {Rcd-Proj-X} to ensure that there is actually
no type-directed overloading is involved.


\subsection {Typing rules for fragile, implicit constructs}
\label{app/oml/typing/I}


\begin{mathparfig}[htpb!]{fig/typing/I}
        {Typing rules for fragile, implicitly typed extensions.}
  \inferrule[Magic]
    {\parens{\G \th \ei : \ti}\iton}
    {\G \th \emagic \es : \tp}

  \inferrule[Proj-I]
    {\eshape \E \e {\any \tvcs \Pi\iton \tvcs} \\\\
     \G \th \E\where{\exproj \e j n} : \t}
    {\G \th \E\where{\eproj \e j} : \t}

  \inferrule [Use-I]
    {\eshape \E  \e {\any \tvcs \tpoly \ts} \\\\
     \G \th \E\where{\exinst \e \tvcs \ts} : \t}
    {\G \th \E\where{\einst \e} : \t}

  \inferrule [Poly-I]
    {\Eshape \E \e {{\any \tvcs \tpoly \ts}} \\\\
     \G \th \E \where{\epoly[\exi \tvcs \ts] \e} : \t}
    {\G \th \E \where{\epoly \e} : \t}
\\
  \inferrule[Rcd-I]
    {\Eshape \E \es {\any \tvcs \Tapp \tvcs} \\
     \G \th \E\where{\exrecord \T {\overline{\elab = \e}}} : \t }
    {\G \th \E\where{\erecord {\overline{\elab = \e}}} : \t}

  \inferrule[Rcd-Proj-I]
    {\eshape \E \e {\any \tvcs \Tapp \tvcs} \\
     \G \th \E\where{\exfield \e \T \elab} : \t}
    {\G \th \E\where{\efield \e \elab} : \t}
\end{mathparfig}

We now turn to the typing of fragile implicit constructs, given in
\cref{fig/typing/I}. While typing
rules for fully annotated terms ($\e^x$) are standard and unsurprising,
%% part of folklore knowledge,
typing rules for terms  with omitted type annotations ($\e^i$)
are new---and non-compositional.
%
They all share a common framework that ensures that some omitted type
annotations are uniquely determined from the context. Still, each construct
requires a specific instantiation of the framework.
%
We first describe the framework, then present each feature separately,
starting with the easiest case---structural tuples.

\paragraph{Uniquely determined shapes}

Typing rules for fragile features depend on a surrounding one-hole context
$\E$. They assert that the typability of the expression $\G \th \E \where
{\e^i}: \t$ where $\e^i$ is an expression with an implicit annotation.
%
We first request a typing for the expression with an explicit annotation $\G
\th \E \where {\e^x}: \t$ where $\e^x$ is a fully annotated variant of $\e^i$.
We then request that (the shape of) the annotation is fully determined from
context, either from the type of the expression $\e$, which we write $\eshape
\E \e \sh$, or from the type of the hole containing subexpressions $\es$, which
we write $\Eshape \E \es \sh$.

In order to describe the judgments $\eshape \E \e \sh$ and $\Eshape \E \es
\sh$, we introduce a \emph{typed hole} construct~$\emagic \es$. Here,~$\es$
is treated as a collection of expressions that are well-typed in the current
environment (\Rule{Magic}) but whose types are independent of the type of
the hole: the hole itself may be assigned an arbitrary type.  It is a
key\XDR{We never enforce this} that typed holes are not allowed in source
terms and are just a device for the definition of non-ambiguous shapes.

\XDR{I think the infer/checking modes counter-intuitive as we are always
\emph{inferring} the shape. So,  I change the wording from here till to the
end of the section as an attempt to better carry the flow of information.  I
am also more explicit on the reading of typing rules emphasized that once
the shape has been inferred the rule always calls/behaves as its explicit
counterpart.}

Finally, we formalize what it means for a shape $\sh$ to be determined
from the type of either
\begin{enumerate*}
\item an expression $\e$ in the context $\E$, written
$\eshape \E \e \sh$, or
\item the context hole of $\E$ containing
expressions~$\es$, written $\Eshape \E \es \sh$:
\end{enumerate*}
\begin{mathpar}
\def \Eqdef {&\eqdef&}
{\begin{tabular}{RCL}
\eshape \E \e \sh \Eqdef
  \forall \G, \t, \gt, \uad
  \G \th \eerase {\E \where {\emagic {\eannot \e {} \gt }}} : \t
      \wide\implies \shape \gt = \sh
\\[1ex]
\Eshape \E \es \sh \Eqdef
  \forall \G, \t, \gt, \uad
      \G \th \eerase {\E\where{\eannot {\emagic \es} {} \gt}} : \t
      \wide\implies \shape \gt = \sh
\end{tabular}}
\end{mathpar}
As with unicity in constraints, we must
erase implicit constructs in the term that have not yet been elaborated,
written $\eerase \e$ (defined in \cref{app/ref/eerase}).

\paragraph{Overloaded tuples and polytypes}

The implicit rule \Rule{Proj-I} types the projection $\eproj \e j$ as as
$\eproj[n] \e j$ provided the shape of the type of $\e$ in context $\E$
is a tuple of arity $n$.
%
Similarly, Rule \Rule{Use-I} permits instantiating a polytype in expression
$\einst e$ as in expression $\einst[\exi \tvcs \ts] \e$ provided the shape
of the type of $\e$ in the context $\E$ is $\any \tvcs \tpoly \ts$.
%
Rule \Rule{Poly-I} types the implicit boxing construct $\epoly \e$ as
$\epoly [\exi \tvcs \ts] \e$ provided the context $\E$ with
expressions $\e$ expects a polytype of shape $\any \tvcs \tpoly \ts$.
%
This rule differs from the previous two as the shape is determined by the
ztype of the context hole as opposed to the type of $\e$.


\paragraph{Overloaded record labels}

We adopt a similar non-compositional approach for elaborating overloaded
labels, whether in record projection ($\efield e \elab$) or record construction
($\erecord {\overline{\elab = \e}}$).
%
Typing record projections in \Rule{Rcd-Proj-I} is analogous to tuple
projections: the projection $\efield \e \elab$ is typed as $\exfield  \e
\Tapp \elab$ provided the shape of the type of expression $\e$ in context
$\E$ is a nominal record $\any \tvcs \Tapp \tvcs$.
%
Similarly to polytypes, Rule \Rule{Rcd-I} types an overloaded record
$\erecord {\overline{\elab = \e}}$ as $\exrecord \T {\overline{\elab =
\e}}$, provided the context $\E$ with expressions $\es$ expects a nominal
record type of shape $\any \tvcs \Tapp \tvcs$.  This rule differs from \Rule
{Poly-I} in the use of several subexpressions that may appear in the unicity
judgment, since any field assignment expression can contribute to
determining the record's type, \eg as in the expression
\relax
$\efun r r = {\erecord { x = (r :\ \mathtt{cpoint}).x; y = 10 }}$.
\XDR{I do not understand the example: here the type of the record
$\set { x = \ldots; y = \ldots}$is
fully determined by the two fields $\set {x, y}$ without any type
information, as explained just above. We need another conflicting
definition, e.g. as follows.}
\begin{program}[input]
type surface = { x : int; y : int}              °\ocamlflags 10°
$\efun r r = {\erecord { x = (r :\ \mathtt{point}).x; y = 10 }}$.
\end{program}




\subsection {Examples of typings}
\label {app/oml/examples}

The following lemma shows that we can always take a larger context $\E$ for
implicit rules \Rule {Proj-I}, \Rule {Use-I}, \Rule {Poly-I}, \Rule{Rcd-I},
and \Rule{Rcd-Proj-I}.  That is, there is always a derivation using only
toplevel contexts.
\begin{lemma}
\label{lem/context/largest}
\newcommand {\Eab}{\parens{\Ea\where \Eb}}
If $\eshape \Eb \e \sh$, then $\eshape \Eab \e \sh$. Similarly, if $\Eshape \Eb \es \sh$, then $\Eshape \Eab \es \sh$.
\end{lemma}

% Examples
We now illustrate the typing of implicit constructs with a few examples.
\begin{example}
To illustrate a simple case of non-typability, we show that the expression $e$
equal to $\efun \x {\eproj \x k}$ is ambiguous, \ie that it does not
typecheck.
%
%% Let $e_n$ be the explicitly annotated version $\efun r
%% {\eproj[n] \x i}$. for $n \le k$.
If there is a derivation of $\efun \x
{\eproj \x k}$ then there must be one of the form:
\begin{mathpar}
\infer*[Right=Proj-I]{
                  \eshape \E \x {\any \tvcs \Pi\iton \tvcs} \\
                \eset \th \E \where {\eproj[n] \x k} : \t
}{%             -------------------------------------------
                  \eset \th \E \where {\eproj \x k} : \t
}
\end{mathpar}
where $E$ is the term $\efun \x \ehole$, which is the largest possible
context, thanks to~\cref {lem/context/largest}.
%
Let $\t$ be $\Pi\iton \ti \to \t_k$ for some $n \geq k$.  We have the
following derivation:
\begin{mathpar}
\infer* [Right=Fun]{
          \infer*[Right=Proj-X]
                {\x : \Pi\iton \ti \th \x : \Pi\iton \ti}
                {\x : \Pi\iton \ti \th \eproj[n] \x k : \t_k}
}{%      ----------------------------------------------------------
         \eset \th \E \where{\eproj[n] \x k} : \t
}
\end{mathpar}
Unfortunately, $\eshape \E  \x {\any \tvcs \Pi\iton \tvcs}$ does not hold.
  Indeed, we have $\eset \th \E \where {\emagic {\eannot \x {} {\gt}}} : \t$
for any $\gt$ assuming $\t$ is of the form $\gt \to \tp$.
Hence, $\any \tvcs \Pi\iton[n] \tvcs$ and $\any \tvcs \Pi\iton[n+1] \tvcs$
are two possible shapes for the type of $\x$.
\end{example}

\begin{example}
\locallabelreset
We now illustrate a non-ambiguous example, showing that the
expression $e$ equal to $\th \eapp {(\efun \x {\eproj
\x  1})} {(1, 2)} : \tint$.
%
%
Let $\E$ be the context $\eapp {(\efun \x \ehole)} {(1, 2)}$.  We
have the derivation:
\begin{mathpar}
\infer* [Right=Proj-I]{
		\eshape \E \x {\any {\tvca, \tvcb} \tvca \tprod \tvcb} \\
                \eset \th \E \where {\eproj[2] \x 1} : \tint
}{%             -------------------------------------------
                  \eset \th \E \where {\eproj \x 1} : \tint
}
\end{mathpar}
We have $\eset \th \E \where {\eproj[2] \x 1} : \tint$, indeed. Therefore, it
just remains to show $\eshape \E \x {\any {\tvca, \tvcb} \tvca \tprod \tvcb}$~\llabel C.
Assume $\eset \th \E \where{\emagic {\eannot \x {} \gt}} : \t$. Since $\x : \tint \tprod \tint$
is bound in the context at the hole in $\E$,
there is no other choice but take $\gt$ equal to $\tint \tprod \tint$,
hence $\shape \gt = \any {\tvca, \tvcb} \tvca \tprod \tvcb$, which proves~\lref C.
\end{example}

The following example of non-typability illustrates how the typing rules
still forces to reject typing of some expressions whose elaboration would be
unambiguous. This is intended, to prevent us from having to focus at several
terms simultaneously. Our typing rules enforce the resolution of
shape inference, locally, one occurrence at a time.

\begin{example}
\newcommand{\tyid}{\ty_{\kwd{id}}}
  \newcommand{\eid}{\efun z z}
\newcommand {\epid}[1][]{\epoly[#1]{\eid}}
Let $\tyid$ be $\tpoly{\all \tv \tv \to \tv}$.
%
We show that the expression $e$ equal to $\elet \x {\epoly {\efun z z}}
{(\eapp {\einst \x} 1, \eapp {\einst \x} \eunit)}$ is rejected as ambiguous.
Let $\tyid$ be $\tpoly {\all \tv \tv \to \tv}$.  Clearly, we have $\elet \x
{\epoly [\tyid] {\efun z z}} {(\eapp {\einst[\tyid] \x} 1, \eapp
{\einst[\tyid] \x} \eunit)}$.  This is actually the only possible fully
annotated derivation.
%
To show that $e$ is typable, we must be able to make all annotations
optional, sequentially.  Therefore, the final step, which will eliminate the
last annotation has a single point of focus of the form $\E\where{e^i}$,
where $\e^i$ can be any of the three positions with a missing annotation.  We
consider each case independently, and show that it is actually not typable.
\begin{proofcases}
\proofcase
{$\E$ is $\elet \x \ehole (\eapp {\einst \x} 1, \eapp {\einst \x}\eunit)$}
%
If this holds, we should have a derivation that ends with
\begin{mathpar}
\infer*[Right=Poly-I]{
		  \Eshape \E \eid {\tpoly \tyid} \\
                  \eset \th \E \where {\epid [\tyid]}: \t
}{%               ---------------------------------------
                       \eset \th \E \where \epid : \t
}
\end{mathpar}
However, $\Eshape \E \eid {{\tpoly \tyid}}$ does not hold.
Indeed, the following judgment
$\eset \th \E \where {\eannot {\emagic \eid} {} {\tpoly \ts}} : \t$ holds, where
$\ts$ is either $\tfor \tv \tv \to \tv$ or $\tfor \tv \tv \to
\tv\to\tv$. Hence, the shape of the type of $\eid$ is not uniquely
determined and this case cannot occur.

\proofcase
{$\E$ is
    $\elet \x {\epid} {\eapp {\einst \ehole} 1, \eapp {\einst \x} \eunit}$}
%
The derivation must end with:
\begin{mathpar}
\infer*[Right=Use-X]{
		  \eshape \E \x {\tpoly \tyid} \\
                \eset \th \E \where {\einst[\tyid] \x} : \t
}{%             -------------------------------------------
                    \eset \th \E \where {\einst \x} : \t
}
\end{mathpar}
However, $\eshape \E \x \tyid$ does not hold (the proof is similar to the
previous case).

\proofcase {$\E$ is  $\elet \x \epid {(\eapp {\einst \x} 1, \eapp
  {\einst \ehole} \eunit)}$} This is symmetric to the previous case, which cannot
hold either.
  \end{proofcases}
\end{example}

\begin{example}
Let $\e$ be $\elet f {\efun \x {\eproj \x 1}} {\eapp f (1, 2)}$.
$\e$ is well-typed using \emph{backpropagation}.
$\e$ is of the form $\E \where {\x}$ where  $\E$ is the context $\elet f
{\efun \x \ehole} {\eapp f (1, 2)}$.
We have $\eset \th \E \where {\eproj[2] \x 1} : \tint$.
Let us show that $\eshape \E \x {\any {\tvca, \tvcb} \tvca \tprod \tvcb}$.
%
Assume $\eset \th \E \where {\emagic {\eannot \x {} \gt} } : \t$. As $\gt$ is a ground
type, the type $\gt$ of $\x$ is not a variable.  Then, $\gt$ cannot be that
of an arbitrary sized tuple, since there is no such type for a tuple of
arbitrary size. Hence, $\gt$ must be a tuple $\Pi\iton \tys$ for some size
$n$. Since the codomain of $f$ must be a tuple of size~$2$ (for $\eapp f (1,
2)$ to be well-typed), then $n$ must also be $2$. This shows that $\eshape \E
\x {\any {\tvca, \tvcb} \tvca \tprod \tvcb}$.
%% \begin{mathpar}
%%   \infer
%%     {
%%     \infer
%%       {
%% 	\infer
%% 	  {
%% 	    \infer
%% 	      {
%% 		\infer
%% 		  {}
%% 		  {\tva, \tvb, x : \tva \th x : \tva}}
%% 	      {\tva, \tvb, x : \tva \th \ecast x \tva \tvb : \tvb}}
%% 	  {\tva, \tvb \th \efun x {\ecast x \tva \tvb : \tva \to \tvb}}}
%%       {\emptyset \th \efun \x \ecast \x \tva \tvb : \tfor {\tva, \tvb} \tva \to \tvb} \\
%%     \infer
%%       {\ldots}
%%       {f : \tfor {\tva, \tvb} \tva \to \tvb \th \eapp f (1, 2) : \tunit}}
%%     {\emptyset \th \elet f {\efun \x {\ecast \x \tva \tvb}} {\eapp f (1, 2)} : \tunit}
%% \end{mathpar}
\end{example}


\subsection{Constraint generation}
\label{app/oml/constraints}

% Intro
We now present the formal translation from terms $\e$ to constraints $\c$,
such that the resulting constraint is satisfiable if and only if the term is
well typed. The translation is defined as a function $\cinfer \e \tv$, where $\e$
is the term to be translated and $\tv$ is the expected type of $\e$.

\paragraph{Pattern constraints}

Thus far, our formal presentation of constraint patterns has remained
abstract, deliberately leaving the syntax and semantics of patterns
unspecified to accommodate a range of language features. We now concretize
this by specifying the patterns used in \OML (in \cref{fig:patterns-oml}),
and introducing the corresponding constraints for the variables they bind.
%
Patterns include:
\begin{enumerate*}

  \item Tuple patterns $\cpatprod \tv j$, matching a tuple type $\Pi\iton
    \tys$ of arity $n \geq j$, and binding the $j$-th component to $\tv$.

  \item Nominal patterns $\cpatrcd \ct$, binding the name of a nominal type
    $\Tapp \tys$ to the nominal variable $\ct$.

  \item Polytype patterns $\cpatpoly \cscm$ matching a polytype $\tpoly \ts$ and
    binding the resulting scheme to the variable $\cscm$.

\end{enumerate*}

Each new constraint has an unsubstituted form ($\cscm \leq \t, \x \leq \cscm$
\etc), whose semantics is defined via substitution into a sugared form ($\ts
\leq \t, \x \leq \ts,$ \etc). Semantic environments $\semenv$ are extended to
interpret nominal variables $\ct$ as names $\T$ and scheme variables $\cscm$ as
ground type schemes $\gscm$, that is type schemes with no unbound variables
(\ie $\tfor {\fvs \t} \t$).

\begin{mathparfig}
  {fig:patterns-oml}
  {Patterns for \OML.}
  \begin{bnfgrammar}
   \entry[Patterns]{\cpat}{
      \cpatprod \tv j
      \and \cpatrcd \ct
      \and \cpatpoly \cscm
    } \\
    \entry[Constraints]{\c}{
      \dots
      \and \labenv(\labfrom \elab \ct) \leq \ta \to \tb
      \and \labenv(\labfrom \elab \T) \leq \ta \to \tb
      \andcr \cscm \leq \t
      \and \ts \leq \t
      \andcr \x \leq \cscm
      \and \x \leq \ts
    }
 \end{bnfgrammar}
  \\
  \def \>{\noalign{\vskip .8ex}}
  \newcommand{\Mrule}[5][]{{#2} \Matches {(#3)} \; #4 &\eqdef& {#5} & #1}
  \begin{tabular}{RCLL}
    \Mrule[\text{if } n \geq j]
      {\cpatprod \tv j}
      {\any \tvcs \Pi\iton \tvcs} \tvbs
      {[\tv \is \tvb_j]}
    \\\>
    \Mrule
      {\cpatrcd \ct}
      {\any \tvcs \Tapp} \tvbs
      {[\ct \is \T]}
    \\\>
    \Mrule
      {\cpatpoly \cscm}
      {\any \tvcs \tpoly \ts} \tvbs
      {[\cscm \is \ts \where{\tvcs \is \tvbs}]}
  \end{tabular}
  \\
  \inferrule[Lab-Inst]
    {\semenv \th \labenv(\labfrom \elab {\semenv(\ct)}) \leq \ta \to \tb}
    {\semenv \th \labenv(\labfrom \elab \ct) \leq \ta \to \tb}

  \inferrule[Lab-Dom]
    {\semenv \th \dom {(\phi(\ct))} = \elabs}
    {\semenv \th \dom \ct = \elabs}

  \inferrule[Scm-Inst]
    {\semenv \th \semenv(\cscm) \leq \t}
    {\semenv \th \cscm \leq \t}

  \inferrule[Abs-Inst]
    {\semenv \th \x \leq \semenv(\cscm)}
    {\semenv \th \x \leq \cscm}
  \\
  \newcommand{\Srule}[3][]{{#2} &\eqdef& {#3} & {#1}}
  \newcommand{\Scases}[3]{%
    \left\{
      \begin{array}{l}
      #1\\%[0.4ex]
      #2
      \end{array}%
    \right.
    &
    \hspace{-1ex}\begin{array}{l}
      \text{if } #3\\%[0.4ex]
      \text{otherwise}
    \end{array}%
  }
  \begin{tabular}{RCLL}
    \Srule[\text{if } \labenv(\labfrom \elab \T) = \tfor \tvs \t \to \Tapp \tvs]
      {\labenv(\labfrom \elab \T) \leq \ta \to \tb}
      {\cexists \tvs \cunif \ta \t \cand \cunif \tb {\Tapp \tvs}}
    \\\>
    \dom{\T} = \elabs &\eqdef&
       \Scases{\ctrue}{\cfalse}{\Dom {\labfrom \labenv \T} = \elabs}
    \\\>
    \Srule
      {(\tfor \tvs \tp) \leq \t}
      {\cexists \tvs \cunif \tp \t}
    \\\>
    \Srule
      {\x \leq (\tfor \tvs \t)}
      {\cfor \tvs \capp \x \t}
  \end{tabular}
\end{mathparfig}


% Explanation of constraint gen cases
% Simple constraint gen

\paragraph{Constraint generation}

\begin{mathparfig}
  [htpb!]
  {fig:constraint-gen}
  {The constraint generation translation for \OML.}
\newcommand {\Crule}[2]{#1 &\eqdef& #2}
\def \arraystretch{1.2}%4
\begin{tabular}{LCL}
\Crule
   {\cinfer x \tv}
   {\cinst x \tv}
\\
\Crule
  {\cinfer {()} \tv}
  {\cunif \tv \tunit}
\\
\Crule
  {\cinfer {\efun \x \e} \tv}
  {\cexists {\tvb, \tvc} \cunif \tv {\tvb \to \tvc}
    \cand \clet \x \tvbp {\cunif \tvbp \tvb} {\cinfer \e \tvc}}
\\
\Crule
  {\cinfer {\eapp \ea \eb} \tv}
  {\cexists {\tvb \tvc} \cunif \tvc {\tvb \to \tv} \cand \cinfer \ea {\tvc} \cand \cinfer \eb \tvb}\
\\
\Crule
  {\cinfer {\elet \x \ea \eb} \tv}
  {\clet \x \tvb {\cinfer \ea \tvb} {\cinfer \eb \tv}}
\\
\Crule
  {\cinfer {\eannot \e \tvs \t} \tv}
  {\cexists \tvs \cunif \tv \t \cand \cinfer \e \tv}
\\
\Crule
  {\cinfer {\etuple {\ea, \ldots, \en}} \tv}
  {\cexists \tvs \cunif \tv {\tProd \tvs}
    \cand \cAnd \iton \cinfer \ei {\tv_i}}
\\
\Crule
  {\cinfer {\exproj \e j n} \tv}
  {\cexists {\tvb, \tvbs}
    \cinfer \e \tvb
    \cand \cunif \tvb {\tProd \tvbs}
    \cand \cunif \tv {\tvb_j}}
\\
\Crule
  {\cinfer {\eproj \e j} \tv}
  {\cexists \tvb \cinfer \e \tvb
    \cand \cmatch \tvb {\cbranch {\cpatprod \tvc j} {\cunif \tv \tvc}}}
\\
\Crule
  {\cinfer {\expoly \e \tvs \ts} \tv}
  {\cexists {\tvs}
    \cinfer \e \ts
    \cand \cunif \tv {\tpoly \ts}}
\\
\Crule
  {\cinfer {\exinst \e \tvs \ts} \tv}
  {\cexists {\tvs, \tvb}
    \cinfer \e \tvb
    \cand \cunif \tvb {\tpoly \ts}
    \cand \ts \leq \tv}
\\
\Crule
  {\cinfer {\einst \e} \tv}
  {\cexists \tvb
    \cinfer \e \tvb
    \cand \cmatch \tvb {\cbranch {\cpatpoly \cscm} \cscm \leq \tv}}
\\
\Crule
  {\cinfer {\epoly \e} \tv}
  {\clet \x \tvb {\cinfer \e \tvb}
    {\cmatch \tv {\cbranch {\cpatpoly \cscm} {\x \leq \cscm}}}}
\\
\Crule
  {\cinfer {\efield \e \elab} \tv}
  {\begin{cases}
    \cexists {\tvb} \cinfer \e \tvb \cand
    \labenv(\labfrom \elab \T) \leq \tvb \to \tva
    & \text{if } \labuni \elab \T
    \\
    \cexists \tvb \cinfer \e \tvb \cand
    \cmatch \tvb
      {\cbranch {\cpatrcd \ct} {\labenv(\labfrom \elab \ct) \leq \tvb \to \tv}}
    & \text{otherwise}
  \end{cases}}
\\
\Crule
  {\cinfer {\exfield \e {\T~} \elab} \tv}
  {\cexists \tvb \cinfer \e \tvb \cand
   \labenv(\labfrom \elab \T) \leq \tvb \to \tva}
\\
\Crule
  {\cinfer {\erecord {\overline{\elab = \e}}} \tv}
  {\begin{cases}
  \cexists \tvbs \cAnd\iton \cinfer \ei \tvbi \cand
   \cAnd\iton \labenv(\labfrom \elabi \T) \leq \tv \to \tvbi
    & \text{if } \labsuni \elabs \T \\
    \cexists \tvbs \cAnd\iton \cinfer \ei \tvbi & \text{otherwise} \\
    \uad\cand \cmatch \tv {\cbranch {\cpatrcd \ct}
      {\dom {\ct} = \elabs \cand \cAnd\iton \labenv(\labfrom \elabi \ct) \leq \tv \to \tvbi}} &
  \end{cases} }
\\
\Crule
  {\cinfer {\exrecord \T {\overline{\elab = \e}}} \tv}
  {\cexists \tvbs \cAnd\iton \cinfer \ei \tvbi \cand \dom {\T} = \elabs \cand \cAnd\iton \labenv(\labfrom \elabi \T) \leq \tv \to \tvbi }
\\
\Crule
  {\cinfer {\emagic \es} \tv}
  {\cexists \tvbs \cAnd\iton \cinfer \ei \tvbi}
\\\\
\Crule
  {\cinfer \e \t}
  {\cexists \tv \cunif \tv \t \cand \cinfer \e \tv}
\\
\Crule
  {\cinfer \e {\tfor \tvs \t}}
  {\cfor \tvs \cinfer \e \t}
\\\\
\Crule
  {\csem {\eset \th \e : \t}}
  {\cinfer \e \t}
\\
\Crule
  {\csem {\x : \ts, \G \th \e : \t}}
  {\clet \x \tv {\ts \le \tv} {\csem {\G \th \e : \t}}}
\end{tabular}

\end{mathparfig}


The function $\cinfer - {\mathop{=}}$ is defined in \cref{fig:constraint-gen}.
All generated type variables are fresh with respect to the expected type $\tv$,
ensuring capture-avoidance.
%
Unsurprisingly, variables generate an instantiation constraint. Unit $\eunit$
requires the type $\tv$ to be $\tunit$. A function generates a constraint that
binds two fresh flexible type variables for the argument and return types.  We
use a $\Let$ constraint to bind the argument in the constraint generated for
the body of the function. The $\Let$ constraint is monomorphic since $\tvbp$ is
fully constrained by type variables defined outside the abstraction's scope
and therefore cannot be generalized. Applications introduce two fresh flexible,
one for the argument type and one for the type of the function, typing each
subterm with these, ensuring $\tv$ is the expected return type.
 Let-bindings generates a polymorphic let constraint; $\cabs \tv
{\cinfer \e \tv}$ is a principal constraint abstraction for $\e$: its intended
interpretation is the set of all types that $\e$ admits.

% New constraint gen cases
% Annotations, tuples
Annotations bind their flexible variables and enforce the equality of
the annotated type $\t$ and the expected type $\tv$. Tuples introduce
fresh variables for each component and unify their product with $\tv$.
Explicit projections ensure $\e$ has a tuple type $\Pi\iton \tvbs$
and extract the $j$-th component $\tvb_j$, unifying it with $\tv$.
Implicit projections defer this via a suspended match constraint, until
the shape of $\e$'s expected type is known to be a tuple, extracting the
$j$-th component with the pattern $\cpatprod \tvb j$,

% Polytypes
For polytypes, boxing asserts that $\e$ has the polymorphic type $\ts$ (using
universal quantification) and that the expected type is the polytype $\tpoly
\ts$. Unboxing suspends until the inferred type of $\e$ is known to be a
polytype, captured by the pattern $\cpatpoly \cscm$, at which point we require
$\tv$ to be an instance of $\cscm$. Explicit unboxing is analogous, but uses an
explicit scheme $\ts$ and therefore does not require a suspended match
constraint. Implicit boxing infers the principal type for $\e$ using a $\Let$
constraint and suspends until the expected type of the entire term is known to
be a polytype, bound to $\cscm$. We then assert that the principal type of $\e$
is at least as general as $\cscm$, via the constraint $\x \leq \cscm$.

% Records
Record projections generate a fresh variable for the nominal record type and
constrain $\e$ to this type, suspending until the type of $\e$ ($\tvb$) is
known to be a nominal record type $\ct$. Once resolved, the type of the
projected label is retrieved from $\labenv$ and instantiated.
%
For record expressions, we generate a fresh variable $\tvbi$ for each field
assignment constraining each assignment $\ei$ to $\tvbi$. The rest of the
constraint is deferred until the context determines the type of the whole
record type to be $\ct$. Once known, the labels are instantiated to match the
assignments $\tv \to \tvbi$, and we addition check that the domain of $\ct$ is
exactly $\elabs$, ensuring that every label is defined.
%
Explicit records and projections, along with closed-world disambiguated terms,
bypass suspension and directly instantiate the appropriate labels.


\section{Unification}
\label{app:unification}

The unification rules are listed in \cref{fig:unification-algorithm}.
Rewriting proceeds under an arbitrary context $\Up$, modulo $\alpha$-equivalence
and associativity/commutativity of conjunctions.

Our algorithm is largely standard~\citep*{Pottier-Remy/emlti} but replaces type
constructors with \emph{canonical principal shapes}, enabling a uniform
treatment of monotypes and polytypes within unification compared to
prior formulations~\citep*{Garrigue-Remy/poly-ml}.

%


\begin{mathparfig}[htpb!]
  {fig:unification-algorithm}
  {Unification algorithm as a series of rewriting rules
   $\upa \unif \upb$. All shapes are principal.}
   \rewrite[U-Exists]
      {(\cexists \alpha \upa) \cand \upb }{ \tv \disjoint \upb}
      {\cexists \tv {\upa \cand \upb}}

    \rewrite[U-Cycle]
      {\up }{ \cyclic \up}
      {\cfalse}

    \rewrite[U-True]
      {\up \cand \ctrue}
      {}
      {\up}

    \rewrite[U-False]
      {\Up\where\cfalse }{ \Up \neq \square}
      {\cfalse}

    \rewrite[U-Merge]
      {\cunif \tv \ueqa \cand \cunif \tv \ueqb}
      {}
      {\cunif \tv {\cunif \ueqa \ueqb}}

    \rewrite[U-Stutter]
      {\cunif \tv {\cunif \tv \ueq}}
      {}
      {\cunif \tv \ueq}

    \rewrite[U-Name]
      {\cunif {\pshapp \parens{\tys, \ti, \typs}} \ueq }
      { \tv \disjoint \tys, \typs, \ueq \\ \ti \notin \TyVars}
      {\cexists \tv {\cunif \tv \ti \cand \cunif {\pshapp \parens{\tys, \tv, \typs}} \ueq}}

    \rewrite[U-Decomp]
      {\cunif {\pshapp \tvs} {\cunif {\pshapp \tvbs} \ueq}}
      {}
      {\cunif {\pshapp \tvs} \ueq \cand \cunif \tvs \tvbs}

    \rewrite[U-Clash]
      {\cunif {\pshapp \tvs} {\cunif {\pshapp[\shp]\tvbs } \ueq }}{
       \sh \neq \shp}
      {\cfalse}

    \rewrite[U-Trivial]
      {\ueq }
      {|\ueq| \leq 1}
      {\ctrue}
\end{mathparfig}


\parcomment{Explanation of the rules}

We briefly summarize the role of each rule. \Rule{U-Exists} lifts existential
quantifiers, enabling applications of \Rule{U-Merge} and \Rule{U-Cycle} since
all multi-equations eventually become part of a single conjunction.
\Rule{U-Merge} combines mutli-equations sharing a common variable and
\Rule{U-Stutter} removes duplicate variables. \Rule{U-Decomp} decomposes equal
types with matching shapes into equalities between their subcomponents, while
\Rule{U-Clash} detects shape mismatches that result in failure. \Rule{U-Name}
introduces fresh variable for subcomponents, ensuring unification operates on
\emph{shallow terms}, making sharing of type variables explicit and avoiding
copying types in rules such as \Rule{U-Decomp}. \Rule{U-True} and
\Rule{U-Trivial} eliminate trivial constraints, and \Rule{U-False} propagates
failure.
%
Finally, \Rule{U-Cycle} implements the \emph{occurs check}, ensuring that a
type variable does not occur in the type it is being unified with. This is a
necessary condition for unification, as it would otherwise lead to infinite
types\footnote{We discuss relaxing this constraint in \cref{sec/rec-types}.}.
This is formalized by the relation $\tv \prec_\up \tvb$ indicating that $\tv$
occurs in a type assigned to $\tvb$ in $\up$. A unification problem is cyclic,
written $\cyclic \up$, if $\tv \prec_\up^* \tv$ for some $\tv$.

\section{Full technical reference}
\label{appendix:figures}
\label{app:full-reference}

This section repeats all the technical definitions mentioned in the paper,
including the cases, rules, and definitions that were omitted from the main
paper to save space. It can serve as a useful cheatsheet to understand a
definition in full, or when studying the meta-theory of the system.

\begin{mathpar}
\begin{bnfgrammar}%
\entryset[Type variables]{\tva, \tvb, \tvc}{\TyVars}{}
\\
%% \entryset[Types]{\t}{\Types}\\
\entry[Types]{\t}{
    \tv \and
    \tunit \and
    \ta \to \tb \and
    \Pi\iton \ti \and
    \T \tys \and
    \tpoly \ts
}\\
\entry[Type schemes]{\ts}{
    \t \and
    \all \tv \ts
}\\[1ex]
\entry[Ground types]{\gt}{}{}\\
\entry[Ground type schemes]{\gscm}{}{}\\
  \entry[Ground region]{\gr}{\greg \tv \semenv}\\
\entry[Sets of ground types]{\gabs \subseteq \Ground}{}{}\\
\entry[Sets of ground regions]{\gabsr \subseteq \GroundRegion}{}\\
\entry[Constraints]{\c}{
        \ctrue
  \and  \cfalse
  \and  \ca \cand \cb
  \and  \cexists \tv \c
  \and 	\cfor \tv \c
  \and  \cunif \ta \tb
  \nextline
  \and  \clet \x \tv \ca \cb
  \and  \capp \x \t
  \nextline
  \and  \cmatch \t \cbrs
  \nextline
  \and \ueq
  \and \cletr \x \tv \tvs \ca \cb
  \and \cexistsi \inst \x \c
  \and \cpinst \inst \tv \t
  \nextline
  \and \labenv(\labfrom \elab \ct) \leq \ta \to \tb
  \and \dom \ct = \elabs
  \and \labenv(\labfrom \elab \T) \leq \ta \to \tb
  \and \dom {\T} = \elabs
  \nextline
  \and \cscm \leq \t \mid \ts \leq \t \mid \x \leq \cscm \mid \x \leq \ts
}\\[1ex]
\entry[Branches]{\cbr}{\cbranch \cpat \c} \\
\entry[Patterns]{\cpat}{
  \cpatwild \and \cpatprod \tv j \and \cpatrcd \ct \and \cpatpoly \cscm
} \\[1ex]
\entry[Semantic environment]{\semenv}{
  \eset \and \semenv\where{\tv := \gt}
  \and \semenv\where{\x := \gabs}
  \and \semenv\where{\x := \gabsr}
  \and \semenv\where{\inst := \semenvp}
  \nextline
  \and \semenv\where{\ct := \T}
  \and \semenv\where{\cscm := \gscm}
}\\
\entry[Unification problems]{\up}{
  \ctrue \and \cfalse \and \upa \cand \upb \and \cexists \tv \up \and \ueq
} \\
\entry[Multi-equations]{\ueq}{
  \eset \mid \cunif \t \ueq
} \\[1ex]
\entry[Constraint contexts]{\C}{
  \square
  \and \C \cand \c
  \and \c \cand \C
  \and \cexists \tv \C
  \and \cfor \tv \C
  \nextline
  \and \clet \x \tv \C \c
  \and \clet \x \tv \c \C
  \nextline
  \and \cletr \x \tv \tvs \C \c
  \and \cletr \x \tv \tvs \c \C
  \and \cexistsi \inst \x \C
} \\
\entry[Shapes] {\Sh} {
  \any \tvcs \t
}
\\
\entry[Canonical principal shapes] {\sh} {} {}\\
\entry[Terms]{\e}{
  x \and
  () \and
  \efun x e \and
  \eapp \ea \eb \and
  \elet x \ea \eb \and
  \eannot \e \tvs \t \andcr
  \erecord {\overline{\elab = \e} } \and
  \efield e \elab \and
  \exrecord \T {\overline{\elab = \e}} \and
  \exfield \e \T \elab
  \andcr
   (\ea, \ldots, \en) \and
   \efield e j \and
   \exfield e n j \andcr
   \epoly e \and
   \expoly e \tvs \ts \and
   \einst e \and
   \exinst e \tvs \ts
   \nextline
   \and \emagic \es
}\\
\entry[Term contexts]{\E}{
  \square
  \and \eapp \E \e
  \and \eapp \e \E
  \and \elet \x \E \e
  \and \elet \x \e \E
  \and \eannot \E \tvs \t
  \andcr \erecord {\elaba = \ea\; \ldots\; \elabi = \E\; \ldots\; \elab_n = \en}
  \and \efield \E \elab
  \andcr \exrecord \T {\elaba = \ea\; \ldots\; \elabi = \E\; \ldots\; \elab_n = \en}
  \and \exfield \E \T \elab
  \andcr (\ea, \ldots, \E, \ldots, \en)
  \and \eproj \E j
  \and \exproj \E j n
  \andcr \epoly \E
  \and \expoly \E \tvs \ts
  \and \einst \E
  \and \exinst \E \tvs \ts
  \andcr
  \emagic {\ea, \ldots, \E, \ldots, \en}
}\\
\entry[Typing contexts]{\G}{
   \eset \and
   \G, x : \ts
}\\
\entry[Label environment]{\labenv}{
  \eset \and \labenv, \elab : \tfor \tvs {\T \tvs \to \t}
}
\end{bnfgrammar}
\end{mathpar}



\begin{judgboxmathpar}
  {\semenv \th \c}
  {Under the environment $\semenv$, the constraint $\c$ is satisfiable.}

  \infer[True]
    { }
    {\semenv \th \ctrue}

  \infer[Conj]
    {\semenv \th \ca \\
     \semenv \th \cb}
    {\semenv \th \ca \cand \cb}

  \infer[Exists]
    {\semenv\where{\tv \is \gt} \th \c}
    {\semenv \th \cexists \tv \c}

  \infer[Forall]
    {\forall \gt, ~ \semenv\where{\tv \is \gt} \th \c}
    {\semenv \th \tfor \tv \c}

  \infer[Unif]
    {\semenv(\ta) = \semenv(\tb)}
    {\semenv \th \cunif \ta \tb}

  \infer[Let]
    {\semenv \th \exists \tv. \ca \\
     \semenv\where{\x \is \semenv(\cabs \tv \ca)} \th \cb}
    {\semenv \th \clet \x \tv \ca \cb}

  \infer[App]
    {\semenv(\t) \in \semenv(\x)}
    {\semenv \th \capp \x \t}

  \infer[Match-Ctx]
    {\Cshape \C \t \sh \\
      \semenv \th \C\where{\cmatched \t \sh \cbrs}
    }
    {\semenv \th \C\where{\cmatch \t \cbrs}}

  \infer[Multi-Unif]
    {\forall \t \in \ueq,~ \semenv(\t) = \gt}
    {\semenv \th \ueq}

  \infer[LetR]
    {\semenv \th \cexists {\tv, \tvs} \ca \\
     \semenv\where{\x \is \semenv(\cabsr \tv \tvs \ca)} \th \cb}
    {\semenv \th \cletr \x \tv \tvs \ca \cb}

  \infer[AppR]
    {\greg \tv \semenvp \in \semenv(\x) \\
     \semenv(\t) = \semenvp(\tv) }
    {\semenv \th \capp \x \t}

  \infer[Exists-Inst]
    {\greg \tv\semenvp \in \semenv(\x) \\
     \semenv\where{\inst \is \semenvp} \th \c}
    {\semenv \th \cexistsi \inst \x \c}

  \infer[Partial-Inst]
    {\semenv(\inst)(\tv) = \semenv(\t) }
    {\semenv \th \cpinst \inst \tv \t}

  \inferrule[Lab-Inst]
    {\semenv \th \labenv(\elab/\semenv(\ct)) \leq \ta \to \tb}
    {\semenv \th \labenv(\labfrom \elab \ct) \leq \ta \to \tb}

  \inferrule[Lab-Dom]
    {\semenv \th \dom {\phi(\ct)} = \elabs}
    {\semenv \th \dom \ct = \elabs}

  \inferrule[Scm-Inst]
    {\semenv \th \semenv(\cscm) \leq \t}
    {\semenv \th \cscm \leq \t}

  \inferrule[Abs-Inst]
    {\semenv \th \x \leq \semenv(\cscm)}
    {\semenv \th \x \leq \cscm}
\\
  \newcommand{\Srule}[3][]{{#2} &\eqdef& {#3} & {#1}}
  \newcommand{\Scases}[3]{%
    \left\{
      \begin{array}{l}
      #1\\[0.4ex]
      #2
      \end{array}%
    \right.
    &
    \hspace{-1ex}\begin{array}{l}
      \text{if } #3\\[0.4ex]
      \text{otherwise}
    \end{array}%
  }
  \begin{tabular}{RCLL}
    \Srule[\text{if } \cmatches \cpati \sh \tvs \theta]{\cmatched \t \sh {\cbranch \cpat \cs}}
      {\cexists \tvs \cunif \t \shapp \tvs \cand \theta(\ci)}
    \\[1ex]
    \Srule[\text{if } \labenv(\labfrom \elab \T) = \tfor \tvs {\Tapp \tvs} \to \t]
      {\labenv(\labfrom \elab \T) \leq \ta \to \tb}
      {\cexists \tvs \cunif \ta {\Tapp \tvs} \cand \cunif \tb \t }
    \\[1ex]
    \dom{\T} = \elabs &\eqdef& \Scases{\ctrue}{\cfalse}{\Dom {\labfrom \labenv \T} = \elabs} \\[1ex]
    \Srule
      {(\tfor \tvs \tp) \leq \t}
      {\cexists \tvs \cunif \tp \t}
    \\[1ex]
    \Srule
      {\x \leq (\tfor \tvs \t)}
      {\cfor \tvs \capp \x \t}
  \end{tabular}
\\
  \semenv(\cabsr \tv \tvs \c) \uad\eqdef\uad \set{\greg \tv {\semenv\where{\tv \is \gt, \tvs \is \gts}} \in \GroundRegion :
    \semenv\where{\tv \is \gt, \tvs \is \gts} \th \c}
\\
\semenv(\cabs \tv \c) \Wide\eqdef \
  \set {\gt \in \Ground : \semenv\where{\tv \is \gt} \th \c}
\\
\Cshape \C \t \sh \Wide\eqdef \
  \forall \semenv, \gt. \uad
      \semenv \th \cerase {\C\where{\cunif \t \gt}} \implies \shape \gt = \sh
\end{judgboxmathpar}
\emph{Note: in most definitions, we ignore the additional  $\OML$ constraints, as they are not particularly interesting.} \\

\begin{judgboxmathpar}
  {\Sh \preceq \Shp}
  {The shape $\Shp$ is an instance of $\Sh$. Alternatively, $\Shp$ is more general than $\Sh$.}
  \infer[Inst-Shape]
    {\tvcs_2 \disjoint \any {\tvcs_1} \t}
    {\any {\tvcs_1} \t \preceq
     \any {\tvcs_2} \t \where {\tvcs_1 \is \tys_1}}
\end{judgboxmathpar}

\begin{definition}
A non-trivial shape $\Sh \in \Shapesz$ is the principal shape of the type
$\t$ iff:
\begin{enumerate}
  \item
    $\exists \typs,\ \t = \shapp[\Sh] \typs$
  \item
    $\forall \Shp \in \Shapesz, \forall \typs,\ \t = \shapp[\Shp] \typs
    \implies \Sh \preceq \Shp$
\end{enumerate}

A principal shape $\any \tvcs \t$ is \emph{canonical} if the sequence of its
free variables $\tvcs$ appear in the order in which the variables occur in
$\t$. $\shape \t$ is the canonical principal shape of $\t$.
\end{definition}

\begin{judgboxmathpar}
  {\cmatches \cpat \sh \tvs \theta}
  {The pattern $\cpat$ matches the shape $\sh$ with components $\tvs$ binding\\pattern variables in $\theta$.}
  \\
  \newcommand{\Mrule}[5][]{{#2} \Matches {(#3)} \; #4 &\eqdef& {#5} & #1}
  \begin{tabular}{RCLL}
    \Mrule[\text{if } n \geq j]
      {\cpatprod \tvb j}
      {\any \tvcs \Pi\iton \tvcs} \tvs
      {[\tvb \is \tvj]}
    \\[1ex]
    \Mrule
      {\cpatrcd \ct}
      {\any \tvcs \Tapp} \tvs
      {[\ct \is \T]}
    \\[1ex]
    \Mrule
      {\cpatpoly \cscm}
      {\any \tvcs \tpoly \ts} \tvs
      {[\cscm \is \ts \where{\tvcs \is \tvs}]}
  \end{tabular}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\c \simple}
  {The constraint $\c$ is simple.}
  \label{fig:simple}
  \inferrule[Simple-True]
    { }
    {\ctrue \simple}

  \inferrule[Simple-False]
    { }
    {\cfalse \simple}

  \inferrule[Simple-Conj]
    {\ca \simple \\ \cb \simple}
    {\ca \cand \cb \simple}

  \inferrule[Simple-Exists]
    {\c \simple}
    {\cexists \tv \c \simple}

  \inferrule[Simple-Forall]
    {\c \simple}
    {\cfor \tv \c \simple}

  \inferrule[Simple-Unif]
    { }
    {\cunif \ta \tb \simple}

  \inferrule[Simple-Let]
    {\ca \simple \\ \cb \simple}
    {\clet \x \tv \ca \cb \simple}

  \inferrule[Simple-App]
    { }
    {\capp \x \t \simple}

  \inferrule[Simple-LetR]
    {\ca \simple \\ \cb \simple}
    {\cletr \x \tv \tvs \ca \cb \simple}

  \inferrule[Simple-Exists-Inst]
    {\c \simple}
    {\cexistsi \inst \x \c \simple}

  \inferrule[Simple-Partial-Inst]
    { }
    {\cpinst \inst \tv \t \simple}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\C \simple}
  {The constraint context $\C$ is simple.}
  \label{fig:simple-context}

  \inferrule[Simple-Ctx-Hole]
    { }
    {\square \simple}

  \inferrule[Simple-Ctx-Conj-Left]
    {\C \simple \\ \c \simple}
    {\C \cand \c \simple}

  \inferrule[Simple-Ctx-Conj-Right]
    {\C \simple \\ \c simple}
    {\c \cand \C \simple}

  \inferrule[Simple-Ctx-Exists]
    {\C \simple}
    {\cexists \tv \C \simple}

  \inferrule[Simple-Ctx-Forall]
    {\C \simple}
    {\cfor \tv \C \simple}

  \inferrule[Simple-Ctx-Let-Abs]
    {\C \simple \\ \c \simple}
    {\clet \x \tv \C \c \simple}

  \inferrule[Simple-Ctx-Let-In]
    {\c \simple \\ \C \simple}
    {\clet \x \tv \c \C \simple}

  \inferrule[Simple-Ctx-Exists-Inst]
    {\C \simple}
    {\cexistsi \inst \x \C \simple}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\cerase \c}
  {The erasure of $\c$.}
  \label{fig:erasure}
\newcommand{\Erule}[2]{\cerase {#1} &\eqdef& {#2}}
\begin{tabular}{RCL}
  \Erule{\ctrue}{\ctrue} \\
  \Erule{\cfalse}{\cfalse} \\
  \Erule{\ca \cand \cb}{\cerase \ca \cand \cerase \cb} \\
  \Erule{\cexists \tv \c}{\cexists \tv \cerase \c} \\
  \Erule{\cfor \tv \c}{\cfor \tv \cerase \c} \\
  \Erule{\cunif \ta \tb}{\cunif \ta \tb} \\
  \Erule{\clet \x \tv \ca \cb}{\clet \x \tv {\cerase \ca} {\cerase \cb}} \\
  \Erule{\capp \x \t}{\capp \x \t} \\
    \Erule{\cmatch \t {\cbranch {\bar \cpat} {\bar \c}}}{\ctrue} \\
  \Erule{\cletr \x \tv \tvs \ca \cb}{\cletr \x \tv \tvs {\cerase \ca} {\cerase \cb}} \\
  \Erule{\cexistsi \inst \x \c}{\cexistsi \inst \x \cerase \c}\\
  \Erule{\cpinst \inst \tv \t}{\cpinst \inst \tv \t}
\end{tabular}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\semenv \Th \c}
  {Under the semantic environment $\semenv$,
   the constraint $\c$ is canonically satisfiable.}
  \label{fig:canonical-sem}
  \inferrule[Can-Simple]
    {\semenv \thsimple \c}
    {\semenv \Th \c}

  \inferrule[Can-Match-Ctx]
    {\Cshape \C \t \sh \\ \semenv \Th \C\where{\cmatched \t \sh \cbrs}}
    {\semenv \Th \C\where{\cmatch \t \cbrs}}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {{\labfrom \elab \T} \leq \tya \to \tyb}
  {The label $\elab$ in the nominal record type $\T$ has the field type $\tyb$ and record type $\tya$.}
  \inferrule[Lab-Inst]
    {\labenv(\labfrom \elab \T) = \tfor \tvs {\T \tvs} \to \t }
    {{\labfrom \elab \T} \leq \Tapp \tys \to \t\where{\tvs \is \tys} }
\end{judgboxmathpar}

\judgbox
  {\labuni \elab \T}
  {The label $\elab$ infers the unique nominal record type $\T$.}

\begin{judgboxmathpar}
  {\labsuni \elabs \T}
  {The \emph{closed} set of labels $\elabs$ infer the unique nominal record type $\T$.}
  \infer[Lab-Uni]
    {\elab \in \Dom {\labfrom \labenv \T} \\
     \forall \Tp, \uad \elab \in \Dom {\labfrom \labenv \Tp} \implies {\T} = \Tp}
    {\labuni \elab \T}

  \infer[Labs-Uni]
    {\Dom {\labfrom \labenv \T} = \elabs \\
     \forall \Tp, \uad \Dom{\labfrom \labenv \Tp} = \elabs \implies {\T} = \Tp}
    {\labsuni \elabs \T}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\G \th \e : \ts}
  {Under the typing context $\G$, the term $\e$ is assigned the type $\ts $}
  \inferrule[Var]
    {x : \sigma \in \G}
    {\G \th x : \sigma}

  \inferrule[Fun]
    {\G, x : \ta \th e : \tb }
    {\G \th \efun x e : \ta \to \tb}

  \inferrule[App]
    {\G \th \ea : \ta \to \tb \\
     \G \th \eb : \ta}
    {\G \th \eapp \ea \eb : \tb}

  \inferrule[Unit]
    { }
    {\G \th () : 1}

  \inferrule[Annot]
    {\G \th e : \t\where {\tvs \is \tys}}
    {\G \th (e : \exi \tvs \t) : \t\where {\tvs \is \tys}}

  \inferrule[Gen]
    {\G \th e : \sigma \\ \tv \disjoint \G}
    {\G \th e : \tfor \tv \sigma}

  \inferrule[Inst]
    {\G \th e : \tfor \tv \ts}
    {\G \th e : \ts \where{\tv \is \t}}

  \inferrule[Let]
    {\G \th \ea : \sigma \\
     \G, x : \sigma \th \eb : \t}
    {\G \th \elet x \ea \eb : \t}
%% \color{gray}{
%%   \inferrule[Magic]
%%     {\G \th \e : \t}
%%     {\G \th \emagic \e : \tp}
%% }

%% \Subparabox[fig/ref/typing/core]{Typing rules --- Structural tuples}{}
  \inferrule[Tuple]
    {\parens{\G \th \ei : \ti}\iton}
    {\G \th (\ea, \ldots, \en) : \Pi\iton \ti}

  \inferrule[Proj-X]
    {\G \th \e : \Pi\iton \ti \\
     1 \leq j \leq n}
    {\G \th \exproj \e j n : \tj}

  \inferrule[Proj-I]
    {\eshape \E \e {\any \tvcs \Pi\iton \tvcs} \\
     \G \th \E\where{\exproj \e j n} : \t}
    {\G \th \E\where{\eproj \e j} : \t}

  \inferrule [Poly-X]
    {\G \th \e : \ts\where {\tvs \is \tys}}
    {\G \th \epoly[\exi \tvs \ts] \e : \tpoly {\ts \where {\tvs \is \tys}}}

  \inferrule [Poly-I]
    {\Eshape \E \e {{\any \tvcs \tpoly \ts}} \\
     \G \th \E \where{\epoly[\exi \tvcs \ts] \e} : \t}
    {\G \th \E \where{\epoly \e} : \t}

  \inferrule [Use-X]
    {\G \th \e : \tpoly \ts \where {\tvs \is \tys}}
    {\G \th \exinst e \tvs \ts : \ts \where {\tvs \is \tys}}

  \inferrule [Use-I]
    {\eshape \E  \e {\any \tvcs \tpoly \ts} \\
     \G \th \E\where{\exinst \e \tvcs \ts} : \t}
    {\G \th \E\where{\einst \e} : \t}

  \inferrule[Rcd-X]
    {\parens{\G \th \ei : \tyi}\iton \\ \parens{{\labfrom \elabi \T} \leq \t \to \tyi}\iton \\ \Dom {\labfrom \labenv \T} = \elabs }
    {\G \th \exrecord \T {\elaba = \ea; \ldots; \elab_n = \en} : \t }

  \inferrule[Rcd-Closed]
    {\G \th \exrecord \T {\overline{\elab = \e}} : \t \\ \labsuni \elabs \T}
    {\G \th \erecord {\overline{\elab = \e}} : \t}

  \inferrule[Rcd-I]
    {\Eshape \E \es {\any \tvcs \Tapp \tvcs} \\ \G \th \E\where{\exrecord \T {\overline{\elab = \e}}} : \t }
    {\G \th \E\where{\erecord {\overline{\elab = \e}}} : \t}

  \inferrule[Rcd-Proj-X]
    {\G \th \e : \tya \\
     {\labfrom \elab \T} \leq \tya \to \tyb}
    {\G \th \exfield \e \T \elab : \tyb}

  \inferrule[Rcd-Proj-Closed]
    {\G \th \exfield \e \T \elab : \t \\
     \labuni \elab \T}
    {\G \th \efield \e \elab : \t}

  \inferrule[Rcd-Proj-I]
    {\eshape \E \e {\any \tvcs \Tapp \tvcs} \\
     \G \th \E\where{\exfield \e \T \elab} : \t}
    {\G \th \E\where{\efield \e \elab} : \t}

  \inferrule[Magic]
    {\parens{\G \th \ei : \ti}\iton}
    {\G \th \emagic {\bar \e} : \tp}

\def \Eqdef {&\eqdef&}
{\begin{tabular}{RCL}
\eshape \E \e \sh \Eqdef
  \forall \G, \t, \gt, \uad
  \G \th \eerase {\E \where {\emagic {\eannot \e {} \gt }}} : \t
      \wide\implies \shape \gt = \sh
\\[1ex]
\Eshape \E {\bar\e} \sh \Eqdef
  \forall \G, \t, \gt, \uad
      \G \th \eerase {\E\where{\eannot {\emagic {\bar \e}} {} \gt}} : \t
      \wide\implies \shape \gt = \sh
\\[1ex]
\end{tabular}}
\end{judgboxmathpar}


\judgbox
  {\cinfer {\G \th \e} \t}
  {$\cinfer {\G \th \e} \t$ is satisfiable iff $\e$ has the expected \emph{known} type $\t$ under \emph{known} context $\G$.}

\judgbox
  {\cinfer \e \ts}
  {$\cinfer \e \ts$ is satisfiable iff $\e$ has the expected \emph{known} type scheme $\ts$.}

\begin{judgboxmathpar}
  {\cinfer \e \tv}
  {$\cinfer \e \tv$ is satisfiable iff $\e$ has the expected type $\tv$.}

\newcommand {\Crule}[2]{#1 &\eqdef& #2}
\def \arraystretch{1.2}%4
\begin{tabular}{LCL}
\Crule
   {\cinfer x \tv}
   {\cinst x \tv}
\\
\Crule
  {\cinfer {()} \tv}
  {\cunif \tv \tunit}
\\
\Crule
  {\cinfer {\efun \x \e} \tv}
  {\cexists {\tvb, \tvc} \cunif \tv {\tvb \to \tvc}
    \cand \clet \x \tvbp {\cunif \tvbp \tvb} {\cinfer \e \tvc}}
\\
\Crule
  {\cinfer {\eapp \ea \eb} \tv}
  {\cexists {\tvb \tvc} \cunif \tvc {\tvb \to \tv} \cand \cinfer \ea {\tvc} \cand \cinfer \eb \tvb}\
\\
\Crule
  {\cinfer {\elet \x \ea \eb} \tv}
  {\clet \x \tvb {\cinfer \ea \tvb} {\cinfer \eb \tv}}
\\
\Crule
  {\cinfer {\eannot \e \tvs \t} \tv}
  {\cexists \tvs \cunif \tv \t \cand \cinfer \e \tv}
\\
\Crule
  {\cinfer {\etuple {\ea, \ldots, \en}} \tv}
  {\cexists \tvs \cunif \tv {\tProd \tvs}
    \cand \cAnd \iton \cinfer \ei {\tv_i}}
\\
\Crule
  {\cinfer {\exproj \e j n} \tv}
  {\cexists {\tvb, \tvbs}
    \cinfer \e \tvb
    \cand \cunif \tvb {\tProd \tvbs}
    \cand \cunif \tv {\tvb_j}}
\\
\Crule
  {\cinfer {\eproj \e j} \tv}
  {\cexists \tvb \cinfer \e \tvb
    \cand \cmatch \tvb {\cbranch {\cpatprod \tvc j} {\cunif \tv \tvc}}}
\\
\Crule
  {\cinfer {\expoly \e \tvs \ts} \tv}
  {\cexists {\tvs}
    \cinfer \e \ts
    \cand \cunif \tv {\tpoly \ts}}
\\
\Crule
  {\cinfer {\exinst \e \tvs \ts} \tv}
  {\cexists {\tvs, \tvb}
    \cinfer \e \tvb
    \cand \cunif \tvb {\tpoly \ts}
    \cand \ts \leq \tv}
\\
\Crule
  {\cinfer {\einst \e} \tv}
  {\cexists \tvb
    \cinfer \e \tvb
    \cand \cmatch \tvb {\cbranch {\cpatpoly \cscm} \cscm \leq \tv}}
\\
\Crule
  {\cinfer {\epoly \e} \tv}
  {\clet \x \tvb {\cinfer \e \tvb}
    {\cmatch \tv {\cbranch {\cpatpoly \cscm} {\x \leq \cscm}}}}
\\
\Crule
  {\cinfer {\efield \e \elab} \tv}
  {\begin{cases}
    \cexists {\tvb} \cinfer \e \tvb \cand \labenv(\labfrom \elab \T) \leq \tvb \to \tva & \text{if } \labuni \elab \T \\
    \cexists \tvb \cinfer \e \tvb \cand \cmatch \tvb {\cbranch {\cpatrcd \ct} {\labenv(\labfrom \elab \ct) \leq \tvb \to \tv}} & \text{otherwise}
  \end{cases}}
\\
\Crule
  {\cinfer {\exfield \e \T \elab} \tv}
  {\cexists \tvb \cinfer \e \tvb \cand \labenv(\labfrom \elab \T) \leq \tvb \to \tva}
\\
\Crule
  {\cinfer {\erecord {\overline{\elab = \e}}} \tv}
  {\begin{cases}
  \cexists \tvbs \cAnd\iton \cinfer \ei \tvbi \cand \cAnd\iton \labenv(\labfrom \elabi \T) \leq \tv \to \tvbi
    & \text{if } \labsuni \elabs \T \\
    \cexists \tvbs \cAnd\iton \cinfer \ei \tvbi & \text{otherwise} \\
    \uad\cand \cmatch \tv {\cbranch {\cpatrcd \ct}
      {\dom {\ct} = \elabs \cand \cAnd\iton \labenv(\labfrom \elabi \ct) \leq \tv \to \tvbi}}
  \end{cases} }
\\
\Crule
  {\cinfer {\exrecord \T {\overline{\elab = \e}}} \tv}
  {\cexists \tvbs \cAnd\iton \cinfer \ei \tvbi \cand \dom {\T} = \elabs \cand \cAnd\iton \labenv(\labfrom \elabi \T) \leq \tv \to \tvbi }
\\
\Crule
  {\cinfer {\emagic \es} \tv}
  {\cexists \tvbs \cAnd\iton \cinfer \ei \tvbi}
\\\\
\Crule
  {\cinfer \e \t}
  {\cexists \tv \cunif \tv \t \cand \cinfer \e \tv}
\\
\Crule
  {\cinfer \e {\tfor \tvs \t}}
  {\cfor \tvs \cinfer \e \t}
\\\\
\Crule
  {\csem {\eset \th \e : \t}}
  {\cinfer \e \t}
\\
\Crule
  {\csem {\x : \ts, \G \th \e : \t}}
  {\clet \x \tv {\ts \le \tv} {\csem {\G \th \e : \t}}}
\end{tabular}
\end{judgboxmathpar}


\begin{judgboxmathpar}
  {\e \simple}
  {The term $\e$ is simple.}
  \inferrule[Simple-Var]
    { }
    {\x \simple}

  \inferrule[Simple-Fun]
    {\e \simple}
    {\efun \x \e \simple}

  \inferrule[Simple-App]
    {\ea \simple \\ \eb \simple}
    {\eapp \ea \eb \simple}

  \inferrule[Simple-Unit]
    { }
    {\eunit \simple}

  \inferrule[Simple-Let]
    {\ea \simple \\ \eb \simple}
    {\elet \x \ea \eb \simple}

  \inferrule[Simple-Annot]
    {\e \simple}
    {\eannot \e \tvs \t \simple}

  \inferrule[Simple-Tuple]
    {\parens {\ei \simple}\iton}
    {\etuple {\ea, \ldots, \en} \simple}

  \inferrule[Simple-Proj-X]
    {\e \simple}
    {\exproj \e j n \simple}

  \inferrule[Simple-Poly-X]
    {\e \simple}
    {\expoly \e \tvs \ts \simple}

  \inferrule[Simple-Use-X]
    {\e \simple}
    {\exinst \e \tvs \ts \simple}

  \inferrule[Simple-Rcd-X]
    {\parens {\ei \simple} \iton}
    {\exrecord \T {\elaba = \ea\; \ldots\; \elab_n = \en}}

  \inferrule[Simple-Rcd-Closed]
    {\parens {\ei \simple} \iton \\ \labsuni \elabs \T}
    {\erecord {\elaba = \ea\; \ldots\; \elab_n = \en}}

  \inferrule[Simple-Rcd-Proj-X]
    {\e \simple}
    {{\exfield \e \T \elab} \simple}

  \inferrule[Simple-Rcd-Proj-Closed]
    {\e \simple \\ \labuni \elab \T}
    {\efield \e \elab \simple}

  \inferrule[Simple-Magic]
    {\parens{\ei \simple}\iton}
    {\emagic \es \simple}
\end{judgboxmathpar}

\label {app/ref/eerase}
\begin{judgboxmathpar}
  {\eerase \e}
  {The erasure of $\e$.}
\newcommand{\Erule}[2]{\eerase {#1} &\eqdef& {#2}}
  \begin{tabular}{RCL}
  \Erule{\x}{\x} \\
  \Erule{\efun \x \e}{\efun \x \eerase \e} \\
  \Erule{\eapp \ea \eb}{\eapp {\eerase \ea} {\eerase \eb}} \\
  \Erule{\eunit}{\eunit} \\
  \Erule{\elet \x \ea \eb}{\elet \x {\eerase \ea} {\eerase \eb}} \\
  \Erule{\eannot \e \tvs \t}{\eannot {\eerase \e} \tvs \t} \\
  \Erule{\etuple {\ea, \ldots, \en}}{\etuple {\eerase \ea, \ldots, \eerase \en}} \\
  \Erule{\eproj \e j}{\emagic {\eerase \e}} \\
  \Erule{\exproj \e j n}{\exproj {\eerase \e} j n} \\
  \Erule{\expoly \e \tvs \ts}{\expoly {\eerase \e} \tvs \ts} \\
  \Erule{\epoly \e}{\emagic {\eerase \e}}\\
  \Erule{\einst \e}{\emagic {\eerase \e}}\\
  \Erule{\exinst \e \tvs \ts}{\exinst {\eerase \e} \tvs \ts}\\
    \Erule{\erecord {\elaba = \ea; \ldots; \elab_n = \en}}{\begin{cases}
      \erecord {\elaba = \eerase \ea; \ldots; \elab_n = \eerase \en} &\text{if } \labsuni \elabs \T \\
      \emagic {\eerase \ea, \ldots, \eerase \en} & \text{otherwise}
    \end{cases}}\\
  \Erule{\exrecord \T {\elaba = \ea; \ldots; \elab_n = \en}}{\exrecord \T {\elaba = \eerase \ea; \ldots; \elab_n = \eerase \en}}\\
    \Erule{\efield \e \elab}{\begin{cases}
      \efield \e \elab & \text{if } \labuni \elab \T \\
      \emagic {\eerase \e} & \text{otherwise}
    \end{cases}}\\
  \Erule{\exfield \e \T \elab}{\exfield {\eerase \e} \T \elab}\\
  \Erule{\emagic \es}{\emagic {\parens {\eerase \ei} \iton}}\\
\end{tabular}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\G \thsimplesd \e : \t}
  {Under the typing context $\G$, the simple term $\e$ has the type $\t$.}
\\
  \inferrule[Var-SD]
    {x : \tfor \tvs \t \in \G}
    {\G \thsimplesd x : \t\where{\tvs \is \tys}}

  \inferrule[Let-SD]
    {\G \thsimplesd \ea : \ta\\
     \tvs \disjoint \G \\
     \G, x : \tfor \tvs \ta \thsimplesd \eb : \tb}
    {\G \thsimplesd \elet x \ea \eb : \tb}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\Th \e : \t}
  {The term $\e$ canonically has the type $\t$.}
  \inferrule[Can-Base]
    {\eset \thsimplesd \e : \t}
    {\Th \e : \t}

  \inferrule[Can-Proj-I]
    {\eshape \E \e {\any \tvcs \Pi\iton \tvcs} \\
     \Th \E\where{\exproj \e j n} : \t}
    {\Th \E\where{\eproj \e j} : \t}

  \inferrule [Can-Poly-I]
    {\Eshape \E \e {{\any \tvcs \tpoly \ts}} \\
     \Th \E \where{\epoly[\exi \tvcs \ts] \e} : \t}
    {\Th \E \where{\epoly \e} : \t}

  \inferrule [Can-Use-I]
    {\eshape \E  \e {\any \tvcs \tpoly \ts} \\
     \Th \E\where{\exinst \e \tvcs \ts} : \t}
    {\Th \E\where{\einst \e} : \t}

  \inferrule[Can-Lab-I]
    {\Lshape \Lab \elab \T \\
      \Th \Lab[\labfrom \elab \T] : \t}
    {\Th \Lab[\elab] : \t}

  \inferrule[Can-Rcd-I]
    {\Eshape \E \es {\any \tvcs \Tapp \tvcs} \\
     \Th \E\where{\exrecord \T {\elaba = \ea; \ldots; \elab_n = \en}} : \t}
    {\Th \E\where{\erecord {\elaba = \ea; \ldots; \elab_n = \en}} : \t}

  \inferrule[Can-Rcd-Proj-I]
    {\Eshape \E \e {\any \tvcs \Tapp \tvcs} \\
     \Th \E\where{\exfield \e \T \elab} : \t}
    {\Th \E\where{\efield \e \elab} : \t}
\end{judgboxmathpar}


\label {app/rules/unif}
\begin{judgboxmathpar}
  {\up \unif \upp}
  {The unifier rewrites $\up$ to $\upp$.}
   \rewrite[U-Exists]
      {(\cexists \alpha \upa) \cand \upb }{ \tv \disjoint \upb}
      {\cexists \tv {\upa \cand \upb}}

    \rewrite[U-Cycle]
      {\up }{ \cyclic \up}
      {\cfalse}

    \rewrite[U-True]
      {\up \cand \ctrue}
      {}
      {\up}

    \rewrite[U-False]
      {\Up\where{\cfalse}}
      { \Up \neq \square}
      {\cfalse}

    \rewrite[U-Merge]
      {\cunif \tv \ueqa \cand \cunif \tv \ueqb}
      {}
      {\cunif \tv {\cunif \ueqa \ueqb}}

    \rewrite[U-Stutter]
      {\cunif \tv {\cunif \tv \ueq}}
      {}
      {\cunif \tv \ueq}

    \rewrite[U-Name]
      {\cunif {\pshapp \parens{\tys, \ti, \typs}} \ueq }
      {\tv \disjoint \tys, \typs, \ueq \\ \ti \notin \TyVars}
      {\cexists \tv
        {\cunif \tv \ti \cand
         \cunif {\pshapp \parens{\tys, \tv, \typs}} \ueq}}

    \rewrite[U-Decomp]
      {\cunif {\pshapp \tvs} {\cunif {\pshapp \tvbs} \ueq}}
      {}
      {\cunif {\pshapp \tvs} \ueq \cand \cunif \tvs \tvbs}

    \rewrite[U-Clash]
      {\cunif {\pshapp \tvs} {\cunif {\pshapp[\shp]\tvbs } \ueq }}{
       \sh \neq \shp}
      {\cfalse}

    \rewrite[U-Trivial]
      {\ueq}
      {|\ueq| \leq 1}
      {\ctrue}
\end{judgboxmathpar}


\begin{judgboxmathpar}
  {\c \csolve \cp}
  {The constraint solver rewrites $\c$ to $\cp$.}

  \rewrite[S-Unif]
    {\upa}
    {\upa \unif \upb}
    {\upb}

  \rewrite[S-True]
    {C \cand \ctrue}
    {}
    {C}

  \rewrite[S-False]
    {\C\where\cfalse}
    {\C \neq \square}
    {\cfalse}

  \rewrite[S-Let]
    {\clet \x \tv \ca \cb}
    {}
    {\cletr \x \tv \eset \ca \cb}

  \rewrite[S-Exists-Conj]
    {(\cexists \alpha \ca) \cand \cb }{
     \tv \disjoint \cb}
    {\cexists \tv {\ca \cand \cb}}

  \rewrite[S-Let-ExistsLeft]
    {\cletr \x \tv \tvs {\cexists \tvb \ca} \cb }{
     \tvb \disjoint \tv, \tvs, \cb}
    {\cletr \x \tv {\tvs, \tvb} \ca \cb}

  \rewrite[S-Let-ExistsRight]
    {\cletr \x \tv \tvs \ca {\cexists \tvb \cb} }{
     \tvb \disjoint \tv, \tvs, \ca}
    {\cexists \tvb {\clet \x \tvs \ca \cb}}

  \rewrite[S-Let-ConjLeft]
    {\cletr \x \tv \tvs {\ca \cand \cb} \cc }{
     \ca \disjoint \tv, \tvs}
    {\ca \cand \cletr \x \tv \tvs \cb \cc}

  \rewrite[S-Let-ConjRight]
    {\cletr \x \tv \tvs \ca (\cb \cand \cc) }{
     \x \disjoint \cc}
    {\cc \cand \Clet \x \tv \ca \cb}

  \rewrite[S-Match-Ctx]
    {\C\where{\cmatch \t \cbrs}}
    {\th \Cshape \C \t \sh}
    {\C\where{\cmatched \t {\sh} \cbrs}}

   \rewrite[S-Inst-Name]
    {\cpinst \inst \tv \t}
    {\t \notin \TyVars}
    {\cexists \tvc \cunif \tvc \t \cand \cpinst \inst \tv \tvc}

  \rewrite[S-Let-AppR]
    {\cletr \x \tv \tvs \c {\C\where{\capp \x \t}}}
    {\tvc \disjoint \t \\ \x \disjoint \bvs \C}
    {\cletr \x \tv \tvs \c {\C\where{\cexistsi
      {\tvc, \inst} \x {\cunif \tvc \t \cand \cpinst \inst \tv \tvc}}}}

  \rewrite[S-Inst-Copy]
    {\cletr \x \tv \tvs {\c} \C\where{\cpapp \x \tvp \tvc \inst}}
    {\c = \cp \cand \cunif \tvp {\cunif {\shapp \tvbs} \ueq}\\
     \tvp \in \reg \tv \tvs \\\\
     \neg \cyclic {\c} \\
     \tvbs' \disjoint \tvp, \tvc, \tvbs \\
     \x \disjoint \bvs \C}
    {\cletr \x \tv \tvs {\c}
      \C\where{\cexists {\tvbs'}
         {\cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}}}

  \rewrite[S-Inst-Unify]
    {\cpinst \inst \tv \tvca \cand \cpinst \inst \tv \tvcb}
    {}
    {\cpinst \inst \tv \tvca \cand \cunif \tvca \tvcb}

  \rewrite[S-Inst-Poly]
    {\cletr \x \tv {\tvs} {\ueqs \cand \c}
        {\C\where{\cpapp \x \tvp \tvc \inst}}}
    {\cfor \tvp \cexists {\tv} {\ueqs} \cequiv \ctrue \\\\
     \tvp \in \reg \tv \tvs \\
     \tvp \disjoint \c \\
     \inst.\tvp \disjoint \insts \C \\
     \x \disjoint \bvs \C}
    {\cletr \x \tv {\tvs} {\ueqs \cand \c} {\C\where\ctrue}}

  \rewrite[S-Inst-Mono]
    {\cletr \x \tv \tvs \c {\C\where{\cpapp \x \tvb \tvc \inst}}}
    {\tvb \notin \reg \tv \tvs \\ \x, \tvb \disjoint \bvs \C}
    {\cletr \x \tv \tvs \c {\C\where{\cunif \tvb \tvc}}}

  \rewrite[S-Let-Solve]
    {\cletr \x \tv \tvs \ueqs \c}
    {\cexists {\tv, \tvs} \ueqs \cequiv \ctrue \\ \x \disjoint \c}
    {\c}

  \rewrite[S-Compress]
    {\cletr \x \tv {\tvs, \tvb}
       {\ca \cand \cunif \tvb {\cunif \tvc \ueq}} {\cb}}
    {\tvb \neq \tvc}
    {\cletr \x \tv {\tvs}
       {\ca\where{\tvb \is \tvc} \cand \cunif \tvc {\ueq\where{\tvb \is \tvc}}}
       {\cb\where{\x.\tvb \is \tvc}}}

  \rewrite[S-Gc]
    {\cletr \x \tv {\tvs, \tvb} {\ca \cand \cunif \tvb \ueq} \cb}
    {\tvb \disjoint \ca, \ueq, \cb}
    {\cletr \x \tv {\tvs} {\ca \cand \ueq} \cb}

  \rewrite[S-Exists-Lower]
    {\cletr \x \tv {\tvas, \tvbs} \ca \cb}
    {\th \cdetermines {\cexists {\tv, \tvas} \ca} \tvbs}
    {\cexists \tvbs \cletr \x \tv \tvas \ca \cb}

  \rewrite[S-Exists-Exists-Inst]
    {\cexistsi \inst \x \cexists \tv \c}
    {}
    {\cexists \tv \cexistsi \inst \x \c}

  \rewrite[S-Exists-Inst-Conj]
    {\cexistsi \inst \x \ca \cand \cb}
    {\inst \disjoint \ca}
    {\ca \cand \cexistsi \inst \x \cb}

  \rewrite[S-Exists-Inst-Let]
    {\cletr \x \tv \tvs \ca {\cexistsi \inst \xp \cb}}
    {\x \neq \xp}
    {\cexistsi \inst \xp \cletr \x \tv \tvs \ca \cb}

  \rewrite[S-Exists-Inst-Solve]
    {\cexistsi \inst \x \c}
    {\inst \disjoint \c}
    {\c}

  \rewrite[S-All-Conj]
    {\cfor \tvs {\cexists \tvbs {\ca \cand \cb}}}
    {\tvs, \tvbs \disjoint \ca}
    {\ca \cand \cfor \tvs {\cexists \tvbs \cb}}

  \rewrite[S-Exists-All]
    {\cfor \tvs {\cexists {\tvbs, \tvcs} \c}}
    {\th \cdetermines {\cexists {\tvs, \tvbs} \c} \tvcs}
    {\cexists \tvcs \cfor \tvs {\cexists \tvbs \c}}

  \rewrite[S-All-Escape]
    {\cfor {\tvs, \tv} {\cexists \tvbs {\c \cand \ueqs}}}
    {\tv \prec_{\ueqs}^* \tvc \\
     \tvc \disjoint \tv, \tvbs \\
     \tv \disjoint \tvbs}
    {\cfalse}

  \rewrite[S-All-Rigid]
    {\cfor {\tvs, \tv}
      {\cexists \tvbs \c \cand \cunif \tv {\cunif \t \ueq}}}
    {\t \notin \TyVars \\ \tv \disjoint \tvbs}
    {\cfalse}

  \rewrite[S-All-Solve]
    {\cfor \tvs \cexists \tvbs \ueqs}
    {\cexists \tvbs \ueqs \cequiv \ctrue}
    {\ctrue}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\th \Cshape \C \t \sh}
  {Under $\C$, the type $\t$ has the provably unique canonical shape $\sh$.}
  \infer[S-Uni-Var]
    {\color{gray}\tv \disjoint \bvs \Cb}
    {\th \Cshape {\Ca\where{\cunif \tv {\cunif \t \ueq} \cand \Cb\where{-}}} \tv {~\shape \t}}

  \infer[S-Uni-Type]
    {{\color{gray}\t \notin \TyVars}}
    {\th \Cshape \C \t {~\shape \t}}

  \infer[S-Uni-BackProp]
    {\th \Cshape{\cletr \x \tv \tvs {\Ca\where{\ctrue}} {\Cb\where{\cpapp \x \tvp \tvc \inst \cand -}}} \tvc \sh \\
     \color{gray}\tvp \in \tv, \tvs \\
     \color{gray}\x \disjoint \bvs \Cb \\
     \color{gray}\tvp \disjoint \bvs \Ca}
    {\th \Cshape{\cletr \x \tv \tvs {\Ca\where{-}} {\Cb\where{\cpapp \x \tvp \tvc \inst}}} \tv \sh}

\end{judgboxmathpar}

\begin{definition}
  $\cdetermines \c \tvbs$ if and only if every ground assignments
  $\semenv$ and $\semenvp$ that satisfy (the erasure of) $\c$ and coincide outside of $\tvb$
  coincide on $\tvbs$ as well.
  \begin{mathpar}
    \cdetermines \c \tvb \uad\eqdef\uad \all {\semenv, \semenvp} \uad
      \semenv \th \cerase \c
      \wedge \semenvp \th \cerase \c
      \wedge \semenv =_{\setminus \tvbs} \semenvp
      \implies
      \semenv = \semenvp
  \end{mathpar}
\end{definition}

\begin{judgboxmathpar}
  {\th \cdetermines \c \tvs}
  {$\c$ provably determines $\tvs$.}

  \inferrule
    [S-Det-Dom]
    {\tvc \disjoint \tvbs, \tvas \\ \tvs \subseteq \fvs \ueq}
    {\th \cdetermines {\cexists \tvbs \c \cand \cunif \tvc \ueq} \tvs}

  \inferrule
    [S-Det-Esc]
    {\fvs \t \disjoint \tvs, \tvbs}
    {\th \cdetermines {\cexists \tvbs \c \cand \cunif \tvs {\cunif \t \ueq}} \tvs}
\end{judgboxmathpar}

\begin{judgboxmathpar}
  {\insts \c}
  {The set of instantiations in $\c$.}
  \newcommand{\Srule}[2]{#1 &\eqdef& #2}
  \begin{tabular}{RCL}
    \Srule{\insts \ctrue}{\eset}\\
    \Srule{\insts \cfalse}{\eset}\\
    \Srule{\insts {\ca \cand \cb}}{\insts \ca \cup \insts \cb}\\
    \Srule{\insts {\cexists \tv \c}}{\insts \c}\\
    \Srule{\insts {\cfor \tv \c}}{\insts \c}\\
    \Srule{\insts {\cunif \t \tp}}{\eset}\\
    \Srule{\insts {\clet \x \tv \ca \cb}}{\insts \ca \cup \insts \cb}\\
    \Srule{\insts {\capp \x \t}}{\eset}\\
    \Srule{\insts {\ueq}}{\eset}\\
    \Srule{\insts {\cletr \x \tv \tvs \ca \cb}}{\insts \ca \cup \insts \cb}\\
    \Srule{\insts {\cexistsi \inst \x \c}}{\insts \c}\\
    \Srule{\insts {\cpapp \x \tv \tvc \inst}}{\set {\inst.\tv}}
  \end{tabular}
\end{judgboxmathpar}


\begin{definition}[Measure]
  For the relation $\semenv \th \c$, the following measure enables a useful
  induction principle:
    \begin{mathpar}
    \cmeasure \c \uad\eqdef\uad \angles{\cnmatches \c, \csize \c}
  \end{mathpar}
  where $\angles \ldots$ denotes a pair with lexicographic ordering, and:
  \begin{enumerate}

    \item $\cnmatches \c$ is the number of $\cmatch \t \cbrs$ constraints in
      $\c$.

    \item the last component $\csize \c$ is a structural measure of constraints \ie a
      conjunction $\ca \cand \cb$ is larger than the two conjuncts $\ca,
      \cb$.

  \end{enumerate}
\end{definition}


\section{Properties of the constraint language}
\label{app:proofs-constraints}

This appendix establishes key properties of the constraint language. The first
is the principality of shapes \cref{thm:principal-shapes}: any non-variable type
$\t$ admits a non-trivial principal shape $\sh$.

The second is the canonicalization of satisfiability derivations $\semenv \th
\c$, which enables a simple induction principal for reasoning about unicity.
This canonical form for derivations is a crucial tool in our proof of
soundness and completeness in \cref{app/oml/proofs}.

\subsection{Principality of shapes}

\principalShapes
\begin{proof}
  Let us assume $\t$ is a non-variable type.

  \begin{proofcases}
    \proofcase{$\t$ is a type constructor $\tconstr \tys$}

    $\tconstr$ is a top-level type constructor of arity $n$, which in our
    setting may be the nullary $\tunit$, the binary arrow, the $n$-ary product,
    or a $n$-ary nominal type. In all these cases, the shape of $\t$ is $\any
    \tvcs \tconstr \tvcs$ where $\tvcs$ is a sequence of $n$ distinct type
    variables. This is clearly principal.

    \proofcase{$\t$ is a polytype $\tpoly {\tfor \tvs \t}$}

    We may assume \Wlog that each variable of $\tvs$ occurs free in
    $\t$.
    %
    Let $(\pi_i)\iton$ be the sequence of shortest paths in $\t$ that cannot be
    extended to reach a (polymorphic) variable in $\tvas$, in lexicographic
    order and $\tvcs$ be a sequence $(\tvci)\iton$ of distinct variables that do
    not appear in~$\t$.
    %
    Let $\tyz$ be $\t \where {\pi_i \is \tvci}\iton$, \ie the term $\t$ where each
    path $\pi_i$ has been substituted by the variable $\tvci$.  Let $\Sh$ be the
    shape $\any \tvcs {\tpoly {\all \tvs \tyz}}$.
    We claim that $\Sh$ is actually the principal shape of $\tpoly {\all \tvs
    \t}$.

    \medskip
    \locallabelreset

    By construction, $\t$ is equal to $\shapp[\Sh] \tys$~\llabel 1.
    where $\tys$ is the sequence composed of $\ti$ equal to $\t/\pi_i$
    for $i$ ranging from $1$ to $n$.
    %
    Indeed, by
    definition, $\shapp[\Sh] \tys$ is equal to $(\t\where {\pi_i \is \tvci}\iton)
    \where {\tvci \is \ti}$ which is obviously equal to $\t$.
    The remaining of the proof checks that $\Sh$ is minimal~\llabel 2, that is,
    we assume that $\Sh'$ is another shape such that $\tpoly {\all\tvs\t}$ is
    equal to $\shapp [\Shp] \typs$ for some $\typs$~\llabel H and show that $\Sh
    \preceq \Shp$~\llabel C.

    \medskip

    It follows from~\lref H that
      $\Shp$ must be a polytype shape, \ie of the form $\any \tvcps {\tpoly
      {\all \tvbs \typ}}$ and
      $\tpoly {\all \tvs \t}$ is equal to $\tpoly {\all\tvbs \tp} \where {\tvcps
      \is \typs}$~\llabel{P}.
    \relax
    We may assume \Wlog that $\tvbs$ and $\tvcps$ are disjoint, that
    $\tvcps$ does not contain useless variables, \ie
    that they all appear in $\tp$ and that they actually appear in lexicographic
    order.
    \relax
    Now that never term contains useless variables, \lref P implies that the
    sequences $\tvas$ and $\tvbs$ can be put in one-to-one correspondences.
    Besides, since they all ordered in the order of appearance in terms, they
    the correspondence respects the ordering. Hence, the substitution $\where
    {\tvbs \is \tvas}$ is a renaming. Therefore, we can assume \Wlog that
    $\tvbs$ is $\tvas$,
    \relax
    That is, \lref P becomes that $\tpoly {\all \tvs \t}$ is equal to $\tpoly
    {\all \tvs \typ \where {\tvcps \is \typs}}$, which given that variables
    $\tvs$ appear in the same order in both terms, implies that $\t$ is
    equal to $\typ \where {\tvcps \is
    \typs}$~\llabel T.

    \relax

    \medskip

    Since $\typs$ does not contain any variable in $\tvs$, every path $\pi_i$
    is a path in $\typ$. Thus, we may write $\typ$ as
    \relax $\typ \where {\pi_i \is \tyi''}\iton$ where $\tyi''$ is $\typ/\pi_i$.
    This is also equal to
    \relax $(\typ \where {\pi_i \is \tvci}\iton) \where {\tvci \is \tyi''}\iton$,
    that is $\tyz\where {\tvci \is \tyi''}\iton$.
    %
    In summary, we have $\typ$ is equal to
    \relax $\tyz \where {\tvci \is \tyi''}\iton$,
    which implies that
    \relax  $\tpoly {\all \tvs \typ}$ is equal to
    \relax  $\tpoly {\all \tvs {\tyz \where {\tvci \is \tyi''}\iton}}$, \ie
    \relax  $\tpoly {\all \tvs \tyz} \where {\tvci \is \tyi''}\iton$~\llabel E.
    %
    By \Rule {Inst-Shape}, we have
    \begin{mathpar}[inline]
    \any \tvcs  \tpoly {\all \tvs \tyz} \preceq
    \any \tvcps\tpoly {\all \tvs \tyz} \where {\tvci \is \tyi''}\iton,
    \end{mathpar}
    which, given~\lref E, is exactly~\lref C.

  \end{proofcases}
\end{proof}

\subsection{Canonicalization of satisfiability}

They key result in this section is that our semantic derivations $\semenv \th
\c$ can always be rewritten to only apply the rule \Rule{Match-Ctx} at the very
bottom of the derivation, rather than in the middle of derivations. This
corresponds to explicitating the unique shapes of all suspended constraints (in
some order that respects the dependency between suspended constraints), and
then continuing with a syntax-directed proof of a fully-discharged constraint.

We did not impose this ordering in our definition of the semantics to make it
more flexible and more declarative, but the inversion principle that it
provides will be helpful when reasoning about the solver in
\cref{app:proofs-solving}.

We define in \cref{fig:simple} a formal judgment $\c \simple$ that says that
$\c$ does not contain any suspended match constraint, and extend it trivially
to constraint contexts: $\C \simple$. In particular, the erasure $\cerase \c$
of a constraint (\cref{def:erasure}) is always simple. We then introduce in
\cref{fig:canonical-sem} a ``canonical'' semantic judgment $\semenv \Th \c$
that enforces the structure we mentioned: its derivation starts by discharging
suspended constraints, until eventually we reach a simple constraint $\c$.
Below we prove that any semantic derivation $\semenv \th \c$ can be turned into
a canonical semantic derivation $\semenv \Th \c$.

We can think of this result as controlling the amount of non-syntax-directness in our rules: we need some of it, but it suffices to have it only at the outside, and it contains a more standard derivation that is easy to reason about.

\paragraph{Inversion} When $\c$ is simple, a derivation of $\semenv \th \c$
does not use the contextual rule (it is a derivation in $\semenv \thsimple
\c$), so it enjoys the usual inversion principle on syntax-directed judgments;
for example, if $\semenv \thsimple {\ca \cand \cb}$ then by inversion $\semenv
\thsimple \ca$ and $\semenv \thsimple \cb$, etc.

\paragraph{Congruence} Congruence does not hold in general in our system due to
the contextual rule. For example, $\ca \eqdef (\cmatch \tva {\cbranch \wild
\ctrue})$ is unsatisfiable so we have $\ca \cequiv \cfalse$, but for $\C \eqdef
(\cexists \tva \cunif \tva \tint \cand \square)$ we have $\C \where \ca \cequiv
\ctrue$ and $\C \where \cfalse \equiv \cfalse$. It holds simply for simple
constraints.

\begin{lemma}[Simple congruence]
  \label{lem:cong-simple}
  Given simple constraints $\ca, \cb$ and simple context $\C$.
  If \\$\ca \centails \cb$, then $\C\where{\ca} \centails \C\where{\cb}$.

  \begin{proof}
    Induction on the derivation of $\C \simple$.
  \end{proof}
\end{lemma}

\paragraph{Composability}

The composability result below is an important test of our definition of the
unicity condition $\Cshape \C \t \sh$, which is in part engineered for this
lemma to be simple to prove. In the past we used a definition of unicity
that also required $\C \where \ctrue$ to be satisfiable, which broke the
composability property.
\begin{lemma}[Composability of unicity]
  \label{lem:compose-unicity}
  If $\Cshape \Ca \t \sh$, then $\Cshape {\Cb\where\Ca} \t \sh$.
  \begin{proof}
    Induction on the structure of $\Cb$.
    \begin{proofcases}
      \proofcase{$\square$}
        immediate.
      \proofcase{$\Cc \cand \c$}

	\begin{llproof}
	  \shapePf{\Ca}{\t}{\sh}{Premise}
	  \shapePf{\Cc\where\Ca}{\t}{\sh}{By \ih}
	  \ForallPf{\semenv, \gt}{}{Definition of $\Cshape {\parens{\Cc\where\Ca \cand \c}} \t \sh$}
	  \vdashPf{\semenv}{\cerase {\Cc\where\Ca\where{\cunif \t \gt}} \cand \cerase \c}{$\implies$I}
	  \vdashPf{\semenv}{\cerase {\Cc\where\Ca\where{\cunif \t \gt}}}{Simple inversion}
	  \eqPf{\shape \gt}{\sh}{$\implies$E on $\Cshape {\Cc\where\Ca} \t \sh$}
\Hand 	  \shapePf{\parens{\Cc\where\Ca \cand \c}}{\t}{\sh}{Above}
	\end{llproof}

      \proofcase{$\c \cand \Cc$}

	\begin{llproof}
	  Similar to the $\Cc \cand \c$ case.
	\end{llproof}

      \proofcase{$\cexists \tv \Cc$}

	\begin{llproof}
	  \shapePf{\Ca}{\t}{\sh}{Premise}
	  \shapePf{\Cc\where\Ca}{\t}{\sh}{By \ih}
	  \ForallPf{\semenv, \gt}{}{Definition of $\Cshape {\parens{\cexists \tv \Cc\where\Ca}} \t \sh$}
	  \vdashPf{\semenv}{\cexists \tv \cerase {\Cc\where\Ca\where{\cunif \t \gt}}}{$\implies$I}
	  \vdashPf{\semenv\where{\tv \is \gtp}}{\cerase {\Cc\where\Ca\where{\cunif \t \gt}}}{Simple inversion}
	  \eqPf{\shape \gt}{\sh}{$\implies$E on $\Cshape {\Cc\where\Ca} \t \sh$}
\Hand 	  \shapePf{\parens{\cexists \tv \Cc\where\Ca}}{\t}{\sh}{Above}
	\end{llproof}

      \proofcase{$\cfor \tv \Cc$}

	\begin{llproof}
	  Similar to $\cexists \tv \Cc$ case.
	\end{llproof}

      \proofcase{$\cexistsi \inst \x \Cc$}

	\begin{llproof}
	  Similar to $\cexists \tv \Cc$ case.
	\end{llproof}

      \proofcase{$\clet \x \tv \Cc \c$}

	\begin{llproof}
	  \shapePf{\Ca}{\t}{\sh}{Premise}
	  \shapePf{\Cc\where\Ca}{\t}{\sh}{By \ih}
	  \ForallPf{\semenv, \gt}{}{Definition of $\Cshape {\parens {\Let \x \ldots}} \t \sh$}
	  \vdashPf{\semenv}{\clet \x \tv {\cerase {\Cc\where\Ca\where{\cunif \t \gt}}} {\cerase \c}}{$\implies$I}
	  \vdashPf{\semenv}{\cexists \tv \cerase {\Cc\where\Ca\where{\cunif \t \gt}}}{Simple inversion}
	  \vdashPf{\semenv\where{\tv \is \gtp}}{\cerase {\Cc\where\Ca\where{\cunif \t \gt}}}{Simple inversion}
	  \eqPf{\shape \gt}{\sh}{$\implies$E on $\Cshape {\Cc\where\Ca} \t \sh$}
\Hand 	  \shapePf{\parens{\clet \x \tv {\Cc\where\Ca} \c}}{\t}{\sh}{Above}
	\end{llproof}

      \proofcase{$\clet \x \tv \c \Cc$}

	\begin{llproof}
	  Similar to $\clet \x \tv \Cc \c$ case.
	\end{llproof}

      \proofcase{$\cletr \x \tv \tvs \Cc \c$}

	\begin{llproof}
	  Similar to $\clet \x \tv \Cc \c$ case.
	\end{llproof}

      \proofcase{$\cletr \x \tv \tvs \c \Cc$}

	\begin{llproof}
	  Similar to $\clet \x \tv \c \Cc$ case.
	\end{llproof}
    \end{proofcases}
  \end{proof}
\end{lemma}

\begin{lemma}[Inversion of unicity]
  \label{lem:unicity-inversion}~
  \begin{enumerate}[(\roman*)]
    \item If $\Cshape {\parens{\cexists \tv \C}} \t \sh$, then $\Cshape \C \t \sh$.
    \item If $\Cshape {\parens{\cfor \tv \C}} \t \sh$, then $\Cshape \C \t \sh$.
  \end{enumerate}
  \begin{proof}
    The definition of $\Cshape \C \t \sh$ uses simple semantics on the
    erasure $\cerase \C$, so these results are easily shown by simple inversion.
  \end{proof}
\end{lemma}

\begin{lemma}[Decanonicalization]
  \label{lem:decanonicalization}
  If $\semenv \Th \c$, then $\semenv \th \c$.
  \begin{proof}
    Induction on the given derivation $\semenv \Th \c$
  \end{proof}
\end{lemma}

\begin{theorem}[Canonicalization]
  \label{thm:canonicalization}
  If $\semenv \th \c$, then $\semenv \Th \c$.
  \begin{proof}
  We proceed by induction on $\semenv \th \c$ with the measure $\cmeasure \c$.
  \begin{proofcases}
    \proofcasederivation
      {True}
      { }
      {\semenv \th \ctrue}

      \begin{llproof}
\Hand   \VdashPf{\semenv}{\ctrue}{immediate by \Rule{Can-Base}}
      \end{llproof}

    \proofcasederivation
      {Unif}
      {\semenv(\ta) = \semenv(\tb)}
      {\semenv \th \cunif \ta \tb}

      \begin{llproof}
	Similar to the \Rule{True} case.
      \end{llproof}
    \proofcasederivation
      {Conj}
      {\semenv \th \ca \\ \semenv \th \cb}
      {\semenv \th \ca \cand \cb}

      \begin{llproof}
	\vdashPf{\semenv}{\ca} {Premise}
	\vdashPf{\semenv}{\cb} {Premise}
	\VdashPf{\semenv}{\ca} {By \ih}
	\VdashPf{\semenv}{\cb} {By \ih}
	\decolumnizePf
	\casesPf{\semenv \Th \ca, \semenv \Th \cb}
      \end{llproof}

      \begin{proofcases}
	\proofcasederivationdouble
	  {Can-Base}
	  {\semenv \th \ca \\ \ca \simple}
	  {\semenv \Th \ca}
	  {Can-Base}
	  {\semenv \th \cb \\ \cb \simple}
	  {\semenv \Th \cb}

        \begin{llproof}
\Hand     \VdashPf{\semenv}{\ca \cand \cb}{immediate by \Rule{Can-Base}}
        \end{llproof}


	\proofcasederivationdouble
	  {Can-Match-Ctx}
	  {\Cshape \C \t \sh \\ \semenv \Th \C\where{\cmatched \t \sh \cbrs}}
	  {\semenv \Th \underbrace{\C\where{\cmatch \t \cbrs}}_\ca}
	  {}
	  {}
	  {\semenv \Th \cb}

	  \begin{llproof}

	    \VdashPf{\semenv}{\C\where{\cmatched \t \sh \cbrs}} {Premise}
	    \vdashPf{\semenv}{\C\where{\cmatched \t \sh \cbrs}} {\cref{lem:decanonicalization}}
	    \vdashPf{\semenv}{\C\where{\cmatched \t \sh \cbrs} \cand \cb}{By \Rule{Conj}}
 	    \VdashPf{\semenv}{\C\where{\cmatched \t \sh \cbrs} \cand \cb}{By \ih}
	    \Pf{}{}{\Cshape \C \tv \sh}{Premise}
	    \Pf{}{}{\Cshape {\parens {\C \cand \cb}} \tv \sh}{\cref{lem:compose-unicity}}
\Hand 	    \VdashPf{\semenv}{\C\where{\cmatch \t \cbrs}}{By \Rule{Can-Match-Ctx}}
	  \end{llproof}

	\proofcasederivationdouble
	  {}
	  {}
	  {\semenv \Th \ca}
	  {Can-Match-Ctx}
	  {\Cshape \C \t \sh \\ \semenv \Th \C\where{\cmatched \t \sh \cbrs}}
	  {\semenv \Th \underbrace{\C\where{\cmatch \t \cbrs}}_\cb}

	  \begin{llproof}
	    \Pf{}{}{}{Symmetric to the above case.}
	  \end{llproof}
      \end{proofcases}

      \proofcasederivation
	{Exists}
	{\semenv\where{\tv \is \gt} \th \c}
	{\semenv \th \cexists \tv \c}

	\begin{llproof}
	  \vdashPf{\semenv\where{\tv \is \gt}}{\c}{Premise}
	  \VdashPf{\semenv\where{\tv \is \gt}}{\c}{By \ih}
	  \casesPf{\semenv\where{\tv \is \gt} \Th \c}
	\end{llproof}

	\begin{proofcases}

	    \proofcasederivation
	      {Can-Base}
	      {\semenv\where{\tv \is \gt} \th \c \\ \c \simple}
	      {\semenv\where{\tv \is \gt} \Th \c}

	      \begin{llproof}
\Hand 		\VdashPf{\semenv}{\cexists \tv \c}{Immediate by \Rule{Can-Base}}
	      \end{llproof}


	      \proofcasederivation
		{Can-Match-Ctx}
		{\Cshape \C \t \sh \\ \semenv\where{\tv \is \gt} \Th \C\where{\cmatched \t \sh \cbrs}}
		{\semenv \Th \underbrace{\C\where{\cmatch \t \cbrs}}_\c}

		\begin{llproof}
		  \VdashPf{\semenv\where{\tv \is \gt}}{\C\where{\cmatched \t \sh \cbrs}}{Premise}
		  \vdashPf{\semenv\where{\tv \is \gt}}{\C\where{\cmatched \t \sh \cbrs}}{\cref{lem:decanonicalization}}
	    \decolumnizePf
		  \vdashPf{\semenv}{\cexists \tv \C\where{\cmatched \t \sh \cbrs}}{By \Rule{Exists}}
		  \VdashPf{\semenv}{\cexists \tv \C\where{\cmatched \t \sh \cbrs}}{By \ih}
		  \Pf{}{}{\Cshape \C \t \sh}{Premise}
		  \Pf{}{}{\Cshape {\parens {\cexists \tv \C}} \t \sh}{\cref{lem:compose-unicity}}
\Hand             \VdashPf{\semenv}{\cexists \tv \C\where{\cmatch \t \cbrs}}{By \Rule{Can-Match-Ctx}}
		\end{llproof}
	\end{proofcases}

	\proofcasederivation
	  {Forall}
	  {\forall \gt,~ \semenv\where{\tv \is \gt} \th \c}
	  {\semenv \th \cfor \tv \c}

	  \begin{llproof}
	    Similar to the \Rule{Exists} case.
	  \end{llproof}

	\proofcasederivation
	  {Let}
	  {\semenv \th \cexists \tv \ca \\ \semenv\where{\x \is \semenv(\cabs \tv \ca)} \th \cb}
	  {\semenv \th \clet \x \tv \ca \cb}

	  \begin{llproof}
	    \vdashPf{\semenv}{\cexists \tv \ca}{Premise}
	    \VdashPf{\semenv}{\cexists \tv \ca}{By \ih}
	    \vdashPf{\semenv\where{\x \is \semenv(\cabs \tv \ca)}}{\cb}{Premise}
	    \VdashPf{\semenv\where{\x \is \semenv(\cabs \tv \ca)}}{\cb}{By \ih}
	    \decolumnizePf
	    \casesPf{\semenv \Th \cexists \tv \ca, \semenv\where{\x \is \semenv(\cabs \tv \ca)} \Th \cb}
	  \end{llproof}

	  \begin{proofcases}
	    \proofcasederivationdouble
	      {Can-Base}
	      {\semenv \th \cexists \tv \ca \\ \cexists \tv \ca \simple}
	      {\semenv \Th \cexists \tv \ca}
	      {Can-Base}
	      {\semenv\where{\x \is \semenv(\cabs \tv \ca)} \th \cb \\ \cb \simple}
	      {\semenv\where{\x \is \semenv(\cabs \tv \ca)} \Th \cb}

	      \begin{llproof}
\Hand		\VdashPf{\semenv}{\clet \x \tv \ca \cb}{Immediate by \Rule{Can-Base}}
	      \end{llproof}

	    \proofcasederivationdouble
	      {Can-Match-Ctx}
	      {\Cshape {\parens {\cexists \tv \ca}} \t \sh \\ \semenv \Th \cexists \tv \C\where{\cmatched \t \sh \cbrs}}
	      {\semenv \Th \cexists \tv \underbrace{\C\where{\cmatch \t \cbrs}}_\ca}
	      {}
	      {}
	      {\semenv\where{\x \is \semenv(\cabs \tv \ca)} \Th \cb}

	      \begin{llproof}
		\shapePf{\parens {\cexists \tv \C}}{\t}{\sh}{Premise}
		\shapePf{\C}{\t}{\sh}{\cref{lem:unicity-inversion}}
		\VdashPf{\semenv}{\cexists \tv \C\where{\cmatched \t \sh \cbrs}}{Premise}
		\vdashPf{\semenv}{\cexists \tv \C\where{\cmatched \t \sh \cbrs}}{\cref{lem:decanonicalization}}
	    \decolumnizePf
		\eqPf{\semenv(\cabs \tv \ca)}
		  {\semenv(\cabs \tv \C\where{\cmatched \t \sh \cbrs})}
		  {\cref{corollary:matched-abstractions}}
		\vdashPf{\semenv}{\clet \x \tv {\C\where{\cmatched \t \sh \cbrs}} \cb}{By \Rule{Let}}
		\VdashPf{\semenv}{\clet \x \tv {\C\where{\cmatched \t \sh \cbrs}} \cb}{By \ih}
		\shapePf{\parens{\clet \x \tv \C \cb}}{\t}{\sh}{\cref{lem:compose-unicity}}
\Hand 		\VdashPf{\semenv}{\clet \x \tv {\C\where{\cmatch \t \cbrs}} \cb}{By \Rule{Can-Match-Ctx}}
	      \end{llproof}

	    \proofcasederivationdouble
		{}
		{}
		{\semenv \Th \cexists \tv \ca}
		{Can-Match-Ctx}
		{\Cshape \C \t \sh \\ \semenv\where{\x \is \semenv(\cabs \tv \ca)} \Th \C\where{\cmatched \t \sh \cbrs}}
		{\semenv\where{\x \is \semenv(\cabs \tv \ca)} \Th \underbrace{\C\where{\cmatch \t \cbrs}}_\cb}

		\begin{llproof}
		  \shapePf{\C}{\t}{\sh}{Premise}
		  \shapePf{\parens{\clet \x \tv \ca \C}}{\t}{\sh}{\cref{lem:compose-unicity}}
		  \VdashPf{\semenv\where{\x \is \semenv(\cabs \tv \ca)}}{\C\where{\cmatched \t \sh \cbrs}}{Premise}
		  \vdashPf{\semenv\where{\x \is \semenv(\cabs \tv \ca)}}{\C\where{\cmatched \t \sh \cbrs}}{\cref{lem:decanonicalization}}
		  \vdashPf{\semenv}{\clet \x \tv \ca {\C\where{\cmatched \t \sh \cbrs}}}{By \Rule{Let}}
		  \VdashPf{\semenv}{\clet \x \tv \ca {\C\where{\cmatched \t \sh \cbrs}}}{By \ih}
\Hand 		  \VdashPf{\semenv}{\clet \x \tv \ca {\C\where{\cmatch \t \sh}}}{By \Rule{Can-Match-Ctx}}
		\end{llproof}
	  \end{proofcases}

      \proofcasederivation
	{App}
	{\semenv(\t) \in \semenv(\x)}
	{\semenv \th \capp \x \t}

      \begin{llproof}
	Similar to the \Rule{True} case.
      \end{llproof}

      \proofcasederivation
	{LetR}
	{\semenv \th \cexists {\tv, \tvs} \ca \\
	 \semenv\where{\x \is \semenv(\cabsr \tv \tvs \ca)} \th \cb}
	{\semenv \th \cletr \x \tv \tvs \ca \cb}

      \begin{llproof}
	Similar to the \Rule{Let} case.
      \end{llproof}

      \proofcasederivation
	{AppR}
	{\greg \tv \semenvp \in \semenv(\x) \\
	 \semenv(\t) = \semenvp(\tv)}
	{\semenv \th \capp \x \t}

      \begin{llproof}
	Similar to the \Rule{App} case.
      \end{llproof}

    \proofcasederivation
      {Exists-Inst}
      {\greg \tv \semenvp \in \semenv(\x) \\ \semenv\where{\inst \is \semenvp} \th \c}
      {\semenv \th \cexistsi \inst \x \c}

      \begin{llproof}
	Similar to the \Rule{Exists} case.
      \end{llproof}


    \proofcasederivation
      {Multi-Unif}
      {\forall \t \in \ueq,~ \semenv(\t) = \gt}
      {\semenv \th \ueq}

      \begin{llproof}
	Similar to the \Rule{Unif} case.
      \end{llproof}

    \proofcasederivation
      {Partial-Inst}
      {\semenv(\inst)(\tv) = \semenv(\t)}
      {\semenv \th \cpinst \inst \tv \t}


      \begin{llproof}
	Similar to the \Rule{App} case.
      \end{llproof}


  \end{proofcases}
  \end{proof}
\end{theorem}

\begin{lemma}[Inversion of suspension]
  \label{lem:susp-inversion}
  If $\semenv \th \C\where{\cmatch \t \cbrs}$ and $\Cshape \C \t \sh$,
  then\\$\semenv \th \C\where{\cmatched \t \sh \cbrs}$.

  \begin{proof}
    We use canonicalization (\cref{thm:canonicalization}) to induct on $\semenv \Th
    \C\where{\cmatch \t \cbrs}$ instead of $\semenv \th \C\where{\cmatch \t
    \cbrs}$.

    This simplifies the proof, but introduces a circular dependency between
    \cref{thm:canonicalization} and \cref{lem:susp-inversion}.
    %
    However, this does not compromise the well-foundedness of induction, as the
    application of \cref{lem:susp-inversion} (via
    \cref{corollary:matched-abstractions}) within the proof of
    \cref{thm:canonicalization} is restricted to strictly smaller constraints.

    \begin{proofcases}
      \proofcasederivation
	{Can-Base}
	{\semenv \th \C\where{\cmatch \t \cbrs} \\ \C\where{\cmatch \t \cbrs} \simple}
	{\semenv \Th \C\where{\cmatch \t \cbrs}}

        The second premise is a contradiction.

      \proofcasederivation
	{Can-Match-Ctx}
	{\Cshape \Cp \tp \shp \\ \semenv \Th \Cp\where{\cmatched \tp \shp \cbrs'}}
	{\semenv \Th \underbrace{\Cp\where{\cmatch \tp \cbrs'}}_{\C\where{\cmatch {~\t~} {~\cbrs}}}}

	\begin{llproof}
	  \casesPf{\C = \Cp}
	\end{llproof}
	\begin{proofcases}
	  \proofcase{$\C = \Cp$}

	    \begin{llproof}
	      \eqPf{\C}{\Cp}{Premise}
	      \eqPf{\tp}{\t}{}
	      \eqPf{\shp}{\sh}{}
	      \eqPf{\cbrs'}{\cbrs}{}
\Hand         \VdashPf{\semenv}{\C\where{\cmatched \t \sh \cbrs}}{Premise}
	    \end{llproof}

	  \proofcase{$\C \neq \Cp$}

	    \newcommand{\Ctwo}{\C_2}
	    \begin{llproof}
	      \eqPf{\Ctwo\where{\cmatch \t \cbrs, \cmatch \tp \cbrs'}}{\C\where{\cmatch \t \cbrs}}{For some 2-hole context $\Ctwo$}
	      \continueeqPf{\Cp\where{\cmatch \tp \cbrs'}}{}
	      \decolumnizePf
	      \VdashPf{\semenv}{\Ctwo\where{\cmatch \t \cbrs, \cmatched \tp \shp \cbrs'}}{Premise}
	      \decolumnizePf
	      \ForallPf{\semenvp, \gtp}{}{\hspace{32.5ex}Defn. of $\Cshape {\Ctwo\where{\square, \cmatched \tp \shp \cbrs'}} \t \sh$}
	      \decolumnizePf
	      \vdashPf{\semenvp}{\cerase {\Ctwo\where{\cunif \t \gtp, \cmatched \tp \shp \cbrs'}}}{$\implies$I}
	      \vdashPf{\semenvp}{\cerase {\Ctwo\where{\cunif \t \gtp, \ctrue}}}{\cref{lem:cong-simple}}
	    \decolumnizePf
	      \eqPf{\cerase {\Ctwo\where{\cunif \t \gtp, \ctrue}}}{\cerase {\Ctwo\where{\cunif \t \gtp, \cerase {\cmatch \tp \cbrs'}}}}{By definition}
	      \continueeqPf{\cerase {\C\where{\cunif \t \gtp}}}{By definition}
	      \vdashPf{\semenvp}{\cerase {\C\where{\cunif \t \gtp}}}{Above}
	      \eqPf{\shape \gtp}{\sh}{$\implies$E on $\Cshape \C \t \sh$}
	      \shapePf{\Ctwo\where{\square, \cmatched \tp \shp \cbrs'}}{\t}{\sh}{Above}
	      \VdashPf{\semenv}{\Ctwo\where{\cmatched \t \sh \cbrs, \cmatched \tp \shp \cbrs'}}{By \ih}
	      \decolumnizePf
	      \ForallPf{\semenvp, \gtp}{}{\hspace{32.5ex}Defn. of $\Cshape {\Ctwo\where{\cmatched \t \sh \cbrs, \square}} \tp \shp$}
	      \decolumnizePf
	      \vdashPf{\semenvp}{\cerase {\Ctwo\where{\cmatched \t \sh \cbrs, \cunif \tp \gtp}}}{$\implies$I}
	      \vdashPf{\semenvp}{\cerase {\Ctwo\where{\ctrue, \cunif \tp \gtp}}}{\cref{lem:cong-simple}}
	      \eqPf{\cerase {\Ctwo\where{\ctrue, \cunif \tp \gtp}}}{\cerase {\Ctwo\where{\cerase {\cmatch \t \cbrs}, \cunif \tp \gtp}}}{By definition}
	      \continueeqPf{\cerase {\Cp\where{\cunif \tp \gtp}}}{By definition}
	      \vdashPf{\semenvp}{\cerase {\C\where{\cunif \t \gtp}}}{Above}
	      \shapePf{\Cp}{\tp}{\shp}{Premise}
	      \eqPf{\shape \gtp}{\shp}{$\implies$E on $\Cshape \Cp \tp \shp$}
	      \shapePf{\Ctwo\where{\cmatched \t \sh \cbrs, \square}}{\tp}{\shp}{Above}
\Hand 	      \VdashPf{\semenv}{\Ctwo\where{\cmatched \t \sh \cbrs, \cmatch \tp \cbrs'}}{By \Rule{Con-Match-Ctx}}
	    \end{llproof}
	\end{proofcases}
    \end{proofcases}
  \end{proof}
\end{lemma}

\begin{corollary}
  \label{corollary:matched-abstractions}
  If $\Cshape \C \t \sh$, then $\semenv(\cabs \tv \C\where{\cmatch \t \cbrs}) = \semenv(\cabs \tv \C\where{\cmatched \t \sh \cbrs})$.
  Similarly, $\semenv(\cabsr \tv \tvs \C\where{\cmatch \t \cbrs}) = \semenv(\cabsr \tv \tvs \C\where{\cmatched \t \sh \cbrs})$.
  \begin{proof}
    It is sufficient to show that $\semenv\where{\tv \is \gt} \th \C\where{\cmatch \t \cbrs}$ if and only if
    $\semenv \th \C\where{\cmatched \t \sh \cbrs}$.

    \begin{proofcases}
      \proofcase{$\implies$}

	\begin{llproof}
	  \shapePf{\C}{\t}{\sh}{Premise}
	  \vdashPf{\semenv\where{\tv \is \gt}}{\C\where{\cmatch \t \cbrs}}{Premise}
\Hand 	  \vdashPf{\semenv\where{\tv \is \gt}}{\C\where{\cmatched \t \sh \cbrs}}{\cref{lem:susp-inversion}}
	\end{llproof}
      \proofcase{$\impliedby$}

	\begin{llproof}
	  \shapePf{\C}{\t}{\sh}{Premise}
	  \vdashPf{\semenv\where{\tv \is \gt}}{\C\where{\cmatched \t \sh \cbrs}}{Premise}
\Hand 	  \vdashPf{\semenv\where{\tv \is \gt}}{\C\where{\cmatch \t \cbrs}}{By \Rule{Match-Ctx}}
	\end{llproof}
    \end{proofcases}

    For $\semenv(\cabsr \tv \tvs \C\where{\cmatch \t \cbrs}) = \semenv(\cabsr \tv \tvs \C\where{\cmatched \t \sh \cbrs})$, the proof is identical.
  \end{proof}
\end{corollary}

\section{Properties of the constraint solver}
\label{app:proofs-solving}

The primary requirement of our constraint solver is correctness:
a constraint $\c$ is satisfiable if and only if the solver terminates with a solution.

This section decomposes this requirement into three properties: preservation,
progress, and termination---and provides proofs for each. Correctness then
follows as a corollary of these results.

\subsection{Preservation}

This section details the proof of \emph{preservation} for the solver: if $\ca
\csolve \cb$, then $\ca \cequiv \cb$.
%
Since rewriting may occur under arbitrary contexts, it suffices to check for
each rule, that the equivalence $\ca \cequiv \cb$ holds under all contexts
$\C$.

However, the introduction of suspended match constraints breaks congruence of
equivalence. That is, it is no longer the case that $\ca \cequiv \cb$ implies
$\C\where\ca \cequiv \C\where\cb$.
%
For instance, we have $\cmatch \tv \cbrs \cequiv \cfalse$, yet
$\C\where{\cmatch \tv \cbrs} \cnequiv \C\where\cfalse$ for $\C \is \square
\cand \cunif \tv \tint$.

As a result, we must prove \emph{contextual equivalence} for each rewriting
rule explicitly. This is both non-trivial and tedious. To simplify the task, we
first present a series of auxiliary lemmas that recover contextual equivalence
for many common cases.
%
Whenever possible, we prefer to work with equivalences on \emph{simple}
constraints, as these retain the desired congruence properties that do not hold
generally in our system.

\begin{definition}[Contextual eqiuvalence]
  Two constraints $\ca$ and $\cb$ are contextually equivalence, written $\ca \cequivctx \cb$,
  iff:
  \begin{mathpar}
    \ca \cequivctx \cb \uad\eqdef\uad \all \C \uad \C\where\ca \cequiv \C\where\cb
  \end{mathpar}
\end{definition}

\begin{corollary}[Simple equivalence is congruent]
  \label{corollary:cong-simple-equiv}
  Given simple constraints $\ca, \cb$ and simple context $\C$. If
  $\ca \cequiv \cb$, then $\C\where\ca \equiv \C\where\cb$.
  \begin{proof}
    Follows from \cref{lem:cong-simple}.
  \end{proof}
\end{corollary}

\begin{lemma}[Simple equivalence is contextual]
  \label{lem:ctxt-equiv-simple}
  For simple constraints $\ca, \cb$. If $\ca \cequiv \cb$, then $\ca \cequivctx \cb$.
  \begin{proof}
    We proceed by induction on the number of suspended match constraints $n$ in $\C$.

    \begin{proofcases}
      \proofcase{$n$ is 0}
	Follows from \cref{corollary:cong-simple-equiv}.

      \proofcase{$n$ is $k + 1$}

	\begin{proofcases}
	  \proofcase{$\implies$}

	  \newcommand{\Ctwo}{\Cb}
	  \begin{llproof}
	    \vdashPf{\semenv}{\C\where{\ca}}{Premise}
	    \VdashPf{\semenv}{\C\where{\ca}}{\cref{thm:canonicalization}}
	    \shapePf\Cp\t\sh{Inversion of \Rule{Can-Match-Ctx}}
	    \VdashPf{\semenv}{\Cp\where{\cmatched \t \sh \cbrs}}{\ditto}
	    \eqPf{\C\where{\ca}}{\Cp\where{\cmatched \t \sh \cbrs}}{\ditto}
	    \continueeqPf{\Ctwo\where{\cmatched \t \sh \cbrs, \ca}}{For some two-hole context $\Ctwo$}
	    \vdashPf{\semenv}{\Ctwo\where{\cmatched \t \sh \cbrs, \cb}}{By \ih}
	    \ForallPf{\semenvp, \gt}{}{Defn of $\Cshape \Cp \t \sh$}
	    \vdashPf{\semenvp}{\cerase{\Ctwo\where{\t \is \gt, \cb}}}{Premise}
	    \vdashPf{\semenvp}{\cerase{\Ctwo\where{\t \is \gt, \ca}}}{\cref{corollary:cong-simple-equiv}}
	    \vdashPf{\semenvp}{\cerase{\Cp\where{\t \is \gt}}}{Above}
	    \eqPf{\shape \gt}{\sh}{$\implies$E on $\Cshape \Cp \t \sh$}
	    \decolumnizePf
	    \shapePf{\Ctwo\where{\square, \cb}}{\t}{\sh}{Above}
\Hand	    \vdashPf{\semenv}{\Ctwo\where{\cmatch \t \cbrs, \cb}}{By \Rule{Match-Ctx}}
	  \end{llproof}

	  \proofcase{$\impliedby$}

	  \begin{llproof}
	    Symmetric argument.
	  \end{llproof}
	\end{proofcases}
    \end{proofcases}
  \end{proof}
\end{lemma}

\begin{lemma}[Unification is simple]
  \label{lem:unif-problem-simple}
  For all unification problems $\up$, $\up \simple$.
  \begin{proof}
    By induction on the structure of $\up$.
  \end{proof}
\end{lemma}


\begin{definition}[Context equivalence]
  Two contexts $\Ca$ and $\Cb$ are equivalent with guard $P$, written $\Ca \cctxequiv^P \Cb$ iff:
  \begin{mathpar}
    \Ca \cctxequiv^P \Cb \uad\eqdef\uad \all \cs \uad P(\cs) \implies \Ca\where\cs \cequivctx \Cb\where\cs
  \end{mathpar}
\end{definition}

\begin{definition}[Match-closed]
  A predicate $P$ on constraints is \emph{match-closed} if, for all constraints $\cs, \cs'$, contexts $\C$, matches $\cmatch \t \cbrs$ and shapes $\sh$,
  \begin{mathpar}
    P(\cs, \C\where{\cmatch \t \cbrs}, \cs') \implies P(\cs, \C\where{\cmatched \t \sh \cbrs}, \cs')
  \end{mathpar}
\end{definition}

\begin{lemma}[Determines is match-closed]
  \label{lem:determines-is-match-closed}
  $\cdetermines \c \tvbs$ is match-closed. Similarly, $\th \cdetermines \c \tvbs$ is matched closed.
  \begin{proof}
    Follows from the definitions of $\cdetermines \c \tvbs$, $\th \cdetermines \c \tvbs$, and \cref{lem:cong-simple}.
  \end{proof}
\end{lemma}


\begin{lemma}[Simple context equivalence]
  \label{lem:simple-ctxt-equiv}
  For any two simple contexts $\Ca, \Cb$ and a match-closed guard $P$. If
  the two contexts $\Ca$ and $\Cb$ are equivalent under any simple constraints satisfying $P$,
  then $\Ca \cctxequiv^P \Cb$.

  \begin{proof}
    Let us assume that ($\dagger$) holds:
    \begin{mathpar}
      \all{\C, \cs \simple} P(\cs) \implies \C\where{\Ca\where\cs} \cequiv \C\where{\Cb\where\cs}
    \end{mathpar}

    We proceed by induction on the number of suspended match constraints $n$ with
    the statement $Q(n) \is  \all {\cs, \C} \cnmatches {\C} + \cnmatches \cs = n \implies P(\cs) \implies
    \C\where{\Ca\where\cs} \equiv \C\where{\Cb\where\cs}$.


    \begin{proofcases}
      \proofcase{$n$ is 0}

	\begin{llproof}
	  \simplePf{\C, \cs}{Premise ($n$ is 0)}
	  \Hand	  \equivPf{P(\cs) \implies \C\where\Ca\where\cs}{\C\where\Cb\where\cs}{$\dagger$}
	\end{llproof}

      \proofcase{$n$ is $k + 1$}

	\begin{proofcases}
	  \proofcase{$\implies$}

	  \begin{llproof}
	    \Pf{P(\cs)}{}{}{Premise}
	    \vdashPf{\semenv}{\C\where\Ca\where\cs}{Premise}
	    \VdashPf{\semenv}{\C\where\Ca\where\cs}{\cref{thm:canonicalization}}
	    \VdashPf{\semenv}{\Cp\where{\cmatched \t \sh \cbrs}}{Inversion of \Rule{Can-Match-Ctx}}
	    \shapePf{\Cp}{\t}{\sh}{\ditto}
	    \eqPf{\C\where\Ca\where\cs}{\Cp\where{\cmatch \t \cbrs}}{\ditto}
	    \commentPf{Cases on $\C, \cs$.}{}
	  \end{llproof}

	  \begin{proofcases}
	    \proofcase{$\C$ contains $\Cp$'s hole}

	      \newcommand{\Ctwo}{\Cc}
	      \begin{llproof}
		\eqPf{\C\where\Ca\where\cs}{\Ctwo\where{\cmatch \t \cbrs, \Ca\where\cs}}{For some 2-hole context $\Ctwo$}
		\VdashPf{\semenv}{\Ctwo\where{\cmatched \t \sh \cbrs, \Ca\where\cs}}{}
		\eqPf{k}{\cnmatches {\Ctwo\where{\cmatched \t \sh \cbrs, \Ca\where\cs}}}{}
		\vdashPf{\semenv}{\Ctwo\where{\cmatched \t \sh \cbrs, \Cb\where\cs}}{By \ih}
		\decolumnizePf
		\ForallPf{\semenvp, \gt}{}{}
		\vdashPf{\semenvp}{\cerase{\Ctwo\where{\cunif \t \gt, \Cb\where\cs}}}{Premise}
		\vdashPf{\semenvp}{\cerase{\Ctwo\where{\cunif \t \gt, \Ca\where\cs}}}{$\dagger$}
		\eqPf{\shape \gt}{\sh}{$\implies$E on $\Cshape \Cp \t \sh$}
		\shapePf{\Ctwo\where{\square, \Cb\where\cs}}{\t}{\sh}{Above}
\Hand		\vdashPf{\semenv}{\Ctwo\where{\cmatch \t \cbrs, \Cb\where\cs}}{By \Rule{Match-Ctx}}
	      \end{llproof}

	    \proofcase{$\ci$ contains $\Cp$'s hole}

	      \begin{llproof}
		Similar argument to the above case, but relies on the match-closure of $P$.
	      \end{llproof}
	  \end{proofcases}


	  \proofcase{$\impliedby$}

	  \begin{llproof}
	    Symmetric argument.
	  \end{llproof}
	\end{proofcases}
    \end{proofcases}
  \end{proof}
\end{lemma}


\begin{lemma}[Simple let equivalence]
  \label{lem:simple-let-equiv}
  Given simple constraints $\ca, \cb$ and a simple context $\C$.
  Suppose that
    \begin{mathpar}
      \forall \semenv, \semenvp, \cs \simple. \uad
	\semenvp(\x) = \semenv(\cabsr \tv \tvs {\C\where\cs}) \implies
	  \semenvp \th \ca \iff \semenvp \th \cb
    \end{mathpar}
  Then, for any context $\Cp$ that does not re-bind $\x$, we have:
    \begin{mathpar}
      \cletr \x \tv \tvs {\C\where{\bar\square}} {\Cp\where\ca}
	\cctxequiv^P \cletr \x \tv \tvs {\C\where{\bar\square}} {\Cp\where\cb}
    \end{mathpar}
  for any match-closed guard $P$ on the holes.

  \begin{proof}
    Let us assume ($\dagger$):
    \begin{mathpar}
      \forall \semenv, \semenvp, \cs. \uad
	\semenvp(\x) = \semenv(\cabsr \tv \tvs {\C\where\cs}) \implies
	  \semenvp \th \ca \iff \semenvp \th \cb
    \end{mathpar}

    We proceed by induction on the number of suspended match constraints in
    $\Cpp, \Cp, \cs$ with the statement $P(n) \is \all {\Cpp, \Cp, \cs} \cnmatches {\Cpp, \Cp, \cs} = n \implies \Cpp\where{\cletr \x \tv \tvs {\C\where\cs} {\Cp\where{\ca}}}
    \cequiv \Cpp\where{\cletr \x \tv \tvs {\C\where\cs} {\Cp\where\cb}}$.

    \begin{proofcases}
      \proofcase{$n$ is 0}

	Thus $\Cpp, \Cp, \cs$ are simple. It suffices to show the equivalence on the $\Let$-constraint directly and use congruence
	of equivalence for simple constraints (\cref{lem:ctxt-equiv-simple}) to establish the result.

	We proceed by induction on the structure of $\Cp$ with the statement ($\ddagger$):
	\begin{mathpar}
	\forall \semenv, \semenvp. \uad
	  \semenvp(\x) = \semenv(\cabsr \tv \tvs {\C\where\cs}) \implies
	    \semenvp \th \Cp\where{\ca} \iff \semenvp \th \Cp\where{\cb}
	\end{mathpar}
	This holds due to the compositionality of simple equivalence using $\dagger$ as a base case.

	\begin{proofcases}
	  \proofcase{$\implies$}

	\begin{llproof}
	  \vdashPf{\semenv}{\cletr \x \tv \tvs {\C\where{\cs}} {\Cp\where{\ca}}}{Premise}
	  \vdashPf{\semenv}{\cexists {\tv, \tvs} \C\where{\cs}}{Simple inversion}
	  \vdashPf{\semenv\where{\x \is \semenv(\cabsr \tv \tvs \C\where{\cs})}}{\Cp\where{\ca}}{\ditto}
	  \vdashPf{\semenv\where{\x \is \semenv(\cabsr \tv \tvs \C\where{\cs})}}{\Cp\where{\cb}}{$\ddagger$}
	  \vdashPf{\semenv}{\cletr \x \tv \tvs {\C\where{\cs}} {\Cp\where{\cb}}}{By \Rule{LetR}}
	\end{llproof}
	  \proofcase{$\impliedby$}

	  \begin{llproof}
	    Symmetric argument.
	  \end{llproof}
	\end{proofcases}

      \proofcase{$n$ is $k + 1$}

      \begin{llproof}
	Analogous to the inductive step in \cref{lem:simple-ctxt-equiv}.
      \end{llproof}
    \end{proofcases}
  \end{proof}
\end{lemma}

\newcommand{\disjointPf}[3]{\Pf{#1}{\disjoint}{#2}{#3}}
\begin{lemma}
  \label{lem:unicity-soundness}
  If $\th \Cshape \C \t \sh$, then $\Cshape \C \t \sh$.

  \begin{proof}
    \begin{proofcases}
      \proofcasederivation
      {S-Uni-Type}
      {{\t \notin \TyVars}}
      {\th \Cshape \C \t {~\shape \t}}

      \begin{llproof}
        \notinPf{\t}{\TyVars}{Premise}
        \eqPf{\t}{\shapp[\shape \t] \tys}{For some $\tys$}
        \ForallPf{\semenv, \gt}{}{Defn. of $\Cshape \C \t {~\shape \t}$}
        \vdashPf{\semenv}{\cerase{\C\where{\cunif \t \gt}}}{Premise}
        \vdashPf{\semenva}{\cunif \t \gt}{Inversion of $\cerase \Ca$}
        \eqPf{\gt}{\semenva(\t)}{Simple inversion}
        \continueeqPf{\shapp[\shape \t] {\semenva(\tys)}}{\ditto}
\Hand   \eqPf{\shape \gt}{\shape \t}{Applying shape to both sides}
      \end{llproof}


      \proofcasederivation
        {S-Uni-Var}
        {\tv \disjoint \bvs \Cb}
        {\th \Cshape {\Ca\where{\cunif \tv {\cunif \t \ueq} \cand \Cb\where{-}}} \tv {~\shape \t}}

      \begin{llproof}
        \disjointPf{\tv}{\bvs \Cb}{Premise}
        \eqPf{\t}{\shapp[\shape \t] \tys}{For some $\tys$}
        \ForallPf{\semenv, \gt}{}{Defn. of $\Cshape \C \tv {~\shape \t}$}
        \vdashPf{\semenv}{\cerase{\Ca\where{\cunif \tv {\cunif {\shapp[\shape \t] \tys} \ueq} \cand \Cb\where{\cunif \tv \gt}}}}{Premise}
        \vdashPf{\semenva}{\cunif \tv {\cunif {\shapp[\shape \t] \tys} \ueq}}{Inversion of $\cerase \Ca$}
        \vdashPf{\semenvb}{\cunif \tv \gt}{Inversion of $\cerase \Cb$}
        \eqPf{\gt}{\semenvb(\tv)}{Simple inversion}
        \continueeqPf{\semenva(\tv)}{$\tv \disjoint \bvs \Cb$}
        \continueeqPf{\shapp[\shape \t] {\semenva(\tys)}}{Simple inversion}
  \Hand \eqPf{\shape \gt}{\shape \t}{Applying shape to both sides}
      \end{llproof}


      \proofcasederivation
        {S-Uni-BackProp}
        {\th \Cshape{\cletr \x \tv \tvs {\Ca\where{\ctrue}} {\Cb\where{\cpapp \x \tvp \tvc \inst \cand -}}} \tvc \sh \\
         \tvp \in \tv, \tvs \\
         \x \disjoint \bvs \Cb \\
         \tvp \disjoint \bvs \Ca}
        {\th \Cshape{\cletr \x \tv \tvs {\Ca\where{-}} {\Cb\where{\cpapp \x \tvp \tvc \inst}}} \tvp \sh}

        \begin{llproof}
          \inPf{\tvp}{\tv,\tvs}{Premise}
          \disjointPf{\x}{\bvs \Cb}{\ditto}
          \disjointPf{\tvp}{\bvs \Ca}{\ditto}
          \vdashPf{}{\Cshape{\cletr \x \tv \tvs {\Ca\where{\ctrue}} {\Cb\where{\cpapp \x \tvp \tvc \inst \cand -}}} \tvc \sh}{\ditto}
          \shapePf{\cletr \x \tv \tvs {\Ca\where{\ctrue}} {\Cb\where{\cpapp \x \tvp \tvc \inst \cand -}}}{\tvc}{\sh}{By \ih}
          \ForallPf{\semenv, \gt}{}{Defn. of $\Cshape \ldots \tv {~\shape \t}$}
          \vdashPf{\semenv}{\cerase{\cletr \x \tv \tvs {\Ca\where{\cunif \tvp \gt}} {\Cb\where{\cpapp \x \tvp \tvc \inst}}}}{Premise}
          \LetPf{\semenva}{\semenv[\x \is \semenv(\cabsr \tv \tvs {\cerase {\Ca\where{\cunif \tvp \gt}}})]}{}
          \eqPf{\semenvp(\tvp)}{\gt}{For any $\greg \tv \semenvp \in \semenva(\x)$}
          \vdashPf{\semenvb}{\cpapp \x \tvp \tvc \inst}{Inversion of $\cerase \Cb$}
          \eqPf{\semenvb(\inst^\x)(\tvp)}{\semenvb(\tvc)}{Simple inversion}
          \inPf{\semenvb(\inst^\x)}{\semenvb(\x)}{Since $\cexistsi \inst \x \in \Cb$, $\semenvb$ extends $\semenva$}
          \eqPf{\semenvb(\inst^\x)(\tvp)}{\gt}{Above}
          \continueeqPf{\semenvb(\tvc)}{\ditto}
          \vdashPf{\semenva}{\cerase {\Cb\where{\cpapp \x \tvp \tvc \inst \cand \cunif \tvc \gt}}}{Entailment for $\cerase \Cb$}
          \vdashPf{\semenv}{\cerase {\cletr \x \tv \tvs {\Ca\where{\cunif \tvp \gt}} {\Cb\where{\cpapp \x \tvp \tvc \inst \cand \cunif \tvc \gt}}}}{By \Rule{LetR}}
          \vdashPf{\semenv}{\cletr \x \tv \tvs {\Ca\where{\ctrue}} {\Cb\where{\cpapp \x \tvp \tvc \inst \cand \cunif \tvc \gt}}}{Simple congruence}
\Hand     \eqPf{\shape \gt}{\sh}{$\implies E$ on $\Cshape \ldots \tvc \sh$}
        \end{llproof}

    \end{proofcases}
  \end{proof}
\end{lemma}

\begin{lemma}
  \label{lem:unicity-completeness}

  If $\C$ is normalized, then $\Cshape \C \t \sh$ if and only $\th \Cshape \C \t \sh$.
  \begin{proof}~
    \begin{proofcases}

      \proofcase{$\implies$}
        \newcommand{\NC}{R}

        Let us assume $\Cshape \C \t \sh$ and $\C$ is normalized.

        Given $\C$ is normalized, every constraint in $\C$ is of the form: \\

        \begin{bnfgrammar}
          \entry[]{\NC}{
            \bar{\hat\ueq}
            \cand \overline{\cmatch \tv \cbrs}
            \cand \cexists {\overline{\inst^\x}} {\overline{\cpapp \x \tvb \tvc \inst}}
            \cand \overline{\cletr \x \tvd \tvds {\NC_1} {\NC_2}}
          }
        \end{bnfgrammar}
        \\

        By assumptions, we have $\all {\phi, \gt} {\phi \th \cerase
        \C\where{\cunif \tv \gt}} \implies \shape \gt = \sh$. Hence $\cerase
        \C$ contains $\cerase \NC$ where: \\

        \begin{bnfgrammar}
          \entry[]{\cerase \NC}{
            \bar{\hat\ueq}
            \cand \cexists {\overline{\inst^\x}} {\overline{\cpapp \x \tvb \tvc \inst}}
            \cand \overline{\cletr \x \tvd \tvds {\cerase {\NC_1}} {\cerase {\NC_2}}}
          }
        \end{bnfgrammar}
        \\

        \Wlog all constraints that may determine the shape of $\tv$ are located
        with the regional binder (following the \Rule{S-Lower-Exists} and
        \Rule{S-Let-ConjLeft} rules). There are two cases:

        \begin{proofcases}

          \proofcase{$\cunif \tv {\cunif \t \ueq} \in \bar{\hat\ueq}$} Apply \Rule{S-Uni-Var}.


          \proofcase{Otherwise}

            Since $\C$ is normalized, it must be that case that no equality
            constraint determines the shape of $\tv$. Since any such equality
            would normalize to $\cunif \tv {\cunif \t \ueq}$, contradicting our
            assumption that $\C$ is normalized.

            By elimination on the structure of $\NC$, the only constraints that
            could determine the shape of $\tv$ are partial instantiation
            constraints that copy $\tv$. So there exists a partial
            instantiation constraint $\cpapp \x \tv \tvc \inst$ such that $\Cp
            \where{\cpapp \x \tv \tvc \inst} = \C\where{\ctrue}$ and $\Cshape
            \Cp \tvc \sh$.

            By induction, we have $\th \Cshape \Cp \tvc \sh$. From
            \Rule{S-Uni-BackProp}, we have $\th \Cshape \C \tv \sh$.


        \end{proofcases}

      \proofcase{$\impliedby$} Follows from \cref{lem:unicity-soundness}.

    \end{proofcases}

  \end{proof}
\end{lemma}

\begin{lemma}[Unification preservation]
  \label{lem:unification-preservation}
  If $\upa \unif \upb$, then $\upa \equiv \upb$
  \begin{proof}
    By induction on the given derivation $\upa \unif \upb$.
    See \citet*{Pottier-Remy/emlti} for more details.
  \end{proof}
\end{lemma}

\preservation
\newcommand{\unifPf}[3]{\Pf{#1}{\unif}{#2}{#3}}
\newcommand{\equivctxPf}[3]{\Pf{#1}{\cequivctx}{#2}{#3}}
\newcommand{\ctxequivPf}[3]{\Pf{#1}{\cctxequiv}{#2}{#3}}
\begin{proof}
  We proceed by induction on the given derivation.
  It suffices to show that for each individual rule $R$ ($\ca \csolve_R \cb$),
  that $\ca \cequivctx \cb$.

  \begin{proofcases}
    \proofcaserewrite
      {S-Unif}
      {\upa \\ \upa \unif \upb}
      {\upb}

	\begin{llproof}
	  \unifPf{\upa}{\upb}{Premise}
	  \equivPf{\upa}{\upb}{\cref{lem:unification-preservation}}
	  \simplePf{\upa, \upb}{\cref{lem:unif-problem-simple}}
\Hand 	  \equivctxPf{\upa}{\upb}{\cref{lem:ctxt-equiv-simple}}
	\end{llproof}

    \proofcaserewrite
      {S-Exists-Conj}
      {\parens {\cexists \tv \ca} \cand \cb \\ \tv \disjoint \cb}
      {\cexists \tv \ca \cand \cb}

	\begin{llproof}
	  \disjointPf{\tv}{\cb}{Premise}
	  \decolumnizePf
	  \sufficientPf{equivalence for simple constraints}{}{\cref{lem:simple-ctxt-equiv}}
	  \supposePf{\ca, \cb \simple} {Premise}
	\end{llproof}
	\begin{proofcases}
	  \proofcase{$\implies$}

	  \begin{llproof}
	    \ForallPf{\semenv}{}{}
	    \vdashPf{\semenv}{\parens {\cexists \tv \ca} \cand \cb}{Premise}
	    \vdashPf{\semenv\where{\tv \is \gt}}{\ca}{Simple inversion}
	    \vdashPf{\semenv}{\cb}{Simple inversion}
	    \vdashPf{\semenv\where{\tv \is \gt}}{\cb}{$\tv \disjoint \cb$}
	    \vdashPf{\semenv\where{\tv \is \gt}}{\ca \cand \cb}{By \Rule{Conj}}
\Hand       \vdashPf{\semenv}{\cexists \tv \ca \cand \cb}{By \Rule{Exists}}
	  \end{llproof}
	  \proofcase{$\impliedby$}

	    \begin{llproof}
	    Symmetric argument.
	    \end{llproof}
	\end{proofcases}


      \proofcase{\Rule{S-Let}, \Rule{S-True}, \Rule{S-False},
      \Rule{S-Let-ExistsLeft},
      \Rule{S-Let-Exists-InstLeft}, \Rule{S-Let-ExistsRight},
      \Rule{S-Let-Exists-InstRight}, \Rule{S-Let-ConjLeft},
      \Rule{S-Let-ConjRight}, \Rule{S-Inst-Name}, \Rule{S-Exists-Exists-Inst},
      \Rule{S-Exists-Inst-Conj}, \Rule{S-Exists-Inst-Let}, \Rule{S-Exists-Inst-Solve},
      \Rule{S-All-Conj}}

      \begin{llproof}
	Similar argument to the \Rule{S-Exists-Conj} case.
      \end{llproof}

    \proofcaserewrite
      {S-Match-Ctx}
      {\C\where{\cmatch \t \cbrs} \\ \th \Cshape \C \t \sh}
      {\C\where{\cmatched \t \sh \cbrs}}

	\begin{llproof}
    \vdashPf{}{\Cshape \C \t \sh}{Premise}
	  \shapePf{\C}{\t}{\sh}{\cref{lem:unicity-soundness}}
	  \sufficientPf{equivalences between constraints}{}{\cref{lem:compose-unicity}}
	\end{llproof}

	\begin{proofcases}
	  \proofcase{$\implies$}

	  \begin{llproof}
	    \ForallPf{\semenv}{}{}
	    \vdashPf{\semenv}{\C\where{\cmatch \tv \cbrs}}{Premise}
\Hand 	    \vdashPf{\semenv}{\C\where{\cmatched \tv {\shape \t} \cbrs}}{\cref{lem:susp-inversion}}
	  \end{llproof}

	  \proofcase{$\impliedby$}

	  \begin{llproof}
	    \ForallPf{\semenv}{}{}
	    \vdashPf{\semenv}{\C\where{\cmatched \tv {\shape \t} \cbrs}}{Premise}
\Hand 	    \vdashPf{\semenv}{\C\where{\cmatch \tv \cbrs}}{By \Rule{Match-Ctx}}
	  \end{llproof}
	\end{proofcases}


    \proofcaserewrite
      {S-Let-AppR}
      {\cletr \x \tv \tvs \ca {\C\where{\capp \x \t}} \\ \tvc \disjoint \t \\ \x \disjoint \bvs \C}
      {\cletr \x \tv \tvs \ca {\C\where{\cexistsi {\tvc, \inst} \x \cunif \tvc \t \cand \cpinst \inst \tv \tvc }}}


	\begin{llproof}
	  \disjointPf{\tvc}{\t}{Premise}
	  \disjointPf{\x}{\bvs \C}{Premise}
	  \decolumnizePf
	  \sufficientPf{equivalence between}{\capp \x \t \text{ and } \cexistsi {\tvc, \inst} \x \cunif \tvc \t \cand \cpinst \inst \tv \tvc}{\cref{lem:simple-let-equiv}}
	  \supposePf{\semenvp(\x) = \semenv(\cabsr \tv \tvs \ca)}{Premise}
	\end{llproof}
	\begin{proofcases}
	  \proofcase{$\implies$}

	    \begin{llproof}
	      \vdashPf{\semenvp}{\capp \x \t}{Premise}
	      \inPf{\greg \tv {\semenva}}{\semenv(\x)}{Simple inversion}
	      \eqPf{\semenva(\tv)}{\semenvp(\t)}{\ditto}
	      \vdashPf{\semenvp\where{\tvc \is \semenvp(\t), \inst \is \semenva}}{\cpinst \inst \tv \tvc}{By \Rule{Partial-Inst}}
	      \vdashPf{\semenvp\where{\tvc \is \semenvp(\t), \inst \is \semenva}}{\cunif \tvc \t}{By \Rule{Unif}}
\Hand	      \vdashPf{\semenvp}{\cexistsi {\tvc, \inst} \x {\cunif \tvc \t \cand \cpinst \inst \tv \tvc}}{By \Rule{Exists}, \Rule{Exists-Inst} and \Rule{Conj}}
	    \end{llproof}

	  \proofcase{$\impliedby$}

	    \begin{llproof}
	      Symmetric argument.
	    \end{llproof}
	\end{proofcases}

    \proofcaserewrite
      {S-Inst-Copy}
      {\cletr \x \tv \tvs {\c}
	\C\where{\cpapp \x \tvp \tvc \inst}\\
	\c = \cp \cand \cunif \tvp {\cunif {\shapp \tvbs} \ueq}\\
	\tvp \in \reg \tv \tvs \\
	\neg \cyclic {\c} \\
	\tvbs' \disjoint \tvp, \tvc, \tvbs \\
       \x \disjoint \bvs \C}
      {\cletr \x \tv \tvs {\c}
	\C\where{\cexists {\tvbs'} \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}}


	\begin{llproof}
	  \disjointPf{\x}{\bvs \C}{Premise}
	  \disjointPf{\tvbs'}{\tvp, \tvc, \tvbs}{Premise}
	  \decolumnizePf
	  \sufficientPf{equivalence between}{\cpapp \x \tvp \tvc \inst \text{ and } \cexists {\tvbs'} \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}{\cref{lem:simple-let-equiv}}
	  \supposePf{\semenvp(\x) = \semenv(\cabsr \tv {\tvs} \c)}{Premise}
	\end{llproof}
	\begin{proofcases}
	  \proofcase{$\implies$}

	    \begin{llproof}
	      \vdashPf{\semenvp} {\cpapp \x \tvp \tvc \inst}{Premise}
	      \inPf{\greg \tv \semenva}{\semenv(\x)}{$\cexistsi \inst \x \in \C$}
	      \eqPf{\semenvp(\inst)}{\semenva}{\ditto}
	      \eqPf{\semenvp(\tvc)}{\semenv(\inst)(\tvp)}{Simple inversion}
	      \continueeqPf{\semenva(\tvp)}{Above}
	      \vdashPf{\semenva}{\cp \cand \cunif \tvp {\cunif {\shapp \tvbs} \ueq}}{Above}
	      \vdashPf{\semenva}{\cunif \tvp {\cunif {\shapp \tvbs} \ueq}}{Simple inversion}
	      \eqPf{\semenva(\tvp)}{\shapp {\semenva(\tvbs)}}{\ditto}
	      \eqPf{\semenvp(\tvc)}{\shapp {\semenva(\tvbs)}}{Above}
	      \vdashPf{\semenvp\where{\tvbs' \is \semenva(\tvbs)}}{\cunif \tvc {\shapp {\tvbs'}}}{By \Rule{Unif}}
	      \vdashPf{\semenvp\where{\tvbs' \is \semenva(\tvbs)}}{\cpapp \x \tvbs {\tvbs'} \inst}{By \Rule{Partial-Inst}}
\Hand 	      \vdashPf{\semenvp}{\cexists {\tvbs'} \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}{By \Rule{Exists} and \Rule{Conj}}
	    \end{llproof}

	  \proofcase{$\impliedby$}

	    \begin{llproof}
	      Symmetric argument.
	    \end{llproof}
	\end{proofcases}

    \proofcaserewrite
      {S-Inst-Unif}
      {\cpinst \inst \tv \tvca \cand \cpinst \inst \tv \tvcb}
      {\cpinst \inst \tv \tvca \cand \cunif \tvca \tvcb}

      \begin{llproof}

	\sufficientPf{equivalence between}{{\cpinst \inst \tv \tvca \cand
	\cpinst \inst \tv \tvcb} \text{ and } {\cpinst \inst \tv \tvca \cand
	\cunif \tvca \tvcb} }{\cref{lem:simple-ctxt-equiv}}

      \end{llproof}

      \begin{proofcases}
	\proofcase{$\implies$}

	  \begin{llproof}
	    \vdashPf{\semenv}{\cpinst \inst \tv \tvca \cand \cpinst \inst \tv \tvcb}{Premise}
	    \vdashPf{\semenv}{\cpinst \inst \tv \tvca}{Simple inversion}
	    \vdashPf{\semenv}{\cpinst \inst \tv \tvcb}{\ditto}
	    \eqPf{\semenv(\tvca)}{\semenv(\inst)(\tv)}{\ditto}
	    \eqPf{\semenv(\tvcb)}{\semenv(\inst)(\tv)}{\ditto}
	    \eqPf{\semenv(\tvca)}{\semenv(\tvcb)}{Above}
	    \vdashPf{\semenv}{\cunif \tvca \tvcb}{By \Rule{Unif}}
\Hand	    \vdashPf{\semenv}{\cpinst \inst \tv \tvca \cand \cunif \tvca \tvcb}{By \Rule{Conj}}
	  \end{llproof}

	\proofcase{$\impliedby$}

	  \begin{llproof}
	    Symmetric argument.
	  \end{llproof}
      \end{proofcases}

    \proofcaserewrite
      {S-Inst-Poly}
      {\cletr \x \tv {\tvs} {\ueqs \cand \c} {\C\where{\cpapp \x \tvp \tvc \inst}} \\
       \cfor \tvp \cexists {\tv, \tvs} {\ueqs} \cequiv \ctrue \\
       \tvp \in \reg \tv \tvs \\
       \tvp \disjoint \c \\
       \inst.\tvp \disjoint \insts \C \\
       \x \disjoint \bvs \C}
      {\cletr \x \tv {\tvs} {\ueqs \cand \c} {\C\where\ctrue}}


	\begin{llproof}
	  \equivPf{\cfor \tvp \cexists {\tv, \tvs} \ueqs}{\ctrue}{Premise}
	  \disjointPf{\tvp}{\c}{Premise}
	  \disjointPf{\inst.\tvp}{\insts \C}{Premise}
	  \disjointPf{\x}{\bvs \C}{Premise}
	  \decolumnizePf
	  \sufficientPf{equivalence between}
	    {\cpapp \x \tvp \tvc \inst \text{ and } \ctrue}
	    {\cref{lem:simple-let-equiv}}
	  \supposePf{\semenvp(\x) = \semenv(\cabsr \tv {\tvs, \tvp} \ueqs \cand \c)}{Premise}
	\end{llproof}
	\begin{proofcases}
	  \proofcase{$\implies$}

	    \begin{llproof}
	      \vdashPf{\semenvp}{\cpapp \x \tvp \tvc \inst}{Premise}
\Hand	      \vdashPf{\semenvp}{\ctrue}{By \Rule{True}}
	    \end{llproof}

	  \proofcase{$\impliedby$}

	    \begin{llproof}
	      \vdashPf{\semenvp}{\ctrue}{Premise}
	      \inPf{\greg \tv {\semenva}}{\semenvp(\x)}{$\C = \Ca\where{\cexistsi \inst \x \Cb}$}
	      \eqPf{\semenvp(\inst)}{\semenva}{\ditto}
	      \casesPf{\semenva(\tvp)}
	    \end{llproof}
	    \begin{proofcases}
	      \proofcase{$\semenva(\tvp) = \semenvp(\tvc)$}

		\begin{llproof}
		  \eqPf{\semenva(\tvp)}{\semenvp(\tvc)}{Premise}
\Hand		  \vdashPf{\semenvp}{\cpapp \x \tvp \tvc \inst}{By \Rule{Partial-Inst}}
		\end{llproof}


	      \proofcase{$\semenva(\tvp) \neq \semenvp(\tvc)$}

		\begin{llproof}
		  \LetPf{\semenvb}{\semenva\where{\tvp \is \semenvp(\tvc)}}{}
		  \vdashPf{\semenva}{\ueqs \cand \c}{By definition}
		  \vdashPf{\semenva}{\ueqs}{Simple inversion}
		  \vdashPf{\semenvb}{\ueqs}{$\tvp$ is polymorphic}
		  \vdashPf{\semenvb}{\c}{$\tvp \disjoint \c$}
		  \vdashPf{\semenvb}{\ueqs \cand \c}{By \Rule{Conj}}
		  \inPf{\greg \tv \semenvb}{\semenv(\x)}{By definition}
		  \supposePf{\semenvc \th \Cb\where\ctrue}{Considering entailment on $\cexistsi \inst \x$}
		  \eqPf{\semenvc(\inst)}{\semenva}{\ditto}
		  \vdashPf{\semenvc\where{\inst \is \semenvb}}{\Cb\where\ctrue}{$\inst.\tvp \disjoint \insts \Cb$}
		  \vdashPf{\deriv :: \semenvc}{\Cb\where\ctrue}{By \Rule{Exists-Inst}}
		  \commentPf{$\deriv$ is a derivation that satisfies $\semenva(\tvp) = \semenvp(\tvc)$.}{}
\Hand		  \commentPf{So this case degenerates to the former case.}{}
		\end{llproof}
	    \end{proofcases}
	\end{proofcases}

    \proofcaserewrite
      {S-Inst-Mono}
      {\cletr \x \tv \tvs \c {\C\where{\cpapp \x \tvb \tvc \inst}} \\
       \tvb \notin \reg \tv \tvs \\
       \x, \tvb \disjoint \bvs \C}
      {\cletr \x \tv \tvs \c {\C\where{\cunif \tvb \tvc}}}

	\begin{llproof}
	  \disjointPf{\tvb}{\tv, \tvs}{Premise}
	  \disjointPf{\x, \tvb}{\bvs \C}{Premise}
	  \decolumnizePf
	  \sufficientPf{equivalence between}
	    {\cpapp \x \tvb \tvc \inst \text{ and } \cunif \tvb \tvc}
	    {\cref{lem:simple-let-equiv}}
	  \supposePf{\semenvp(\x) = \semenv(\cabsr \tv {\tvs} \c)}{Premise}
	\end{llproof}

	\begin{proofcases}
	  \proofcase{$\implies$}

	  \begin{llproof}
	    \vdashPf{\semenvp}{\cpapp \x \tvb \tvc \inst}{Premise}
	    \inPf{\greg \tv \semenva}{\semenv(\c)}{$\cexistsi \inst \x \in \C$}
	    \eqPf{\semenvp(\inst)}{\semenva}{\ditto}
	    \eqPf{\semenvp(\tvc)}{\semenva(\tvb)}{Simple inversion}
	    \eqPf{\semenva(\tvb)}{\semenv(\tvb)}{$\tvb \disjoint \tv, \tvs$}
	    \eqPf{\semenvp(\tvb)}{\semenv(\tvb)}{$\tvb \disjoint \bvs \C$}
	    \eqPf{\semenvp(\tvc)}{\semenvp(\tvb)}{Above}
	    \vdashPf{\semenvp}{\cunif \tvc \tvb}{By \Rule{Unif}}
	  \end{llproof}

	  \proofcase{$\impliedby$}

	  \begin{llproof}
	    Symmetric argument.
	  \end{llproof}
	\end{proofcases}


    \proofcaserewrite
      {S-Let-Solve}
      {\cletr \x \tv \tvs \ueqs \c \\ \x \disjoint \c \\
       \cexists {\tv, \tvs} \ueqs \cequiv \ctrue}
      {\c}
	\begin{llproof}
	  \disjointPf{\x}{\c}{Premise}
	  \equivPf{\cexists {\tv, \tvs} \ueqs}{\ctrue}{}
	  \decolumnizePf
	  \sufficientPf{equivalence for simple constraints}{}{\cref{lem:simple-ctxt-equiv}}
	  \supposePf{\c \simple} {Premise}
	\end{llproof}
	\begin{proofcases}
	  \proofcase{$\implies$}

	  \begin{llproof}
	    \ForallPf{\semenv}{}{}
	    \vdashPf{\semenv}{\cletr \x \tv \tvs \ueqs \c}{Premise}
	    \vdashPf{\semenv}{\cexists {\tv, \tvs} \ueqs}{Simple inversion}
	    \vdashPf{\semenv\where{\x \is \semenv(\cabsr \tv \tvs \ueqs)}}{\c}{\ditto}
\Hand	    \vdashPf{\semenv}{\c}{$\x \disjoint \c$}
	  \end{llproof}
	  \proofcase{$\impliedby$}

	    \begin{llproof}
	    \ForallPf{\semenv}{}{}
	    \vdashPf{\semenv}{\c}{Premise}
	    \vdashPf{\semenv\where{\x \is \semenv(\cabsr \tv \tvs \ueqs)}}{\c}{$\x \disjoint \c$}
	    \vdashPf{\semenv}{\cexists {\tv, \tvs} \ueqs}{}
\Hand	    \vdashPf{\semenv}{\cletr \x \tv \tvs \ueqs \c}{By \Rule{LetR}}
	    \end{llproof}
	\end{proofcases}

  \proofcaserewrite{S-Exists-Lower}
    {\cletr \x \tv {\tvas, \tvbs} \ca \cb \\
     \cdetermines {\cexists {\tv, \tvas} \ca} \tvbs \\
     }
    {\cexists \tvbs \cletr \x \tv \tvas \ca \cb}

    \begin{llproof}
      \Pf{}{}{\cdetermines {\cexists {\tv, \tvas} \ca} \tvbs}{Premise}
      \sufficientPf{equivalence for simple constraints}{}{\cref{lem:simple-ctxt-equiv} and \cref{lem:determines-is-match-closed}}
      \supposePf{\ca, \cb \simple}{Premise}
    \end{llproof}
    \begin{proofcases}
      \proofcase{$\implies$}

      \begin{llproof}
	\vdashPf{\semenv}{\cletr \x \tv {\tvas, \tvbs} \ca \cb}{Premise}
	\vdashPf{\semenv}{\cexists {\tv, \tvas, \tvbs} \ca}{Simple inversion}
	\vdashPf{\semenv\where{\x \is \semenv(\cabsr \tv {\tvs, \tvbs} \ca)}}{\cb}{\ditto}
	\vdashPf{\semenv\where{\tv \is \gt, \tvas \is \gts, \tvbs \is \bar\gtp}}{\ca}{\ditto}
	\vdashPf{\semenv\where{\tvbs \is \bar\gtp}}{\cexists {\tv, \tvas} \ca}{By \Rule{Exists}}
	\sufficientPf{}{\semenv\where{\x \is \semenv(\cabsr \tv {\tvs, \tvbs} \ca)} = \semenv\where{\tvbs \is \bar\gt'}(\cabsr \tv \tvs \ca)}{}
      \end{llproof}
      \begin{proofcases}

      \proofcase{$\implies$}

	\begin{llproof}
	  \vdashPf{\semenv\where{\tv \is \gta, \tvs \is \bar\gta, \tvbs \is \bar\gtb}}{\ca}{Premise}
	  \vdashPf{\semenv\where{\tvbs \is \bar\gtb}}{\cexists {\tv, \tvs} \ca}{By \Rule{Exists}}
	  \eqPf{\bar\gtb}{\bar\gtp}{By definition of determines}
\Hand	  \vdashPf{\semenv\where{\tvbs \is \bar\gtp, \tv \is \gta, \tvs \is \bar\gta}}{\ca}{Above}

	\end{llproof}

      \proofcase{$\impliedby$}

      \begin{llproof}
	Symmetric argument.
      \end{llproof}


      \end{proofcases}



      \proofcase{$\impliedby$}

      \begin{llproof}
	Symmetric argument.
      \end{llproof}

    \end{proofcases}

  \proofcase{\Rule{S-Compress}, \Rule{S-Gc}, \Rule{S-Exists-All}, \Rule{S-All-Escape}, \Rule{S-All-Rigid}, \Rule{S-All-Solve}}

  \begin{llproof}
    Similar argument. Use \cref{lem:simple-ctxt-equiv}.
    The simple equivalences are standard, see \citet*{Pottier-Remy/emlti}.
  \end{llproof}
  \end{proofcases}
\end{proof}

\subsection{Progress}

\begin{lemma}[Unification progress]
  If unification problem $\up$ cannot take a step $\up \unif \upp$, then either:
  \begin{enumerate}[(\roman*)]
    \item $\up$ is solved.
    \item $\up$ is $\cfalse$.
    \end{enumerate}
  \begin{proof}
    This is a standard result. See \citet*{Pottier-Remy/emlti}.
  \end{proof}
\end{lemma}


\progress
\begin{proof}
  We proceed by induction on the structure of $\c$. We
  focus on suspended match constraints, conjunctions, and $\Let$ rules.
  \begin{proofcases}
    \proofcase{$\cmatch \t \cbrs$}
      We have two cases:
      \begin{proofcases}
  \proofcase{$\t$ is a non-variable type} Apply \Rule{S-Match-Ctx} using \Rule{S-Uni-Type}
	\proofcase{$\t$ is a type variable $\tv$}

	  We have $\nCshape \square \tv$. It suffices
	  that every match constraint in a context-reachable position
	  $\hat\C\where{\cmatch \tvp \cbrs}$ satisfies $\nCshape {\hat\C} \tvp$.
	  By the definition of constraint contexts, there is only one such
	  $\hat\C$, namely $\square$, for which we already have $\nCshape \square \tv$.
	  Hence $\cmatch \t \cbrs$ is stuck.
      \end{proofcases}

    \proofcase{$\ca \cand \cb$}
    We begin by inducting on $\ca$ and $\cb$. Then we consider cases:
    \begin{proofcases}
      \proofcase{$\ca$ (or $\cb$) take a step} Apply congruence rewriting rule.
      \proofcase{$\ca$ (or $\cb$) is $\ctrue$} Apply \Rule{S-True}.
      \proofcase{$\ca$ (or $\cb$) is $\cfalse$} Apply \Rule{S-False}.
      \proofcase{$\ca$ (or $\cb$) begins with $\exists$} Apply \Rule{S-Exists-Conj}.
      \proofcase{$\ca, \cb$ are solved}

	We either apply the above $\exists$ case, or both $\ca$ and $\cb$ are solved
	multi-equations $\ueqs_1, \ueqs_2$. We perform cases on this:
	\begin{proofcases}
	  \proofcase{$\ueqs_1$ and $\ueqs_2$ are mergable} Apply \Rule{U-Merge}.
	  \proofcase{$\cyclic {\ueqs_1, \ueqs_2}$} Apply \Rule{U-Cycle}.
	  \proofcase{Otherwise} The conjunction $\ueqs_1 \cand \ueqs_2$ is solved.
	\end{proofcases}

      \proofcase{$\ca$ and $\cb$ are stuck (and not $\cfalse$)}

	\Wlog, consider cases $\ca$.
	\begin{proofcases}
	  \proofcase{$\hat\Ca\where{\capp \x \t}$}
	    We have $\x \disjoint \bvs {\hat\Ca}$.

	    $\hat\Ca\where{\capp \x \t} \cand \cb$ is stuck as we do not bind $\x$ in $\hat\Ca \cand \cb$.
	  \proofcase{$\hat\Ca\where{\cpapp \x \tv \tvc \inst}$}
	    We have $\x \disjoint \bvs {\hat \Ca}$ and $\inst.\tv \disjoint \insts {\hat \Ca}$.

	    If $\inst.\tv \in \insts \cb$ and $\inst \disjoint \bvs {\hat\ca}$, then apply \Rule{S-Inst-Unify}.
	    It must be the case that we can apply \Rule{S-Inst-Unify}, otherwise, we could lift these instantiation
	    constraints using \Rule{S-Exists-Lower} and \Rule{S-Let-ConjLeft}, contradicting that $\hat\Ca$ is stuck.

	    Otherwise, $\x \disjoint \bvs {\hat \Ca \cand \cb}$, thus $\hat\Ca\where{\cpapp \x \tv \tvc \inst}$ is stuck.

	  \proofcase{$\hat\Ca\where{\cmatch \tvp \cbrs}$}
	    We have $\nCshape \Ca \tvp$.

	    Consider a match constraint $\cmatch \tvp \cbrs$ in $\ca$.

      If $\th \Cshape {\where{\hat\Ca\where{-} \cand \cb}} \tvp \sh$. Then we can apply \Rule{S-Match-Ctx}.

      Otherwise $\not \th \Cshape {\where{\hat\Ca\where{-} \cand \cb}} \tvp \sh$. We have \cref{lem:unicity-completeness},
      so we are stuck and $\nCshape {(\Ca \cand \cb)} \tvp$.
	\end{proofcases}

    \end{proofcases}

    \proofcase{$\cletr \x \tv \tvs \ca \cb$}
    We begin by inducting on $\ca$ and $\cb$. Then we consider cases:
    \begin{proofcases}
      \proofcase{$\ca$ (or $\cb$) take a step} Apply congruence rewriting rule.
      \proofcase{$\ca$ (or $\cb$) is $\cfalse$} Apply \Rule{S-False}.
      \proofcase{$\ca$ begins with $\exists$} Apply \Rule{S-Let-ExistsLeft}
      \proofcase{$\cb$ begins with $\exists$} Apply \Rule{S-Let-ExistsRight}
      \proofcase{$\cb$ begins with $\cand$ with $\x \disjoint$ from conjunct} Apply \Rule{S-Let-ConjRight}.
      \proofcase{$\ca$ begins with $\cand$ with $\tv, \tvs \disjoint$ from conjunct } Try apply \Rule{S-Let-ConjLeft}
      \proofcase{$\cb$ begins with $\cexistsi \inst \xp {}$, $\x \neq \xp$} Apply \Rule{S-Exists-Inst-Let}
      \proofcase{$\tvp \in \tvs$ is determined by $\ca$} Apply \Rule{S-Exists-Lower}
      \proofcase{$\cb$ is solved}

	Thus $\cb$ must be $\ctrue$ (due to above cases).
	\begin{proofcases}
	  \proofcase{$\ca$ is solved}
	    Thus $\ca$ must be $\ueqs$.

	    There are two cases:
	    \begin{itemize}
	      \proofcase{$\cexists {\tv, \tvs} \ueqs \cequiv \ctrue$} Apply \Rule{S-Let-Solve}.
	      \proofcase{$\cexists {\tv, \tvs} \ueqs \cnequiv \ctrue$} It must be the case there is some $\tvb$ that dominates a $\tvp$ in $\tv, \tvs$ in $\ueqs$.
		Hence $\cdetermines {\cexists {\tv, \tvs \setminus \tvp} \ueqs} \tvp$.
		So we can apply \Rule{S-Exists-Lower}.
	    \end{itemize}

	  \proofcase{$\ca$ is stuck}

	    The constraint $\cletr \x \tv \tvs \ca \cb$ remains stuck, since
	    no additional term variable bindings occur for the scope of $\ca$,
	    ruling out the instantiation cases. Additionally, we cannot apply
	    backpropagation since $\cb$ is $\ctrue$.
	\end{proofcases}

      \proofcase{$\cb$ is stuck}
	\begin{proofcases}
	  \proofcase{$\hat\C\where{\capp \x \t}$} We have $\x \disjoint \bvs {\hat\C}$.

	  Apply \Rule{S-Let-AppR}.

	  \proofcase{$\hat\C\where{\cpapp \x \tvp \tvc \inst}$} We have $\x \disjoint \bvs {\hat\C}$ or $\inst.\tvp \disjoint \insts {\hat\C}$.
	    \begin{itemize}
		\proofcase{$\tvp \in \reg \tv \tvs$}

		We can either apply \Rule{S-Inst-Copy} or \Rule{S-Compress}
		if a multi-equation involving $\tvp$ occurs in $\ca$.

		Otherwise, we consider cases where $\ca$ is solved or stuck.

		If $\ca$ is solved, then it must be of the form $\ueqs$.
		There are two cases:
		\begin{itemize}
		  \proofcase{$\cexists {\tv, \tvs} \ueqs \cequiv \ctrue$}
		  As $\tvp$ does not appear in the head position of any multi-equation in $\ueqs$,
		  it must be polymorphic. Thus $\cfor \tvp {\cexists {\tv, \tvs \setminus \tvp} \ueqs} \cequiv \ctrue$.
		  So we can apply \Rule{S-Inst-Poly}.

		  \proofcase{$\cexists {\tv, \tvs} \ueqs \cnequiv \ctrue$}
		  Apply \Rule{S-Lower-Exists} (using the same logic as above).

		\end{itemize}

		If $\ca$ is stuck, then neither stuck case regarding instantiations
		in $\ca$ is fixed, so in these cases the constraint remains
		stuck. If $\ca$ is stuck with $\hat\Cp\where{\cmatch \tvb
    \cbrs'}$. Then either backpropagation (via \Rule{S-Uni-BackProp} and \Rule{S-Match-Ctx})
		applies with an equation in $\hat\C$, or the entire constraint
    is stuck (by \cref{lem:unicity-completeness}).

		\proofcase{$\tvp \notin \reg \tv \tvs$} Apply \Rule{S-Inst-Mono}.




	    \end{itemize}

	  \proofcase{For any $\hat\C\where{\cmatch \tvp \cbrs}$} We have $\nCshape {\hat\C} \tvp$.

	  Either $\cletr \x \tv \tvs \ca \cb$ can progress with an instantiation constraint (in the above case) to discharge
	  the match constraint or $\cletr \x \tv \tvs \ca \cb$ is stuck.
	\end{proofcases}

    \end{proofcases}


  \end{proofcases}
\end{proof}

\subsection{Termination}

This section presents a proof of termination for our solver.
%
Most rewrite rules, in both unification and constraint solving, are
\emph{destructive}---that is, they eliminate or modify the structure of a
constraint in a way that prevents the rule from begin applied again.
%
Consequently, to establish termination, it suffices to consider only those
rules that are not inherently destructive.

\begin{lemma}[Unification termination]
  \label{lem:unification-termination}
  The unifier terminates on all inputs.
  \begin{proof}
    \newcommand{\sw}[1]{\mathprefix{sw}{(#1)}}
    \newcommand{\iw}[1]{\mathprefix{iw}{(#1)}}
    \newcommand{\tw}[1]{\mathprefix{tw}{(#1)}}
    \newcommand{\uw}[1]{\mathprefix{uw}{(#1)}}

    Let every shape $\sh$ have an integer \emph{weight}
    defined by $\sw \sh \eqdef 4 + 2 \times |\sh|$, where $|\sh|$ is the
    arity of the shape $\sh$.
    %
    The weight of a type $\tw \t$ is defined by:
    \begin{mathpar}
      \begin{tabular}{RCL}
	\tw \tv &\eqdef& 1\\
	\tw {\shapp \tys} &\eqdef& \iw {\shapp \tys} - 2\\[1ex]
	\iw \tv &\eqdef& 0\\
	\iw {\shapp \tys} &\eqdef& \sw \sh + \iw \tys\\
        \iw \tys & \eqdef & \sum\iton \iw \ti\\

      \end{tabular}
    \end{mathpar}
    The helper $\iw \t$ computes the ``internal'' weight of $\t$; in
    the common case of shallow types it is just the weight of its head
    shape.

    We define the weight of a multi-equation as the sum of the weights of its
    members. The weight of a unification problem $\uw \up$ is defined
    as the sum of the weights of its multi-equations.

    In $\up \unif \upp$, the rules \Rule{U-Decomp} and \Rule{U-Name} are not
    obviously destructive, as they may introduce new constraints that
    are structurally larger than the constraint being rewritten.

    However, we show that this is not problematic: in both cases, the unification
    weight $\uw \up$ strictly decreases. The remaining rules are obviously
    destructive and either maintain or decrease the unification weight.

    \begin{proofcases}
      \proofcaserewrite
	{U-Decomp}
	{\cunif {\pshapp \tvs} {\cunif {\pshapp \tvbs} \ueq}}
	{\cunif {\pshapp \tvs} \ueq \cand \cunif \tvs \tvbs}

	We have:
	\begin{mathpar}
	  \begin{tabular}{RRCL}
           (+)&
	    \uw {\cunif {\pshapp \tvs} {\cunif {\pshapp \tvbs} \ueq}} &=&
	      \tw {\pshapp \tvs} + \tw {\pshapp \tvbs}  + \tw \ueq \\
           (-)&
	    \uw {\cunif {\pshapp \tvs} \ueq \cand \cunif \tvs \tvbs}
	      &=&
	      \tw {\pshapp \tvs} + \tw \ueq + \tw \tvs + \tw \tvbs \Strut \\
              \hline
	       &&=&\Strut \tw {\pshapp \tvbs} - \tw \tvs - \tw \tvbs \\
               &&=&  (\sw \sh  + 0 - 2) - 2 |\sh| \\
               &&=&  (2 + 2|\sh|) - 2 |\sh| \Wide = \textbf {2}\\
	  \end{tabular}
	\end{mathpar}
	Hence $\uw {{\cunif {\pshapp \tvs} {\cunif {\pshapp \tvbs} \ueq}}} > \uw {\cunif {\pshapp \tvs} \ueq \cand \cunif \tvs \tvbs}$.


      \proofcaserewrite
	{U-Name}
      {\cunif {\pshapp \parens{\tys, \ti, \typs}} \ueq \\ \tv \disjoint \tys, \typs, \ueq \\ \ti \notin \TyVars }
      {\cexists \tv {\cunif {\pshapp \parens{\tys, \tv, \typs}} \ueq \cand \cunif \tv \ti}}

	Given $\ti \notin \TyVars$, by \cref{thm:principal-shapes},
	$\ti = \shapp[\shp] \bar\typp$ for some shape $\shp$ and types $\bar\typp$.
	So we have:
	\begin{mathpar}
	  \begin{tabular}{.R;;R;C;L.}
          (+) &
	    \uw {\cunif {\pshapp {\parens{\tys, \ti, \typs}}} \ueq}
            &=& \sw \sh + \iw \tys + \iw \ti + \iw \typs - 2 + \uw \ueq \\
          (-) &
	    \uw {\cexists \tv {\cunif \tv \ti \cand \cunif {\pshapp \parens{\tys, \tv, \typs}} \ueq}}
            &=& \sw \sh + \iw \tys + 0 + \iw \typs - 2 + \uw \ueq + 1 + \tw \ti \\
            \hline
           &&=& \iw \tyi - \iw \tv - \tw \ti - 1 \\
	    &&=& \iw \tyi - 0 - (\iw \tyi - 2) - 1 \\
	    &&=& \textbf{1}
	  \end{tabular}
	\end{mathpar}

	Hence $\uw {\cunif {\pshapp \parens{\tys, \ti, \typs}} \ueq } > \uw {\cexists \tv {\cunif {\pshapp \parens{\tys, \tv, \typs}} \ueq \cand \cunif \tv \ti}}$.
    \end{proofcases}
  \end{proof}
\end{lemma}

\termination
\begin{proof}
  The difficulty for termination comes from the ``suspended match discharge'' rule
  \Rule{S-Match-Ctx} which can make arbitrary
  sub-constraints appear in the non-suspended part of the constraint;
  and from the instantiation rules that copy/duplicate existing
  structure in another part of the constraint, increasing its total
  size.

  As we argued before, the other rewrite rules are \emph{destructive},
  they strictly simplify the constraint towards a normal form and can
  only be applied finitely many times when taken together. The
  fragment without discharge rules and incremental instantiation is
  also extremely similar to the constraint language of
  \citet*{Pottier-Remy/emlti}, so their termination proof applies
  directly.

  \paragraph{Discharge rules} The discharge rules strictly decrease
  the number of occurrences of suspended match constraint (if we also
  count nested suspended constraints), and no rewriting rule
  introduces new suspended match constraints. So these discharge rules
  can only be applied finitely many times. To prove termination of
  constraint solving, it thus suffices to prove that rewriting
  sequences that do not contain one of the discharge rules (those that
  occur in-between two discharge rules) are always finite.

  \paragraph{Starting instantiations} By a similar argument, the number
  of non-partial instantiations $\capp \x \t$ decreases strictly on
  \Rule{S-Let-AppR} when a partial instantiation starts, and is
  preserved by other non-discharge rules. The rule \Rule{S-Let-AppR}
  can thus only occur finitely many times in non-discharging sequences,
  and it suffices to prove that all rewriting sequences that are
  non-discharging and do not contain \Rule{S-Let-AppR} are finite.

  \paragraph{Other instantiation rules} Among other instantiation
  rules, the rule of concern is \Rule{S-Inst-Copy}, which is not
  destructive: it introduces new instantiation constraints
  and structurally increases the size of the constraint.

  Intuitively, \Rule{S-Inst-Copy} should not endanger termination
  because the amount of copying it can perform for a given
  instantiation is bounded by the size of the types in the constraint
  $\c$ it is copying from. ($\c$ could have cyclic equations with
  infinite unfoldings, but \Rule{S-Inst-Copy} forbids copying in that
  case.) The difficulty is that rewrites to $\c$ can be interleaved
  with instantiation rules, so that the equations that are being
  copied can grow strictly during instantiation.

  To control this, we perform a structural induction: to prove that
  $(\cletr \x \tv \tvs \ca \cb)$ does not contain infinite
  non-discharging non-instance-starting rewrite rules, we can assume
  that the result holds for the strictly smaller constraint $\ca$, and
  then prove termination of the partial instantiations of $\x$ in
  $\cb$. (The notion of structural size used here is preserved by
  non-discharging rewrite rules, as they do not affect the
  $\Let$-structure of the constraint.)

  Assuming that $\ca$ has no infinite rewriting sequence, it suffices
  to prove that only finitely many rewrites in the rest of the
  constraint (namely $\cb$) can occur between each rewrite of $\ca$.

  \newcommand{\sw}[1]{\mathprefix{sw}{(#1)}}
  \newcommand{\iw}[1]{\mathprefix{iw}{(#1)}}
  \newcommand{\stw}[1]{\mathprefix{tw}{(#1)}}
  \newcommand{\tw}[2]{\mathprefix{tw}{(#1 \in #2)}}
  \newcommand{\eqs}[1]{\mathprefix{eqs}({#1})}
  \newcommand{\cw}[1]{\mathprefix{cw}{(#1)}}

  We define a weight that captures the contribution of types
  within $\ca$ to the partial instances in~$\cb$:
  \begin{mathpar}
    \begin{tabular}{RCL}
      \stw {\shapp \tys} &\eqdef& 2 \times \sw \sh + \sum \iton \stw \ti \\[1ex]
      \stw \tv &\eqdef&
      \left\{
        \begin{array}{ll}
        \sup \Braces {\stw \t : \cunif \tv \t \in \ca } & \text{if $\ca$ is acyclic} \\
        0 & \text{otherwise}
        \end{array}
      \right.
    \end{tabular}
  \end{mathpar}
  The weight of a partial instantiation $\cw {\cpapp \x \tv \t \inst}$ is
  defined as  the sum of $\stw \t$ and ${\stw \tv}$.
  The weight of other constraints is given using the measure
  $\mathprefix{uw}$ defined in the the
  proof of \cref{lem:unification-termination}.

  \begin{proofcases}
    \proofcaserewrite
      {S-Inst-Copy}
      {\cletr \x \tv \tvs {\c}
	\C\where{\cpapp \x \tvp \tvc \inst}\\
	\c = \cp \cand \cunif \tvp {\cunif {\shapp \tvbs} \ueq}\\
	\tvp \in \reg \tv \tvs \\
	\neg \cyclic {\c} \\
       \tvbs' \disjoint \tvp, \tvc, \tvbs \\
       \x \disjoint \bvs \C}
      {\cletr \x \tv \tvs {\c}
	\C\where{\cexists {\tvbs'} \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}}

      We aim to show that the weight of the rewritten constraint
      $\cexists {\tvbs'} \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst$
      is strictly less than the original $\cpapp \x \tvp \tvc \inst$.

      \begin{mathpar}
	\begin{tabular}{RCL}
	  \cw {\cpapp \x \tvp \tvc \inst} &=& 1 + \stw \tv \\
	  &\geq& 1 + 2 \times \sw \sh + \sum\iton \stw \tvbi  \\[1ex]
	  \cw {\cexists {\tvbs'} \cunif \tvc {\shapp \tvbs'} \cand \cpapp \x {\tvbs} {\tvbs'} \inst}
	  &=&
	  1 + \sw \sh + \sum\iton \stw \tvbi + |\tvbs'|
	\end{tabular}
      \end{mathpar}
      To ensure a strict decrease, it suffices to show that $\sw \sh > |\tvbs'|$.
      Given that $|\tvbs'| = |\sh|$, and by the definition of $\sw \sh$, this inequality holds.
      Therefore, the weight strictly decreases under \Rule{S-Inst-Copy}.

  \end{proofcases}

  Thus the constraint solver terminates.
\end{proof}

\subsection{Correctness}

\begin{lemma}
  \label{lem:unsat-match}
  Given non-simple $\c$ constraint. If every match constraint $\C\where{\cmatch \t \cbrs} = \c$
  satisfies $\nCshape \C \t$, then $\c$ is unsatisfiable.
  \begin{proof}
    By contradiction, inverting on the canonical derivation of $\c$.
  \end{proof}
\end{lemma}

\begin{lemma}
  \label{lem:scoping-preservation}
  For all $\ca, \cb$, if $\ca \csolve \cb$, then $\fvs \ca \supseteq \fvs \cb$.
  \begin{proof}
    By induction on $\ca \csolve \cb$.
  \end{proof}
\end{lemma}

\begin{corollary}
  \label{corollary:correctness}
  For the closed-term-variable constraint $\c$, $\c$ is satisfiable if and only if
  $\c \csolve^* \hat\c$ and $\hat\c$ is a solved form equivalent to $\c$.
  \begin{proof}
    We show each direction individually:
    \begin{proofcases}
      \proofcase{$\implies$}

	By transfinite induction on the well-ordering of constraints whose
	existence is shown in \cref{thm:termination}.

	We have $\c$ is satisfiable.
	By \cref{thm:progress}, we have three cases:
	\begin{proofcases}
	  \proofcase{$\c$ is solved}
	  We have $\c \csolve^* \c$ and $\c \cequiv \c$ by reflexitivity.
	  So we are done.

	  \proofcase{$\c$ is stuck}
	    Given $\c$ is a closed-term-variable constraint,
	    it must be the case that either $\c$ is $\cfalse$
      \emph{or} $\hat\C\where{\cmatch \t \cbrs}$ and $\nCshape \C \t$.

	    If $\c$ is $\cfalse$, this contradicts our assumption that $\c$ is satisfiable.
	    Similarly, by \cref{lem:unsat-match}, if $\c$ is $\hat\C\where{\cmatch \t \cbrs}$,
	    then this also contradicts the satisfiability of $\c$.

	  \proofcase{$\c \csolve \cp$}

	  By \cref{thm:preservation}, we have $\c \cequiv \cp$, thus $\cp$ is satisfiable.
    Additionally, by \cref{lem:scoping-preservation}, we have $\fvs \cp = \eset$.
	  So by induction, we have $\cp \csolve^* \hat \c$ and $\hat\c$
	  is a solved form equivalent to $\cp$.
	  By transitivity of equivalence, we therefore have $\hat\c \cequiv \c$, as
	  required.

	\end{proofcases}

      \proofcase{$\impliedby$}

      By induction on the rewriting $\c \csolve^* \hat\c$.
      \begin{proofcases}
	\proofcaserewrite
	  {Zero-Step}
	  { }
	  {\hat\c \csolve^* \hat\c}

	We have $\c = \hat\c$ by inversion. All solved forms are satisfiable, thus
	$\c$ is satisfiable.

	\proofcaserewrite
	  {One-Step}
	  {\c \csolve \cp \\ \cp \csolve^* \hat\c}
	  {\c \csolve^* \hat\c}

	  By induction, we have $\cp$ is satisfiable. By \cref{thm:preservation},
	  $\c \cequiv \cp$, hence $\c$ is satisfiable.

      \end{proofcases}
    \end{proofcases}
  \end{proof}
\end{corollary}

\section{Properties of \OML}
\label{app/oml/proofs}

% What we do

This section states and proves the two central metatheoretic properties of
\OML. The first is the \emph{soundness and completeness} of the constraint
generator $\cinfer \e \tv$ with respect to the \OML typing rules. The second
is the existence of \emph{principal types}, which follows as a consequence
of soundness and completeness: every closed well-typed term $\e$ admits a
most general type.

% Closed terms

Throughout this section, we restrict our attention to \emph{closed
terms}. This is because the typing context $\G$ can contain bindings to
terms whose type is ``guessed''. When we generate constraints for a term
$\e$ under a context $\G$, we encode the type schemes in $\G$ as part of the
constraint itself using $\Let$-constraints. However, these schemes are
treated as known within the constraint! As a result, we assume terms are
closed from the outside to avoid $\G$ leaking any guessed type information.

\subsection{Simple syntax-directed system}

As a first step towards proving soundness and completeness of constraint
generation, we first present a variant of the \OML type system for
\emph{simple terms}. For this system, the syntax tree completely determines
the derivation tree.

We use the standard technique of removing the \Rule{Inst} and \Rule{Gen} rules,
and always apply instantiations in \Rule{Var} (\Rule{Var-SD}) and always
generalize at let-bindings (\Rule{Let-SD}). We can show that this system is
sound and complete with respect to the declarative rules.

\begin{theorem}[Soundness of the syntax directed rules]
  \label{thm:soundness-sd}
  Given the simple term $\e$.
  If $\G \thsimplesd \e : \t$ then we also have $\G \thsimple \e : \t$
  \begin{proof}
    Induction on the given derivation.
  \end{proof}
\end{theorem}

\begin{theorem}[Completeness of the syntax directed rules]
  \label{thm:completeness-sd}
  Given the simple term $\e$.
  If $\G \thsimple \e : \ts$, then $\G \thsimple \e : \t$ for any instance $\t$ of $\ts$.
  \begin{proof}
    Induction on the given derivation.
  \end{proof}
\end{theorem}

\paragraph{Inversion} On a simple syntax-directed derivation $\G \thsimplesd \e : \t$, we have the usual inversion
principle:
\begin{lemma}[Simple inversion]
  \label{lem:simple-inversion-sd}
  ~
  \begin{enumerate}[(\roman*)]
    \item If $\G \thsimplesd \x : \t$, then $\x : \tfor \tvs \tp \in \G$ and $\t = \tp\where{\tvs \is \tys}$.
    \item If $\G \thsimplesd \efun \x \e : \t$, then $\G, \x : \ta \thsimplesd \e : \tb$ and $\t = \ta \to \tb$.
    \item If $\G \thsimplesd \eapp \ea \eb : \t$, then $\G \thsimplesd \ea : \tp \to \t$ and $\G \thsimplesd \eb : \tp$.
    \item If $\G \thsimplesd \eunit : \t$, then $\t = \tunit$.
    \item If $\G \thsimplesd \elet \x \ea \eb : \t$, then $\G \thsimplesd \ea : \tp$, $\tvs \disjoint \G$, and $\G, \x : \tfor \tvs \tp \thsimplesd \eb : \t$.
    \item If $\G \thsimplesd \eannot \e \tvs \tp : \t$, then $\G \thsimplesd \e : \tp\where{\tvs \is \tys}$ and $\t = \tp\where{\tvs \is \tys}$.
   \item If $\G \thsimplesd \etuple {\ea, \ldots, \en} : \t$, then $\G \thsimplesd \ei : \ti$ for all $1 \leq i \leq n$ and $\t = \tProd \ti$.
    \item If $\G \thsimplesd \exproj \e j n : \t$, then $\G \thsimplesd \e : \tProd \ti$ and $\t = \tj$, with $n \geq j$.
    \item If $\G \thsimplesd \expoly \e \tvs {\tfor \tvbs \tp} : \t$, then $\G \thsimplesd \e : \t\where{\tvs \is \tys}$, $\tvbs \disjoint \G$ and
      $\t = \tpoly {\tfor \tvbs \tp}\where{\tvs \is \tys}$.
    \item If $\G \thsimplesd \exinst \e \tvs \ts : \t$, then $\G \thsimplesd \e : \tpoly \ts\where{\tvs \is \tys}$ and $\ts \leq \t$.
    \item If $\G \thsimplesd \emagic \es : \t$, then $\G \thsimplesd \ei : \tip$ for all $1 \leq i \leq n$.
    \item If $\G \thsimplesd \exrecord \T {\overline{\elab = \e}} : \t$, then $\G \thsimplesd \ei : \ti$ and ${\labfrom \elab \T} \leq \t \to \ti$ for $1 \leq i \leq n$ and $\Dom {\labfrom \labenv \T} = \elabs$.
    \item If $\G \thsimplesd \erecord {\overline{\elab = \e}} : \t$, then $\labsuni \elabs \T$ and $\G \thsimplesd \exrecord \T {\overline{\elab = \e}} : \t$.
    \item If $\G \thsimplesd \exfield \e \T \elab : \t$, then $\G \thsimplesd \e : \tp$, ${\labfrom \elab \T} \leq \tp \to \t$.
    \item If $\G \thsimplesd \efield \e \elab : \t$, then $\labuni \elab \T$ and $\G \thsimplesd \exfield \e \T \elab : \t$.
  \end{enumerate}
\end{lemma}

\subsection{Canonicalization of typability}
Our system satisfies a similar canonicalization theorem to constraint satisfiability.

\begin{lemma}[Composability of unicity]
  ~
  \label{lem:comp-unicity-typing}
  \begin{enumerate}[(\roman*)]
    \item If $\Eshape \Ea \es \sh$, then $\Eshape {\Eb\where\Ea} \es \sh$.
    \item If $\eshape \Ea \e \sh$, then $\eshape {\Eb\where\Ea} \e \sh$.
  \end{enumerate}
  \begin{proof}
    By induction on $\Eb$.
  \end{proof}
\end{lemma}

\begin{lemma}[Decanonicalization]
  \label{lem:decanonicalization-typing}
  If $\Th \e : \t$, then $\eset \th \e : \t$.
  \begin{proof}
    By induction on the given derivation $\Th \e : \t$.
  \end{proof}
\end{lemma}

\newcommand{\enimplicit}[1]{{\#\mathprefix[\mathsf]{implicit} {#1}}}
\begin{theorem}[Canonicalization]
  \label{thm:canonicalization-typing}
  If $\th \e : \ts$, then $\Th \e : \t$ for any instance $\t$ of $\ts$.
  \begin{proof}
    By induction on the following measure of $\e$:
    \begin{mathpar}
      \| \e \| \uad\eqdef\uad \angles {\enimplicit \e, |\e|}
    \end{mathpar}
    where $\angles \ldots$ denotes a lexicographically ordered pair, and
  \begin{enumerate}

    \item $\enimplicit \e$ is the number of implicit constructs in $\e$ \ie overloaded tuple projections $\eproj \e j$,
      implicit non-unique field projections $\efield \e \elab$, implicit non-unique records $\erecord {\overline{\elab = \e}}$, polytype instantiations $\einst \e$
      and polytype boxing $\epoly \e$.

    \item the last component $|\e|$ is a structural measure of terms \ie a
      application $\eapp \ea \eb$ is larger than the two terms $\ea, \eb$.
  \end{enumerate}
  This measure is analogous to the measure $\cmeasure \c$ for constraints.
  \end{proof}
\end{theorem}

\subsection{Unifiers}

A substitution $\sub$ is an idempotent function from type variables to types.
The (finite) domain of $\sub$ is the set of type variables such that $\sub(\tv)
\neq \tv$ for any $\tv \in \dom \sub$, while the codomain consists of the free
type variables of its range.
%
We use the notation $\where{\tvs \is \tys}$ for the substitution $\sub$ with
domain $\tvs$ and $\sub(\tvs) = \tys$.

The constraint induced by a substitution $\sub$, written $\exists \sub$, is
$\cexists {\tvbs} \tvs = \tys$ where $\tvbs = \rng \sub$, $\tvs = \dom \sub$
and $\sub(\tvs) = \tys$.

\begin{definition}[Unifier]
  A substitution $\sub$ is a unifier of $\c$ if $\exists \sub$ entails $\c$.
  A unifier $\sub$ of $\c$ is \emph{most general} when $\exists \sub$ is equivalent
  to $\c$.
\end{definition}

\begin{lemma}[Simple inversion of unifiers]
  \label{lem:unifier-simple-inversion}
  ~
  \begin{itemize}
    \item If $\sub$ is a unifier of $\cunif \ta \tb$, then $\sub(\ta) = \sub(\tb)$.
    \item For simple $\ca, \cb$, if $\sub$ is a unifier of $\ca \cand \cb$, then $\sub$ is a unifier of $\ca$ and $\cb$.
    \item For simple $\c$, if $\sub$ is a unifier of $\cexists \tv \c$, then $\sub\where{\tv \is \t}$ is a unifier of $\c$ for some $\t$.
    \item For simple $\c$, if $\sub$ is a unifier of $\cfor \tv \c$, then $\sub$ is a unifier of $\c$.
  \end{itemize}
  \begin{proof}
    Follows by simple inversion.
  \end{proof}
\end{lemma}

\begin{lemma}
  \label{lem:unifier-abs-equiv}
  If $\sub$ unifies $\cexists \tv \c$, then there exists a unifier $\subp$ that extends $\sub$ with $\tv$,
  where $\subp$ is most general unifier of $\exists \sub \cand \c$.


  Then $\cabs \tv \c$ is equivalent to $\cabs \tv \sigma \leq \tv$ under $\sub$, where $\ts = \tfor \tvbs \subp(\tv)$ and
  $\tvbs = \fvs {\subp(\tv)} \setminus \rng \sub$. We write this equivalent constraint abstraction as $\csem {\cabs \tv \c}_\sub$.
  \begin{proof}
    See \citet*{Pottier-Remy/emlti}.
  \end{proof}
\end{lemma}

\begin{lemma}[Let inversion of unifiers]
  For simple $\ca, \cb$.
  If $\sub$ unifies $\clet \x \tv \ca \cb$, then
  $\sub$ unifies $\cexists \tv \ca$ and
  $\sub$ unifies $\cletin \x {\csem {\cabs \tv \ca}_\sub} \cb$
  \begin{proof}
    Follows from \cref{lem:unifier-abs-equiv} and simple inversion.
  \end{proof}
\end{lemma}

\begin{lemma}
  \label{lem:mgus}
  For two substitutions $\sub$, $\subp$. If $\exists \sub \centails \exists \subp$, there exists
  $\subpp$ such that $\sub = \subpp \compose \subp$.
  \begin{proof}
    Standard result, follows from definition of $\exists \sub$.
  \end{proof}
\end{lemma}

\subsection{Soundness and completeness of constraint generation}

\begin{judgboxmathpar}
  {\ctxinfer \E \tvp \tv}
  {$\ctxinfer \E \tvp \tv$ is a satisfiable context iff the context $\E$ has \\ the expected type $\tv$ given the hole has the type $\tvp$.}
\newcommand {\Crule}[2]{#1 &\eqdef& #2}
\def \arraystretch{1.4}%4
  \scalebox{0.9}{
\begin{tabular}{LCL}
  \Crule{\ctxinfer \square \tv \tv}{\square}\\
  \Crule{\ctxinfer {\parens{\eapp \E \e}} \tvp \tv}{\cexists {\tvb \tvc} \cunif \tvc {\tvb \to \tv} \cand \ctxinfer \E \tvp \tvc \cand \cinfer \e \tvb}\\
  \Crule{\ctxinfer {\parens{\eapp \e \E}} \tvp \tv}{\cexists {\tvb \tvc} \cunif \tvc {\tvb \to \tv} \cand \cinfer \e \tvc \cand \ctxinfer \E \tvp \tvb}\\
  \Crule{\ctxinfer {\parens{\elet \x \E \e}} \tvp \tv}{\clet \x \tvb {\ctxinfer \E \tvp \tvb} {\cinfer \e \tv}}\\
  \Crule{\ctxinfer {\parens{\elet \x \e \E}} \tvp \tv}{\clet \x \tvb {\cinfer \e \tvb} {\ctxinfer \E \tvp \tv}}\\
  \Crule{\ctxinfer {{\eannot \E \tvs \t}} \tvp \tv}{\cexists \tvs \cunif \tv \t \cand \ctxinfer \E \tvp \tv}\\
  \Crule{\ctxinfer {\etuple {\ea, \ldots, \E_j, \ldots, \en}} \tvp \tv}{\cexists \tvs \cunif \tv {\tProd \tvi} \cand \cAnd_{i \neq j} \cinfer \ei \tvi \cand \ctxinfer {\E_j} \tvp \tvj} \\
  \Crule{\ctxinfer {\parens{\exproj \E j n}} \tvp \tv}{\cexists {\tvb, \tvbs} \ctxinfer \E \tvp \tvb \cand \cunif \tvb {\tProd \tvbi} \cand \cunif \tv \tvbj}\\
  \Crule{\ctxinfer {\parens{\eproj \E j}} \tvp \tv}{\cexists \tvb \ctxinfer \E \tvp \tvb \cand \cmatch \tvb {\cbranch {\cpatprod \tvc j} {\cunif \tv \tvc}}}\\
  \Crule{\ctxinfer {\expoly \E \tvs \ts} \tvp \tv}{\cexists \tvs \ctxinfer \E \tvp \ts \cand \cunif \tv {\tpoly \ts}}\\
  \Crule{\ctxinfer {\exinst \E \tvs \ts} \tvp \tv}{\cexists {\tvs, \tvb} \ctxinfer \E \tvp \tvb \cand \cunif \tvb {\tpoly \ts} \cand \cleq \ts \tv}\\
  \Crule{\ctxinfer {\epoly \E} \tvp \tv}{\clet \x \tvb {\ctxinfer \E \tvp \tvb} {\\&&\cmatch \tv {\cbranch {\cpatpoly \cscm} {\cleq \x \cscm}}}}\\
  \Crule{\ctxinfer {\einst \E} \tvp \tv}{\cexists \tvb {\ctxinfer \E \tvp \tvb \cand \cmatch \tvb {\cbranch {\cpatpoly \cscm} {\cleq \cscm \tv}}}}\\
\Crule
  {\ctxinfer {\parens{\efield \E \elab}} \tvp \tv}
  {\begin{cases}
    \cexists {\tvb} \ctxinfer \E \tvp \tvb \cand \labenv(\labfrom \elab \T) \leq \tvb \to \tva & \text{if } \labuni \elab \T \\
    \cexists \tvb \ctxinfer \E \tvp \tvb \\ \cand \cmatch \tvb {\cbranch {\cpatrcd \ct} {\labenv(\labfrom \elab \ct) \leq \tvb \to \tv}} & \text{otherwise}
  \end{cases}}
\\
\Crule
  {\ctxinfer {\parens{\exfield \E \T \elab}} \tvp \tv}
  {\cexists \tvb \ctxinfer \E \tvp \tvb \cand \labenv(\labfrom \elab \T) \leq \tvb \to \tva}
\\
\Crule
  {\ctxinfer {\erecord {\elaba = \ea; \ldots; \elab_j = \E_j; \ldots; \elab_n = \en}} \tvp \tv}
  {\begin{cases}
    \cexists \tvbs \cAnd_{i \neq j} \cinfer \ei \tvbi \cand \ctxinfer {\E_j} \tvp \tvbj     & \text{if } \labsuni \elabs \T \\
    \cand \cAnd\iton \labenv(\labfrom \elabi \T) \leq \tv \to \tvbi \\
    \cexists \tvbs \cAnd\iton \cinfer \ei \tvbi & \text{otherwise} \\
    \uad\cand~\cmatch \tv {\cbranch {\cpatrcd \ct}
      {\dom {\ct} = \elabs \\
      \hspace{3cm}\cand \cAnd\iton \labenv(\labfrom \elabi \ct) \leq \tv \to \tvbi}}
  \end{cases} }
\\
\Crule
  {\ctxinfer {\exrecord \T {\elaba = \ea; \ldots; \elab_j = \E_j; \ldots; \elab_n = \en}} \tvp \tv}
  {\cexists \tvbs \cAnd_{i \neq j} \cinfer \ei \tvbi \cand \ctxinfer {\E_j} \tvp \tvbj \cand \dom {\T} = \elabs \\
  &&\cand \cAnd\iton \labenv(\labfrom \elabi \T) \leq \tv \to \tvbi }
\\
\Crule
  {\ctxinfer {\emagic {\ea, \ldots, \E_j, \ldots, \en}} \tvp \tv}
  {\cexists \tvbs \cAnd_{i \neq j} \cinfer \ei \tvbi \cand \ctxinfer {\E_j} \tvp \tvbj}
\\\\
\Crule
  {\ctxinfer \E \tvp \t}
  {\cexists \tv \cunif \tv \t \cand \ctxinfer \E \tvp \tv}
\\
\Crule
  {\ctxinfer \E \tvp {\tfor \tvs \t}}
  {\cfor \tvs \ctxinfer \E \tvp \t}
\\\\
\end{tabular}
  }
\end{judgboxmathpar}

\begin{lemma}
  \label{lem:ctxt-gen-correctness}
  For any term context $\E$, term $\e$, $\ctxinfer \E \tv \tvb \where{\cinfer \e \tv} = \cinfer {\E\where{\e}} \tvb$.
  \begin{proof}
    By induction on the structure of $\E$.
  \end{proof}
\end{lemma}

\begin{lemma}
  \label{lem:erasure-constraint-gen}
  For any term $\e$, $\cerase {\cinfer \e \tv} = \cinfer {\eerase \e} \tv$.
  \begin{proof}
    By induction on $\e$.
  \end{proof}
\end{lemma}

\begin{lemma}[Simple soundness and completeness]
  \label{lem:simple-soundness-completeness}
  For simple terms $\e$.
  $\sub(\G) \thsimplesd \e : \sub(\t)$ if and only if $\sub$ is a unifier of $\csem {\G \th \e : \t}$.
  \begin{proof}
    By induction on $\e \simple$.
  \end{proof}
\end{lemma}

\begin{theorem}[Soundness and completeness]
  \label{thm:soundness-and-completeness}
  $\Th \e : \sub(\tv)$ if and only if $\sub$ is a unifier of $\csem {\e : \tv}$
  \begin{proof}
    By induction on the number $n$ of implicit terms in $\e$.
    \begin{proofcases}
      \proofcase{$n$ is $0$}

	\begin{llproof}
	  \simplePf{\e}{Premise}
	  \iffPf{\eset\thsimplesd \e : \sub(\tv)}{\sub \text{ unifies } \csem {\e : \tv}}{\cref{lem:simple-soundness-completeness}}
	  \iffPf{\eset \thsimplesd \e : \sub(\tv)}{\Th \e : \sub(\tv)}{When $\e \simple$}
\Hand	  \iffPf{\Th \e : \sub(\tv)}{\sub \text{ unifies } \csem {\e : \tv}}{Above}
	\end{llproof}

      \proofcase{$n$ is $k + 1$}

	\begin{proofcases}
	  \proofcase{$\implies$}

	  \begin{proofcases}

	    \proofcasederivation
	      {Can-Proj-I}
	      {\eshape \E \e {\any \tvcs \Pi\iton \tvcs} \\ \sub(\G) \Th \E\where{\exproj \e j n} : \sub(\tv)}
	      {\Th \E\where{\eproj \e j} : \sub(\tv)}

	      \begin{llproof}
		\ThTypPf{\sub(\G)}{\E\where{\exproj \e j n}}{\sub(\tv)}{Premise}
		\UnifierPf{\sub}{\csem {\G \th \E\where{\exproj \e j n} : \tv}}{By \ih}
		\eqPf{\csem {\G \th \E\where{\exproj \e j n } : \tv}}{\cletG {\cinfer {\E\where{\exproj \e j n}} \tv}}{By definition}
		\continueeqPf{\cletG {\ctxinfer \E \tvb \tv}\where{\cinfer {\exproj \e j n} \tvb}}{\cref{lem:ctxt-gen-correctness}}
		\equivPf{\cinfer {\exproj \e j n} \tvb}{\cexists {\tvaa \tvcs} {\cinfer \e \tvaa \cand \cunif \tvaa {\Pi\iton \tvcs} \cand \cunif \tvb \tvc_j}}{By definition}
		\continueequivPf{\cexists {\tvaa} \cinfer \e \tvaa \cand \cmatched \tvaa {\any \tvcs \Pi\iton \tvcs}{\cbranch {\cpatprod \tvc j} {\cunif \tvb \tvc}}}{\ditto}
		\UnifierPf{\sub}{\cletG \ctxinfer \E \tvb \tv \where{\cexists \tvaa \cinfer \e \tvaa \cand \ldots}}{Above}
		\eshapePf{\E}{\e}{\any \tvcs \Pi\iton \tvcs}{Premise}
		\LetPf{\C}{\cletG \ctxinfer\E \tvb \tv \where{\cexists \tvaa \cinfer \e \tvaa \cand \square}}{}
		\vdashPf{\semenv}{\cerase{\C\where{\cunif \tvaa \gt}}}{Premise}
		\eqPf{\cexists \tvaa \cinfer \e \tvaa \cand \cunif \tvaa \gt}{\cexists \tvaa \cinfer {\eannot \e {} \gt} \tvaa}{By definition}
		\decolumnizePf
		\continueeqPf{\cinfer {\emagic {\eannot \e {} \gt}} \tvb}{\ditto}
		\eqPf{\cerase {\C\where{\cunif \tvaa \gt}}}{\cerase {\cletG \ctxinfer \E \tvb \tv \where{\cinfer {\emagic {\eannot \e {} \gt}} \tvb}}}{\ditto}
		\continueeqPf{\cerase {\cletG \cinfer {\E\where{\emagic {\eannot \e {} \gt}}} \tv}}{\cref{lem:ctxt-gen-correctness}}
		\continueeqPf{\cletG \cerase {\cinfer {\E\where{\emagic {\eannot \e {} \gt}}} \tv}}{By definition}
		\continueeqPf{\cletG \cinfer {\eerase {\E\where{\emagic {\eannot \e {} \gt}}}} \tv}{\cref{lem:erasure-constraint-gen}}
		\UnifierPf{\semenv}{\cletG \cinfer {\eerase {\E\where{\emagic {\eannot \e {} \gt}}}} \tv}{Above}
		\ThTypPf{}{\eerase {\E\where{\emagic {\eannot \e {} \gt}}}}{\semenv(\tv)}{By \ih}
		\thTypPf{\eset}{\eerase {\E\where{\emagic {\eannot \e {} \gt}}}}{\semenv(\tv)}{\cref{lem:decanonicalization-typing}}
		\eqPf{\shape \gt}{\any \tvcs \Pi\iton \tvcs}{$\implies$E}
		\shapePf \C \tvaa {\any \tvcs \Pi\iton \tvcs}{Above}
		\UnifierPf{\sub}{\C\where{\cmatch \tvaa {\cbranch {\cpatprod \tvc j} {\cunif \tvb \tvc}}}}{By \Rule{Match-Ctx}}
		\eqPf{\cinfer {\eproj \e j} \tvb}{\cexists \tvaa \cinfer \e \tvaa \cand \cmatchdots \tvaa}{By definition}
		\eqPf{\C\where{\cmatchdots \tvaa}}{\cletG \ctxinfer \E \tvb \tv\where{\cexists \tvaa \cinfer \e \tvaa \cand \ldots}}{\ditto}
		\continueeqPf{\cletG \ctxinfer \E \tvb \tv \where{\cinfer {\eproj \e j} \tvb}}{Above}
		\continueeqPf{\cletG \cinfer {\E\where{\eproj \e j}} \tv}{\cref{lem:ctxt-gen-correctness}}
		\continueeqPf{\csem {\E\where{\eproj \e j} : \tv}}{}
\Hand  		\UnifierPf{\sub}{\csem {\E\where{\eproj \e j} : \tv}}{}
	      \end{llproof}

      \proofcase{\Rule{Can-Poly-I}, \Rule{Can-Use-I}, \Rule{Can-Rcd-I}, \Rule{Can-Rcd-Proj-I}}

	    \begin{llproof}
	      Similar arguments.
	    \end{llproof}
	  \end{proofcases}

	  \proofcase{$\impliedby$}

	  \begin{proofcases}
	    \proofcasederivation
	      {Can-Match-Ctx}
	      {\Cshape \C \tvaa {\any \tvcs \Pi\iton \tvcs} \\
	       \sub \text{ unifies } \C\where{\cmatched \tvaa {\any \tvcs \Pi\iton \tvcs} {\ldots}}}
	      {\sub \text{ unifies } \underbrace{\C\where{\cmatch \tvaa {\cbranch {\cpatprod \tvc j} {\cunif \tvb \tvc}}}}_{\cinfer \e \tv}}

	      \begin{llproof}
		\eqPf{\csem {\e : \t}}{\cletG \cinfer {\E\where{\eproj \e j}} \tv}{Premise}
		\eqPf{\C}{\cletG \ctxinfer \E \tvb \tv\where{\cexists \tv \cinfer \e \tv \cand \square}}{Premise}
		\UnifierPf{\sub}{\C\where{\cmatched \tvaa {\any \tvcs \Pi\iton \tvcs} {\ldots}}}{Premise}
		\UnifierPf{\sub}{\csem {\E\where{\exproj \e j n} : \tv}}{Above (See $\implies$ direction)}
		\ThTypPf{}{\E\where{\exproj \e j n}}{\sub(\tv)}{By \ih}
		\thTypPf{\Gp}{\E\where{\emagic {\eannot \e {} \gt}}}{\tp}{Premise}
		\eqPf{\Gp}{\eset}{$\E\where{\emagic {\eannot \e {} \gt}}$ is closed}
		\ThTypPf{}{\E\where{\emagic {\eannot \e {} \gt}}}{\tp}{\cref{lem:decanonicalization-typing}}
		\UnifierPf{\where{\tv \is \tp}}{\csem {\E\where{\emagic {\eannot \e {} \gt}} : \tv}}{By \ih}
		\vdashPf{\semenv\where{\tv \is \semenv(\tp)}}{\cinfer {\E\where{\emagic {\eannot \e {} \gt}}} \tv}{By definition}
		\shapePf{\C}{\tvaa}{\any \tvcs \Pi\iton \tvcs}{Premise}
		\eqPf{\shape \gt}{\any \tvcs \Pi\iton \tvcs}{$\implies$E}
		\eshapePf{\E}{\e}{\any \tvcs \Pi\iton \tvcs}{Above}
		\ThTypPf{}{\E\where{\eproj \e j}}{\sub(\tv)}{By \Rule{Can-Proj-I}}
	      \end{llproof}

      \proofcase{$\epoly \e$, $\einst \e$, $\erecord {\overline{\elab = \e}}$, $\efield \e \elab$}

	    \begin{llproof}
	      Similar arguments.
	    \end{llproof}
	  \end{proofcases}
	\end{proofcases}
    \end{proofcases}
  \end{proof}
\end{theorem}

\subsection{Principal types}

\principalTypes
\begin{proof}

Let $\e$ be an arbitrary closed well-typed term; that is, there exists a type
  $\t$ such that $\th \e : \t$.
  By \cref{thm:soundness-and-completeness}, the constraint $\cinfer \e \tv$ is satisfiable
  (specifically under the unifier $\cunif \tv \t$). By \cref{corollary:correctness}, there
  exists a solved constraint $\hat\c$ such that $\hat\c \cequiv \cinfer \e \tv$.
  From $\hat\c$, we extract a unifier $\sub$. Since $\hat\c \cequiv \exists \sub$,
  it follows that $\sub$ is \emph{most general}.

  We claim that $\sub(\tv)$ is the principal type of $\e$. This amounts to showing:
  \begin{enumerate}[(\roman*)]
    \item
      \label{proof:principal-types:1}
      $\th \e : \sub(\tv)$
    \item
      \label{proof:principal-types:2}
      For any other typing $\th \e : \tp$, then $\tp = \theta(\sub(\tv))$ for some $\theta$.
  \end{enumerate}
  Since $\sub$ is a unifier of $\cinfer \e \tv$, it follows immediately from
  \cref{thm:soundness-and-completeness} that $\th \e : \sub(\tv)$, proving \ref{proof:principal-types:1}.
  For \ref{proof:principal-types:2}, suppose $\th \e : \tp$ for some $\tp$. Then by
  \cref{thm:soundness-and-completeness} again, there exists a unifier $\subp$ of $\cinfer \e \tv$
  such that $\subp(\tv) = \tp$. Since $\sub$ is most general, we have $\exists \subp \centails \exists \sub$,
  and by \cref{lem:mgus}, this implies the existence of a substitution $\subpp$ such that
  $\subp = \subpp \compose \sub$.
  Hence, $\tp = \subp(\tv) = \subpp(\sub(\tv))$, witnessing that $\tp$ is an instance of $\sub(\tv)$, as
  required \ref{proof:principal-types:2}.
\end{proof}

\section {Further study}

\subsection {Defaulting}

Default rules, which does not fit well with \Geninst-inference are still
often used in practice, and therefore would deserve further investigation.

\paragraph {Default shapes}

In this section we study a particular form of defaulting where, rather than
general default rules that could fire any constraint, we restrict to default
shapes. That is, we may attach a default shape $\sh$ to a match constraints
$\cmatch \t \cbrs$, which is then written $\cmatch \t \cbrs \cdefault
\sh$. The default shape $\sh$ can then be used to force the shape of
$\t$ when it could not be determined from context.

%% We show that under some conditions for well-behaved defaulting there is
%% actually an optimal strategy.

Restricting to default shapes has several benefits.  First, a strategy $\S$
can be reduced to the choice of a mapping from constrains $\c$ to of a
subset $\Sfire \S \c$ of suspended constraints of $\suspc$ that should be
defaulted, simultaneously.  The behavior is then entirely determined,
reusing the same logic that runs when the shape is determined by the context
instead of been forced by the default clause.  In particular, this ensures
that the same behavior could have been obtained by an explicit shape
constraint in the source.

\paragraph {Strategies}

We write $\Sempty$ for the empty strategy that never defaults (and thus fails
on all constraints with leftover suspensions) and $\Sfull$ the full strategy
that defaults all suspended constraints, simultaneously.
%% We can formulate some good properties that defaulting strategies should
%% satisfy.
A strategy $\S$ is \emph{reasonable} if for all constraints
$\c$, $\S (\c)$ succeeds more often than the empty strategy on C.
%
This criterion rules out weird strategies that would default a suspension
before solving the other constraints that could discharge this suspension,
possibly with another shape, hence a different output.

A strategy $\S$ applied to a constraint $\c$, either allows to solve $\c$,
hence with a principal solution written $\Ssol \S$ or ends in error ($\Ssol
\S$ is equal to $\bot$).  Let use write $\Sols$ for the union of
all $\Ssol \S$ for all successful reasonable strategies $\S$.
%
We say that $\S$ is non-ambiguous if, for any $\c$, $\Ssol \S$ is $\bot$
whenever $\Sols$ has more than two elements.  This condition forces a
non-ambiguous strategy to fail instead of picking an arbitrary solution when
different defaulting strategies would give incompatible solutions.

A \emph{good} strategy as one that is both \emph{reasonable} and
\emph{non-ambiguous}. A good strategy should not fail more often that
$\Sempty$ nor succeed when there are more than one possible solution.
%
We claim that there is an optimal \emph{good} strategy $\Sopt$ that explores all
possible default subsets, succeeds when there is exactly one principal
solution, then following a successful strategy, and fails otherwise.

Unfortunately, $\Sopt$ is inefficient: as described , it runs in time
exponential in the number of remaining suspended constraints.  Therefore, we
should seek for sub-optimal, but more efficient good strategies.

\begin{version}{\Not\Final} %\Draft

\paragraph {Dependencies}

Given a stuck constraint $\c$, we may look at the dependency order between
its suspended constraints.
\begin{version}{}

Intuitively, a suspended constraint  $\suspcb$
%% of the form $(\cmatch \tvab \cbrbs \cdefault \shb)$
depends on another suspended constraint $\suspca$
%% of the form $(\cmatch \tvaa \cbras \cdefault \sha)$,
%% and we write $\suspca \cprec \suspcb$,
if defaulting  $\suspca$ allows to solve $\suspcb$---without further
defaulting.  Unfortunately, this is too strong as a suspended constraint may
help resolve another one without solving it. For instance, defaulting two
suspended constraints could be needed to allow solving a third one.

\end{version}
A suspended constraint $\suspcb$ depends on another suspended
constraint~$\suspca$ if there exists a strategy $\S$ that can solve
$\suspcb$ only after defaulting $\suspca$.  That is, if successively
defaulting $\suspca, \bar \suspcs$ solves $\suspcb$ while $\bar \suspcs$
does not.
%
This defines a partial ordering~$\cprec^s$ on suspended constraints of~$\c$,
which is however expensive to compute.

Therefore, we define a syntactical over approximation of $\cprec$ that is
easier to compute. We assume that $\c$ is partially solved. That is, it is
stuck, but excluding cases (\ref{item/progress/scope/x}) and
(\ref{item/progress/scope/i}) which cannot occur with well-formed
constraints.  The solved part of $\cerase {\c}$ defines a partial
(structural domination) ordering $\cprec$ on variables.

$\cerase {\c}$ may also contains partial instantiations
\emath{\cpapp \x \tv \tvc  \inst}, which implies that
knowing shape of $\tv$ will also determine the shape of $\tvc$.  We thus
extend the $\cprec$ ordering with $\tv \cprec \tvc$ for each partial
instantiation \emath{\cpapp \x \tv \tvc \inst}.

Notice that \emath{\cpapp \x \tv \tvc \inst} has also the potential to force
the unification of $\tv$ and $\tvc$, which will happen whenever the scope of
$\tv$ is lowered, \eg by instantiation of $\tv$ without necessarily
determining the shape of $\tv$.  Hence, one may be tempted to add a reverse
edge from $\tvc$ to $\tv$. However, this may only happen if $\tv$ has been
reached, hence $\tvc$ is already considered as reached, hence determined,
even if its shape is not yet known.

Finally,   for each suspended constraints $\cmatch \tvi {\cbrs_i} \cdefault
\shi$ of $\c$, let $\bar\tvbs_i$ be the set of free variables of $\cbrs_i$
and add $\tvi \cprec \tvci$ for each $\tvci$ in $\tvbs_i$.  Indeed, whenever
the shape of $\tvi$ is determined, the constraint $\suspci$ will be
released, and since it is being treated opaquely, it could do anything with
its free variables, hence fully determined they shapes.  This may release
unification constraints between variables of $\tvbs_i$. Hence, we may be
tempted to claim equivalences between them. However, this may only happened
if $\tvi$ has been reached, and thus all variables of $\tvbs_i$ are
considered as reached as well, hence potentially determined.

The partial ordering between variables induces a partial ordering between
suspended constrains: $\suspca \cprec \suspcb$ whenever $\tvaa \cprec \tvab$
and $\suspci$'s are of the form $(\cmatch \tvai {\bar\cbri} \cdefault
\shi)$.

The syntactic dependency ordering $\cprec$ is an over approximation of the
semantic dependency ordering $\cprec^s$.  Hence, a suspended constraint that
is minimal for the syntactic ordering is also minimal for the semantics
ordering---it depends on no other suspended constraints.

A strategy that always defaults a minimal constraint is
\begin{enumerate*}
\item reasonable;
\item non-ambiguous; and\goodbreak
\item \emph{complete}, \ie it preserves the set of solutions $\Sols$.
\end{enumerate*}
Indeed, either a strategy does not discharge this minimal constraint, and it
fails on $\c$, or it discharges this constraint and this must be via
defaulting, given minimality, and for minimal constraints the defaulting
order does not affect the result.  In fact, all constraints that are minimal
can also be defaulted simultaneously.

However, such a strategy may be stuck if there is no minimal element, but
only a minimal cycle of constraints (there is always one). \XDR{Can we still
say that the strategy is complete? Is then the empty strategy complete? We
should distinguish being stuck from returning a failure.}

If there is a cycle of constraints that are minimal, then defaulting them
altogether, which we call the \emph{whole-cycle} strategy, is reasonable and
non-ambiguous, but not complete.  For example, consider the constraint:
\begin{mathpar}
\Wedges {
\cmatch \tv {
    \cbranch \wild {\cunif \tvb \tint}
    } \cdefault \tint
\\
\cmatch \tvb {
    \cbranch\wild {\cunif \tva \tbool}
    } \cdefault \tbool
}
\end{mathpar}
that are clearly interdependent.  Defaulting $\set \tva$ succeeds while
defaulting $\set \tvb$ or $\set {\tva, \tvb}$ fails.  The whole-cycle
strategy $\set{\tva, \tvb}$ fails here, so it is not complete.

\paragraph {Opaque suspended constraints}

Notice however, that if we treat the suspended constraints as opaque, we
cannot distinguish this example from the following where defaulting only
$\set
\tva$ would incorrectly succeed in an ambiguous situation. Hence, it would
not be a non-ambiguous strategy:
\begin{mathpar}
\Wedges{
\cmatch \tv {
    \cbranch \tint  {\cunif \tvb \tint} \mid
    \cbranch \tbool {\cunif \tvb \tint}
    } \cdefault \tint
\\
\cmatch \tvb {
    \cbranch \tint  {\cunif \tva \tint} \mid
    \cbranch \tbool {\cunif \tva \tbool}
    } \cdefault \tbool
}
\end{mathpar}
Indeed, defaulting $\set{\tva}$ gives
\relax $\wedges {\cunif \tva \tint \\ \cunif \tvb \tint}$,
whereas defaulting $\set \tvb$ gives
\relax $\wedges {\cunif \tva \tint \\ \cunif \tvb \tbool}$;
and defaulting $\set {\tva,\tvb}$ fails. This constraint is ambiguous.
Hence, the whole-cycle strategy \emph{correctly} fails.

Intuitively, treating suspended constraints as opaque is a way to compensate
for the over-approxi\-mation of syntactic dependencies by allowing allow to
choose for opaque constraints concrete constraints that actually create
all the dependencies used in the approximation.

We call a strategy \emph{opaque} when it only depends on the syntactic
dependency relation and not on the actual branches of the suspended
constraints.
%
For example, the optimal strategy is \emph{not} opaque, as it behaves
differently on the two examples above whereas they have the same syntactic
dependencies.

\begin{property}
The whole-cycle strategy is optimal among opaque strategies.
\end{property}
\begin{proof}[Proof hint]{}
We may reduce the general case to a specific cycle of size $n$
(one minimal element of the topological sort of the dependency order).
On this cycle, all opaque strategies are characterized by which subset of
the cycle they default.

To show that defaulting all together is optimal:
\begin{enumerate*}

\item
  We show that it is not worse than defaulting less.
\item
  Conversely, we may build a specific example with an $n$-cycle of
  suspended constraints where defaulting all at once succeeds, and
  defaulting strictly less fails.

\end{enumerate*}
The opacity of suspended constraints also leaves us enough freedom to
enforce all the worse case dependencies in the definition of $\cprec$.
\end{proof}

\begin{version}{\Draft}
Computing the syntactic dependencies $\cprec$ is in $O(n \log n)$ where $n$
is the size of the constraint (not just of suspended constraints).  However,
it is not stable by defaulting. Indeed, this may remove (and add) some
syntactic dependencies, which requires the re-computation of $\prec$.
Incremental computation of dependencies with both edge removal and insertion
may be needed. In any case, experimentation will be needed to
understand whether this is a critical issue.
\end{version}
\end{version}


\clearpage
\setcounter{tocdepth}{1}
\tableofcontents


%%% Below this line will is a draft
\Draft{}{\end{document}}\color{blue}

\clearpage

\section{DRAFT: a later TODO  list}

Problems to solve or leave unsolved:
\begin{itemize}

\item
  Overloading of the bracket notation for context filling and polytypes,
  as in $E\where{\epoly \e}$.

  A possibility would be to use braces for either one. Although they are
  used for record expressions, I would say the overlapping with either
  polytypes (they never appear simultaneously) or context (idem, since we
  put label accesses but not records in contexts.

  Alternatively, we could use $\ceils \e$ for polytypes---and then $\floors
  \e$ for the projections.


\end{itemize}

\section{The \OML calculus, feature by feature}

\Xgabriel{This section contains work-in-progress content that I intended to
use to rewrite Section 4, ``The \OML calculus''. I still believe that there
will not be enough space to keep Section 4 anyway, so I decided to stop this
rewrite effort and dump the current content here.}

\subsection{The core fragment}
\label{sec:language:core}
\label{sec/language/typing-rules}

\begin{mathparfig}{fig/typing-core}{Typing and inference: Core \ML}
  \inferrule[Var]
    {x : \sigma \in \G}
    {\G \th x : \sigma}

  \inferrule[Fun]
    {\G, x : \ta \th e : \tb }
    {\G \th \efun x e : \ta \to \tb}

  \inferrule[App]
    {\G \th \ea : \ta \to \tb \\
     \G \th \eb : \ta}
    {\G \th \eapp \ea \eb : \tb}

  \inferrule[Annot]
    {\G \th e : \t\where {\tvs \is \tys}}
    {\G \th (e : \exi \tvs \t) : \t\where {\tvs \is \tys}}

  \inferrule[Gen]
    {\G \th e : \sigma \\ \tv \disjoint \G}
    {\G \th e : \tfor \tv \sigma}

  \inferrule[Inst]
    {\G \th e : \tfor \tv \ts}
    {\G \th e : \ts \where{\tv \is \t}}

  \inferrule[Let]
    {\G \th \ea : \sigma \\
     \G, x : \sigma \th \eb : \t}
    {\G \th \elet x \ea \eb : \t}
\\
\newcommand {\Crule}[2]{#1 & \eqdef & #2}
\begin{array}{l@{\uad} c@{\uad} l}
\Crule
  {\cinfer {\efun \x \e} \t}
  {\cexists {\tva, \tvb}
    \cunif \t {\tva \to \tvb}
    {}}
\\ & & \quad\uad {} \cand \clet \x \tvc {\cunif \tvc \tva} {\cinfer \e \tvb}
\\
\Crule
  {\cinfer {\eapp \ea \eb} \t}
  {\cexists {\tva} \cinfer \ea {\tva \to \t} \cand \cinfer \eb \tva}
\end{array}
\quad
\begin{array}{l@{\uad} c@{\uad} l}
\Crule
   {\cinfer x \t}
   {\cinst x \t}
\\
\Crule
  {\cinfer {\elet \x \ea \eb} \t}
  {\clet \x \tva {\cinfer \ea \tva} {\cinfer \eb \t}}
\\
\Crule
  {\cinfer {\eannot \e \tvs \tp} \t}
  {\cexists \tvs \cunif \t \tp \cand \cinfer \e \tp}
\end{array}
\end{mathparfig}

As usual, the main typing judgment $\G \th \e : \ts$ states that in
context $\G$, expression $\e$ has type scheme $\ts$. We give the
typing rules for the core \ML fragment in \cref{fig/typing-core}. It
also defines constraint generation for this fragment: given a term
$\e$ and its expected type $\t$, which may contain some free type
variables, we define a constraint $\cinfer e \t$ that is satisfiable
if and only if the term is well-typed for some instantiation of those
free type variables. Both typing rules and constraint generations are
standard on this fragment, and we will not comment them further due to
space restrictions.

\subsection{Unicity via magic rules}

TODO: a figure with the magic rule and the two unicity criterion (not for labels).

\subsection{Overloaded tuples}

\begin{mathparfig}{fig/typing-tuples}{Typing and inference: tuples}
  \inferrule[Tuple]
    {\parens{\G \th \ei : \ti}\iton}
    {\G \th (\ea, \ldots, \en) : \Pi\iton \ti}

  \inferrule[Proj-X]
    {\G \th \e : \Pi\iton \ti \\
     1 \leq j \leq n}
    {\G \th \exproj \e j n : \tj}

  \inferrule[Proj-I]
    {\eshape \E \e {\any \tvcs \Pi\iton \tvcs} \\
     \G \th \E\where{\exproj \e j n} : \t}
    {\G \th \E\where{\eproj \e j} : \t}
\\
  \newcommand{\Mrule}[5][]{{#2} \Matches {(#3)} \; #4 &\eqdef& {#5} & #1}
 \begin{array}{rcl@{\qquad}l@{\qquad\qquad} r}
   \cpat & ::= & \dots \mid \cpatprod \tv j & & \text{tuple patterns} \\
    \Mrule[\text{if } n \geq j]
      {\cpatprod \tv j}
      {\any \tvcs \Pi\iton \tvcs} \tvbs
      {[\tv \is \tvb_j]}
   & \text{matching relation}
 \end{array}
\\
\newcommand {\Crule}[2]{#1 & \eqdef & #2}
\begin{array}{l@{\uad} c@{\uad} l}
\Crule
  {\cinfer {\etuple {\ea, \ldots, \en}} \t}
  {\cexists \tvs \cunif \t {\Pi\iton \tvs}
    \cand \cAnd \iton \cinfer \ei {\tvi}}
\\
\Crule
  {\cinfer {\exfield \e j n} \t}
  {\cexists {\tvbs}
    \cinfer \e {\Pi\iton \tvbs}
    \cand \cunif \t {\tvb_j}}
\\
\Crule
  {\cinfer {\eproj \e j} \t}
  {\cexists \tv \cinfer \e \tv
    \cand \cmatch \tv {\cbranch {\cpatprod \tvb j} {\cunif \t \tvb}}}
\end{array}
\end{mathparfig}

\subsection{Polytypes}

\begin{mathparfig}{fig/typing-polytypes}{Typing and inference: polytypes}
  \inferrule [Poly-X]
    {\G \th \e : \ts\where {\tvs \is \tys}}
    {\G \th \epoly[\exi \tvs \ts] \e : \tpoly {\ts \where {\tvs \is \tys}}}

  \inferrule [Poly-I]
    {\Eshape \E \e {{\any \tvcs \tpoly \ts}} \\
     \G \th \E \where{\epoly[\exi \tvcs \ts] \e} : \t}
    {\G \th \E \where{\epoly \e} : \t}

  \inferrule [Use-X]
    {\G \th \e : \tpoly \ts \where {\tvs \is \tys}}
    {\G \th \exinst e \tvs \ts : \ts \where {\tvs \is \tys}}

  \inferrule [Use-I]
    {\eshape \E  \e {\any \tvcs \tpoly \ts} \\
     \G \th \E\where{\exinst \e \tvcs \ts} : \t}
    {\G \th \E\where{\einst \e} : \t}
\\
  \newcommand{\Mrule}[5][]{{#2} \Matches {(#3)} \; #4 &\eqdef& {#5} & #1}
 \begin{array}{rcl@{\qquad}l@{\qquad\qquad} r}
   \cpat & ::= & \dots \mid \cpatpoly \cscm
               & & \text{polytype patterns} \\
   \c & ::= & \dots \mid \cscm \leq \t \mid \ts \leq \t \mid \x \leq \cscm \mid \x \leq \ts
            & & \text{polytype constraints} \\
    \Mrule
      {\cpatpoly \cscm}
      {\any \tvcs \tpoly \ts} \tvbs
      {[\cscm \is \ts \where{\tvcs \is \tvbs}]}
   & \text{matching relation}
 \end{array}
\\
\newcommand {\Crule}[2]{#1 & \eqdef & #2}
\begin{array}{l@{\uad} c@{\uad} l}
\\
\Crule
  {\cinfer {\expoly \e \tvs \ts} \t}
  {\cexists {\tvs}
    \cinfer \e \ts
    \cand \cunif \t {\tpoly \ts}}
\\
\Crule
  {\cinfer {\exinst \e \tvs \ts} \t}
  {\cexists {\tvs}
    \cinfer \e {\tpoly \ts}
    \cand \ts \leq \t}
\\
\Crule
  {\cinfer {\einst \e} \t}
  {\cexists \tva
    \cinfer \e \tva
    \cand \cmatch \tva {\cbranch {\cpatpoly \cscm} \cscm \leq \t}}
\\
\Crule
  {\cinfer {\epoly \e} \t}
  {\clet \x \tv {\cinfer \e \tv}
    {\cmatch \t {\cbranch {\cpatpoly \cscm} {\x \leq \cscm}}}}
\end{array}
\end{mathparfig}

\subsection{Nominal records}

TODO: extend the magic rule and the disambiguation rule, and also provide the unicity-in-env criterion definition. I propose to add those to the figure below.

\begin{mathparfig}{fig/typing-records}{Typing and inference: nominal records}
  \inferrule[Rcd-Assn]
    {\G \th \e : \t \\
     \G \th \el : \t \to \tp}
    {\G \th \el = \e : \tp}

  \inferrule[Rcd]
    {\parens{\G \th \eli = \ei : \t}\iton \\
     \G \th \bar \el \uni \t}
    {\G \th \erecord {\ela = \ea; \ldots; \el_n = \en} : \t}

  \inferrule[Rcd-Proj]
    {\G \th \e : \tp \\
     \G \th \el : \t \to \tp \\
     \G \th \el \uni \t }
    {\G \th \efield \e \el : \t}

  \inferrule[Lab-X]
    {\labenv(\labfrom \elab \T) = \tfor \tvs \t \to \tvs \T }
    {\G \th \labfrom \elab \T : \tys\where{\tvs \is \tys} \to \tys \T}

  \inferrule[Lab-I]
    {\Lshape \Lab \elab \T \\
      \G \th \Lab[\labfrom \elab \T] : \t}
    {\G \th \Lab[\elab] : \t}

  \inferrule[Lab-!]
    {\bar \el \uni \T \in \labenv}
    {\G \th \bar \el \uni \tys \T}

  \inferrule[Lab-?]
    {\G \th \t}
    {\G \th \bar \el \uni \t}
\\
  \newcommand{\Mrule}[5][]{{#2} \Matches {(#3)} \; #4 &\eqdef& {#5} & #1}
 \begin{array}{rcl@{}l@{\qquad} r}
   \cpat & ::= & \dots \mid \cpatrcd \ct & & \text{record patterns} \\
   \c & ::= & \dots
              \mid \labenv(\labfrom \elab \ct) \leq \ta \to \tb
              \mid \labenv(\labfrom \elab \T) \leq \ta \to \tb
            & & \text{record constraints} \\
    \Mrule
      {\cpatrcd \ct}
      {\any \tvcs \tvcs \Tapp} \tvbs
      {[\ct \is ~ \T]}
   & \text{matching relation}
 \end{array}
\\
\newcommand {\Crule}[2]{#1 & \eqdef & #2}
\begin{array}{l@{\uad} c@{\uad} l}
\Crule
  {\cinferassn \el \e \t}
  {\cexists \tv \cinfer \e \tv
    \cand \cinferlab \el \tv \t}
\\
\Crule
  {\cinferlab \elab \ta \tb}
  {\cmatch \tb {\cbranch {\cpatrcd \ct} {\labenv(\labfrom \elab \ct) \leq \ta \to \tb}}}
\\
\Crule
  {\cinferlab {\labfrom \elab \T} \ta \tb}
  {\labenv(\labfrom \elab \T) \leq \ta \to \tb}
\\
\Crule
  {\cinferlab {\elmagic \elab} \ta \tb}
  {\ctrue}
\\
\Crule
  {\cinferlab {\elannot \el \tvs \t} \ta \tb}
  {\cexists \tvs \cinferlab \el \ta \tb \cand \cunif \tb \t}
\\
\Crule
  {\cinferlabuni {\bar \el} \t}
  {\begin{cases}
    \cexists \tvs \cunif \t {\tvs \Tapp} &\text{if } \bar \el \uni \T \in \labenv \\
    \ctrue &\text{otherwise}
   \end{cases}}
\end{array}
\end{mathparfig}


\end{document}

% LocalWords:  omnidirectional typecheck polymorphism Hindley Milner kinded
% LocalWords:  GADTs typechecked codomain typechecking subexpressions Bodin
% LocalWords:  monomorphic subexpression Dunfield Riboulet jfla subtyping
% LocalWords:  greek Chargueraud typable monotype polytype Garrigue Remy th
% LocalWords:  impredicative polytypes minimality RCL ary Proj toplevel mlf
% LocalWords:  typability backpropagation arity Compositionality equi Damas
% LocalWords:  equitypable compositionality inlined equitypability nullary
% LocalWords:  metatheoretical finiteness nonvariable mydesc Inlining Yi na
% LocalWords:  unicity inlining typedness pincipality scrutinee equalities
% LocalWords:  declaratively LeBotlan directionality polymorphically mleth
% LocalWords:  directionally typecheckers typechecker disambiguates unshare
% LocalWords:  typechecks acyclic emlti Disambiguating disambiguated GADT
% LocalWords:  prototyped instantiation Monotypes postfixed unsatisfiable
% LocalWords:  satisfiable matchee datatypes arbritraty generalizable Unif
% LocalWords:  monomorphization desugars Forall satisfiability formers iff
% LocalWords:  equirecursive principalShapes subterms Susp Ctx foundedness
% LocalWords:  unsatisfiability getx olymorphic nstances ive typings LetR
% LocalWords:  metavariable subterm Metatheory principalTypes monotypes Rcd
% LocalWords:  ExistsLeft ExistsRight ConjLeft ConjRight equational AppR Wf
% LocalWords:  existentials instantiations desugared susp ively renamings
% LocalWords:  quantifications subcomponents BackProp Tarjan's invariants
% LocalWords:  rossberg wasm WebAssembly dunfield krishnaswami jones Huet's
% LocalWords:  huet unif conf Vytiniotis Peyton Schrijvers Sulzmann Leijen
% LocalWords:  disambiguating namespace implicits Bour Yallop Didier Annot
% LocalWords:  acyclicity canonicalization aaa formedness unannotated inX
% LocalWords:  casted inMagic inAnnot unsubstituted oml RCLL Scm LCL Decomp
% LocalWords:  mutli cheatsheet inI ProjX PolyX UseX unifier Gc Defn sw iw
% LocalWords:  InstLeft InstRight mergable tw uw RRCL eqs priori multiset
% LocalWords:  reflexitivity metatheoretic lexicographically Unifiers TODO
% LocalWords:  rcl env Pcd illtyped inHole Ui unfoldings welltyped mprset
% LocalWords:  lessskip Xbla Ybla explicitating Composability composability
% LocalWords:  determinacy subcases unifications annotatability approxi Rcx
% LocalWords:  mation macroified cpoint concretize Dom
